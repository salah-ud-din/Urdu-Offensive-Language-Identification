{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GvvjdQWfjdZs",
    "outputId": "0709b5d6-f222-4edd-d1cb-4e4e6b3a00f9"
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y numpy\n",
    "!pip install numpy==1.26.4 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwS6bcGnt6gg",
    "outputId": "cdce657a-497f-4d9e-ba7a-2286e3b25a86"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I74fjqdUjyTz",
    "outputId": "ea891d63-add2-4bb3-b85d-1f42853659cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.26.4\n",
      "TensorFlow version: 2.20.0-dev20250425\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1uIy8uSztsVd",
    "outputId": "dfab8a71-0b18-4cf6-8699-8f67ede32e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              Tweet  Tag\n",
      "0           0  USER دو بے نسلئیے ، حرامخور منافق مل رہے ہیں پ...    0\n",
      "1           3                   USER گھٹیا انسان دنیا ہی چھوڑ دو    1\n",
      "2          11  USER PMLN میں آپ کے بارے میں میری بہتر راۓ تھی...    1\n",
      "3          15  USER اسپین کی ٹیم بھی پاکستان کی کرکٹ ٹیم کی ط...    0\n",
      "4          20  ہمیں تو آج تک سمجھ نہیں آئی کہ کم عقل عیسائی ح...    1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8758 entries, 0 to 8757\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  8758 non-null   int64 \n",
      " 1   Tweet       8758 non-null   object\n",
      " 2   Tag         8758 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 205.4+ KB\n",
      "None\n",
      "Index(['Unnamed: 0', 'Tweet', 'Tag'], dtype='object') (8758, 3)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "\n",
    "import gc, os, time, numpy as np, pandas as pd, datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import gc, os, time,datetime, numpy as np, pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers import Input, Reshape, Embedding, BatchNormalization\n",
    "from tensorflow.keras.layers import GRU, LSTM, Conv1D, Conv2D, Dense, Bidirectional\n",
    "from tensorflow.keras.layers import SpatialDropout1D, Dropout, Concatenate, concatenate\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling1D, AveragePooling1D\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # supress tensorflow warnings\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "PRE_TRAINED_FLAG = True\n",
    "EMBEDDING_MATRIX = []\n",
    "\n",
    "result_path =  '/content/drive/MyDrive/T2-Code/T2-DL-FastText-off-Result.csv'\n",
    "file_path =  '/content/drive/MyDrive/T2-Code/Offensive-24K-T2.xlsx'\n",
    "EMBEDDING_FILE = '/content/drive/MyDrive/T2-Code/Embedding/cc.ur.300.off.vec'\n",
    "\n",
    "result_path =  r'C:\\Users\\mojua\\Desktop\\DL-Code\\T2-DL-FastText-off-Result.csv'\n",
    "file_path = r'C:\\Users\\mojua\\Desktop\\DL-Code\\Dataset\\Offensive-24K-T2.xlsx'\n",
    "EMBEDDING_FILE = r'C:\\Users\\mojua\\Desktop\\DL-Code\\T1-Code\\Embeddings\\cc.ur.300.off.vec'\n",
    "########################################################\n",
    "def WriteResutls(reports):\n",
    "\n",
    "  unt0 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  tin1 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  macroavg = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  weightedavg = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  accu = []\n",
    "  for report in reports:\n",
    "    for k,v in report.items():\n",
    "      if 'UNT' in k:\n",
    "        unt0['precision'].append(v['precision'])\n",
    "        unt0['recall'].append(v['recall'])\n",
    "        unt0['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'TIN' in k:\n",
    "        tin1['precision'].append(v['precision'])\n",
    "        tin1['recall'].append(v['recall'])\n",
    "        tin1['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'macro avg' in k:\n",
    "        macroavg['precision'].append(v['precision'])\n",
    "        macroavg['recall'].append(v['recall'])\n",
    "        macroavg['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'weighted avg' in k:\n",
    "        weightedavg['precision'].append(v['precision'])\n",
    "        weightedavg['recall'].append(v['recall'])\n",
    "        weightedavg['f1-score'].append(v['f1-score'])\n",
    "      else:\n",
    "        accu.append(v)\n",
    "\n",
    "  print('Accuracy:',np.mean(accu))\n",
    "  print(\"\")\n",
    "  print('UNT 0 Precision:',np.mean(unt0['precision']))\n",
    "  print('UNT 0 Recall:',np.mean(unt0['recall']))\n",
    "  print('UNT 0 F1-Score:',np.mean(unt0['f1-score']))\n",
    "  print(\"\")\n",
    "  print('TIN 1 Precision:',np.mean(tin1['precision']))\n",
    "  print('TIN 1 Recall:',np.mean(tin1['recall']))\n",
    "  print('TIN 1 F1-Score:',np.mean(tin1['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('Weighted Avg Precision:',np.mean(weightedavg['precision']))\n",
    "  print('Weighted Avg Recall:',np.mean(weightedavg['recall']))\n",
    "  print('Weighted Avg F1-Score:',np.mean(weightedavg['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('Macro  Precision:',np.mean(macroavg['precision']))\n",
    "  print('Macro  Recall:',np.mean(macroavg['recall']))\n",
    "  print('Macro  F1-Score:',np.mean(macroavg['f1-score']))\n",
    "\n",
    "  file = open( result_path, mode='a' )\n",
    "  file.write( modelname+ ' ( '+ datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") +') \\n' )\n",
    "  file.write( 'Accuracy:'+str(np.mean(accu))+'\\n' )\n",
    "  file.write('UNT 0 Precision:'+str(np.mean(unt0['precision']))+'\\n' )\n",
    "  file.write('UNT 0 Recall:'+str(np.mean(unt0['recall']))+'\\n' )\n",
    "  file.write('UNT 0 F1-Score:'+str(np.mean(unt0['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('TIN 1 Precision:'+str(np.mean(tin1['precision']))+'\\n' )\n",
    "  file.write('TIN 1 Recall:'+str(np.mean(tin1['recall']))+'\\n' )\n",
    "  file.write('TIN 1 F1-Score:'+str(np.mean(tin1['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('Weighted Avg Precision:'+str(np.mean(weightedavg['precision']))+'\\n' )\n",
    "  file.write('Weighted Avg Recall:'+str(np.mean(weightedavg['recall']))+'\\n' )\n",
    "  file.write('Weighted Avg F1-Score:'+str(np.mean(weightedavg['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('Macro  Precision:'+str(np.mean(macroavg['precision']))+'\\n' )\n",
    "  file.write('Macro  Recall:'+str(np.mean(macroavg['recall']))+'\\n' )\n",
    "  file.write('Macro  F1-Score:'+str(np.mean(macroavg['f1-score']))+'\\n' )\n",
    "  file.close()\n",
    "  print(\"Done\")\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "def hms_string( sec_elapsed ):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{} hrs {:>02} mins {:>05.2f} secs\".format( h, m, s )\n",
    "########################################################################################\n",
    "def get_coefs( word, *arr ):\n",
    "    return word, np.asarray( arr, dtype='float32' )\n",
    "\n",
    "def get_vectors( tokenizer, emb_mean, emb_std, embed_size ):\n",
    "    hits = 0\n",
    "    misses = 0\n",
    "    word_index = tokenizer.word_index\n",
    "    num_words = len( word_index ) + 1\n",
    "    embedding_matrix = np.random.normal( emb_mean, emb_std, ( num_words, embed_size ) ) # for unk tokens\n",
    "    embedding_matrix[0] = np.zeros( ( embed_size ) ) # replace zero padding with zeros\n",
    "    for word, i in word_index.items(  ):\n",
    "        embedding_vector = EMBEDDINGS_INDEX.get( word )\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[ i ] = embedding_vector\n",
    "            hits += 1\n",
    "        else:\n",
    "            misses += 1\n",
    "    print( \"Pretrained Embeddings: %d hits (%d misses)\" % ( hits, misses ) )\n",
    "    gc.collect()\n",
    "    return embedding_matrix\n",
    "\n",
    "#################################################################################################################\n",
    "\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "df.reset_index( drop=True, inplace=True )\n",
    "df.Tweet = df.Tweet.astype( 'str' )\n",
    "df.dropna( inplace=True )\n",
    "df.reset_index( drop=True, inplace=True )\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.columns, df.shape)\n",
    "gc.collect()\n",
    "xcolumn = 'Tweet'\n",
    "ycolumn = 'Tag'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zFQaJoc1lRi8"
   },
   "outputs": [],
   "source": [
    "def optimize_threshold( y_true, y_pred ):\n",
    "    thresholds = np.arange( 0.1, 0.9, 0.001 )\n",
    "    vscores = np.zeros( thresholds.shape[ 0 ] )\n",
    "    for th in range( thresholds.shape[ 0 ] ):\n",
    "        vscores[ th ] = f1_score( y_true, ( y_pred >= thresholds[ th ] ).astype( 'int32' ) )\n",
    "    return thresholds[ np.argmax( vscores ) ] # return threshold that has max val score\n",
    "\n",
    "class F1_score_callback( Callback ):\n",
    "    def __init__( self, val_data, filepath, patience=10, decay=True, decay_rate=0.1, decay_after=2 ):\n",
    "        self.file_path = filepath\n",
    "        self.patience = patience\n",
    "        self.patience_counter = 0\n",
    "        self.decay = decay\n",
    "        self.decay_rate = decay_rate\n",
    "        self.decay_after = decay_after\n",
    "        self.validation_data = val_data\n",
    "\n",
    "    def __optimize_threshold_for_f1( self, y_true, y_pred ):\n",
    "        thresholds = np.arange( 0.1, 0.9, 0.001 )\n",
    "        vscores = np.zeros( thresholds.shape[ 0 ] )\n",
    "        for th in range( thresholds.shape[ 0 ] ):\n",
    "            vscores[ th ] = f1_score( y_true, ( y_pred >= thresholds[ th ] ).astype( 'int32' ) )\n",
    "        return thresholds[ np.argmax( vscores ) ]\n",
    "\n",
    "    def on_train_begin( self, logs=None ):\n",
    "        self.val_f1s = []\n",
    "        self.best_val_f1 = np.NINF\n",
    "\n",
    "    def on_epoch_end( self, epoch, logs={} ):\n",
    "        val_predict = self.model.predict( self.validation_data[ 0 ] )\n",
    "        val_targ = self.validation_data[ 1 ]\n",
    "\n",
    "        threshold = self.__optimize_threshold_for_f1( val_targ, val_predict )\n",
    "\n",
    "        _val_f1 = f1_score( val_targ, ( val_predict >= threshold ).astype( 'int32' ) )\n",
    "        self.val_f1s.append(_val_f1)\n",
    "\n",
    "        self.patience_counter = self.patience_counter + 1\n",
    "\n",
    "        printstatement = 'Epoch: {:03d}'.format( epoch + 1 ) +\\\n",
    "        ' --LR: {:1.0e}'.format( K.get_value( self.model.optimizer.learning_rate ) ) +\\\n",
    "        ' --MaxValF1: {:0.7f}'.format( max( self.val_f1s ) ) +\\\n",
    "        ' --CurValF1: {:0.7f}'.format( _val_f1 ) + ' --Patience: {:02d}'.format( self.patience_counter )\n",
    "\n",
    "        if _val_f1 > self.best_val_f1:\n",
    "            self.model.save( self.file_path, overwrite=True, include_optimizer=True )\n",
    "            self.best_val_f1 = _val_f1\n",
    "            printstatement = printstatement + ' --F1 improved: {:0.7f}'.format( self.best_val_f1 )\n",
    "            self.patience_counter = 0\n",
    "\n",
    "        print( printstatement )\n",
    "\n",
    "        if ( (self.decay==True) & ((self.patience_counter % self.decay_after) == 0) & (self.patience_counter != 0) ):\n",
    "          if isinstance(self.model.optimizer.learning_rate, tf.Variable):\n",
    "            K.set_value(self.model.optimizer.learning_rate, (K.get_value( self.model.optimizer.learning_rate ) * self.decay_rate))\n",
    "          else:\n",
    "            self.model.optimizer.learning_rate = K.get_value( self.model.optimizer.learning_rate ) * self.decay_rate  # just assign directly\n",
    "\n",
    "            #K.set_value( self.model.optimizer.learning_rate, ( K.get_value( self.model.optimizer.learning_rate ) * self.decay_rate ) )\n",
    "\n",
    "        if self.patience_counter == self.patience:\n",
    "            self.model.stop_training = True\n",
    "            print( 'Training stopped due to the patience parameter.' + \\\n",
    "                  ' --Patience: {:02d}'.format( self.patience_counter ) )\n",
    "\n",
    "        return\n",
    "\n",
    "def focal_loss( gamma=1., alpha=.1 ):\n",
    "    def focal_loss_fixed( y_true, y_pred ):\n",
    "        pt_1 = tf.where( tf.equal( y_true, 1 ), y_pred, tf.ones_like( y_pred ) )\n",
    "        pt_0 = tf.where( tf.equal( y_true, 0 ), y_pred, tf.zeros_like( y_pred ) )\n",
    "        return -K.sum( alpha * K.pow( 1. - pt_1, gamma ) * K.log( pt_1 ) ) - K.sum( ( 1 - alpha ) * K.pow( pt_0, gamma ) * K.log( 1. - pt_0 ) )\n",
    "    return focal_loss_fixed\n",
    "\n",
    "def MCBiGRU(\n",
    "    max_len=100, embed_inp=10000, embed_size=300, embedding_matrix=[], embed_trainable=False,\n",
    "    drpt=.1, emb_weights_init='', conv_weights_init='', conv_act='', fc_weights_init='',\n",
    "    fc_act='', optimizer='' ):\n",
    "\n",
    "    window_sizes = [ 1,2,3,5,6 ]\n",
    "    allchannels = [  ]\n",
    "\n",
    "    inp = Input( shape=( max_len, ) )\n",
    "    if embedding_matrix is None:\n",
    "        x = Embedding( input_dim=embed_inp, output_dim=embed_size,\n",
    "                      embeddings_initializer=emb_weights_init, trainable=embed_trainable )( inp )\n",
    "    else:\n",
    "        x = Embedding( input_dim=embed_inp, output_dim=embed_size,\n",
    "                      weights=[ embedding_matrix ], trainable=embed_trainable )( inp )\n",
    "\n",
    "    for j,i in enumerate( window_sizes ):\n",
    "        conv = Conv1D( filters=128, kernel_size=i, padding='valid',\n",
    "                      activation=conv_act, kernel_initializer=conv_weights_init )( x )\n",
    "        drpt1 = Dropout( drpt )( conv )\n",
    "        maxpool = MaxPooling1D( pool_size=4 )( drpt1 )\n",
    "        bgru = Bidirectional( GRU( 200, return_sequences=False ) )( maxpool )\n",
    "        drpt2 = Dropout( drpt )( bgru )\n",
    "        allchannels.append( drpt2 )\n",
    "\n",
    "    z = concatenate( allchannels )\n",
    "    fc = Dense( 2000, activation=fc_act, kernel_initializer=fc_weights_init )( z )\n",
    "    bnorm = BatchNormalization(  )( fc )\n",
    "    output = Dense( 1, activation='sigmoid' )( bnorm )\n",
    "\n",
    "    model = Model( inputs=inp, outputs=output )\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "############################################################################\n",
    "def CNN_George(\n",
    "    max_len=100, embed_inp=10000, embed_size=300, embedding_matrix=[], embed_trainable=False,\n",
    "    emb_weights_init='', optimizer='' ):\n",
    "\n",
    "    filter_sizes = [ 3,4,5 ]\n",
    "    num_filters = 32\n",
    "    inp = Input( shape=( max_len, ) )\n",
    "    if embedding_matrix is None:\n",
    "        x = Embedding( input_dim=embed_inp, output_dim=embed_size,\n",
    "                      embeddings_initializer=emb_weights_init, trainable=embed_trainable )( inp )\n",
    "    else:\n",
    "        x = Embedding( input_dim=embed_inp, output_dim=embed_size,\n",
    "                      weights=[ embedding_matrix ], trainable=embed_trainable )( inp )\n",
    "\n",
    "    x = Reshape( ( max_len, embed_size, 1 ) )( x )\n",
    "    pooled = [  ]\n",
    "    for j,i in enumerate( filter_sizes ):\n",
    "        conv = Conv2D( num_filters, kernel_size=( i, embed_size ), activation='relu' )( x )\n",
    "        globalmax = GlobalMaxPooling2D(  )( conv )\n",
    "        pooled.append( globalmax )\n",
    "    z = Concatenate( axis=1 )( pooled )\n",
    "    output = Dense( 1, activation='sigmoid' )( z )\n",
    "\n",
    "    model = Model( inputs=inp, outputs=output )\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3jNu0_k9pvjQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words in Pretrained Embeddings:  1154697\n",
      "Pretrained Embeddings mean: -0.0023497287  std:  0.08804372\n"
     ]
    }
   ],
   "source": [
    "modelname = 'CNN_George-ft'\n",
    "modelpath = './Saved Models/' + modelname + '/'\n",
    "modelresults = './Model Results'\n",
    "modelsummaries = './Model - Summaries-Figures'\n",
    "DIRECTORIES_TO_BE_CREATED = [ modelpath, modelresults, modelsummaries ]\n",
    "for directory in DIRECTORIES_TO_BE_CREATED:\n",
    "    if not os.path.exists( directory ): os.makedirs( directory )\n",
    "\n",
    "# hyper parameters for this model\n",
    "MAX_LEN = 128\n",
    "EMBED_SIZE = 300\n",
    "EMBED_TRAINABLE = False\n",
    "EMB_WEIGHTS_INIT = 'he_normal'\n",
    "LR_RATE = 1e-3\n",
    "OPTIMIZER = 'adam'\n",
    "BATCH = 32\n",
    "NEPOCHS = 30\n",
    "PATIENCE = 5\n",
    "DECAY = True\n",
    "DECAY_RATE = 0.3\n",
    "DECAY_AFTER = 1\n",
    "\n",
    "if PRE_TRAINED_FLAG == True:\n",
    "    EMBEDDINGS_INDEX = dict( get_coefs( *o.strip().split() ) for o in open( EMBEDDING_FILE, encoding='utf-8' )  if len(o)>19 )\n",
    "    print( 'Total Words in Pretrained Embeddings: ', len( EMBEDDINGS_INDEX.values() ) )\n",
    "    all_embs = np.stack( list(EMBEDDINGS_INDEX.values()) )\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    print( 'Pretrained Embeddings mean:', emb_mean, ' std: ', emb_std )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pzTcqrt4qJda",
    "outputId": "55583fa7-0f0a-4da7-a398-2caa7ee6662a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local System Time: 10:34 AM\n",
      "StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
      "2025-05-23 10:34:27\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">+----------------------------------------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\"> Layer (type)                  </span>|<span style=\"font-weight: bold\"> Output Shape              </span>|<span style=\"font-weight: bold\">         Param # </span>|<span style=\"font-weight: bold\"> Connected to               </span>|\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | -                          |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)          |       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,611,800</span> | input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)           | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        |          <span style=\"color: #00af00; text-decoration-color: #00af00\">28,832</span> | reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        |          <span style=\"color: #00af00; text-decoration-color: #00af00\">38,432</span> | reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        |          <span style=\"color: #00af00; text-decoration-color: #00af00\">48,032</span> | reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| global_max_pooling2d_3        | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             |\n",
       "| (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)          |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| global_max_pooling2d_4        | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             |\n",
       "| (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)          |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| global_max_pooling2d_5        | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             |\n",
       "| (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)          |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| concatenate_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)   | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)                |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | global_max_pooling2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… |\n",
       "|                               |                           |                 | global_max_pooling2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… |\n",
       "|                               |                           |                 | global_max_pooling2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 |              <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span> | concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        |\n",
       "+----------------------------------------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "+----------------------------------------------------------------------------------------------------------+\n",
       "|\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m|\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)    | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               |               \u001b[38;5;34m0\u001b[0m | -                          |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)       | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m300\u001b[0m)          |       \u001b[38;5;34m5,611,800\u001b[0m | input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| reshape_1 (\u001b[38;5;33mReshape\u001b[0m)           | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m1\u001b[0m)       |               \u001b[38;5;34m0\u001b[0m | embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)             | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)        |          \u001b[38;5;34m28,832\u001b[0m | reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)             | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)        |          \u001b[38;5;34m38,432\u001b[0m | reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)             | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)        |          \u001b[38;5;34m48,032\u001b[0m | reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| global_max_pooling2d_3        | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                |               \u001b[38;5;34m0\u001b[0m | conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             |\n",
       "| (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)          |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| global_max_pooling2d_4        | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                |               \u001b[38;5;34m0\u001b[0m | conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             |\n",
       "| (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)          |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| global_max_pooling2d_5        | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                |               \u001b[38;5;34m0\u001b[0m | conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             |\n",
       "| (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)          |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| concatenate_1 (\u001b[38;5;33mConcatenate\u001b[0m)   | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)                |               \u001b[38;5;34m0\u001b[0m | global_max_pooling2d_3[\u001b[38;5;34m0\u001b[0m]… |\n",
       "|                               |                           |                 | global_max_pooling2d_4[\u001b[38;5;34m0\u001b[0m]… |\n",
       "|                               |                           |                 | global_max_pooling2d_5[\u001b[38;5;34m0\u001b[0m]… |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dense_1 (\u001b[38;5;33mDense\u001b[0m)               | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 |              \u001b[38;5;34m97\u001b[0m | concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        |\n",
       "+----------------------------------------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,727,193</span> (21.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,727,193\u001b[0m (21.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115,393</span> (450.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m115,393\u001b[0m (450.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,611,800</span> (21.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,611,800\u001b[0m (21.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained Embeddings: 14041 hits (4664 misses)\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "Epoch: 001 --LR: 1e-03 --MaxValF1: 0.8682505 --CurValF1: 0.8682505 --Patience: 01 --F1 improved: 0.8682505\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 002 --LR: 1e-03 --MaxValF1: 0.8687430 --CurValF1: 0.8687430 --Patience: 01 --F1 improved: 0.8687430\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 003 --LR: 1e-03 --MaxValF1: 0.8705613 --CurValF1: 0.8705613 --Patience: 01 --F1 improved: 0.8705613\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 004 --LR: 1e-03 --MaxValF1: 0.8712422 --CurValF1: 0.8712422 --Patience: 01 --F1 improved: 0.8712422\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 005 --LR: 1e-03 --MaxValF1: 0.8732394 --CurValF1: 0.8732394 --Patience: 01 --F1 improved: 0.8732394\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 006 --LR: 1e-03 --MaxValF1: 0.8732394 --CurValF1: 0.8713418 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 007 --LR: 3e-04 --MaxValF1: 0.8742382 --CurValF1: 0.8742382 --Patience: 02 --F1 improved: 0.8742382\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 008 --LR: 3e-04 --MaxValF1: 0.8742382 --CurValF1: 0.8741722 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 009 --LR: 9e-05 --MaxValF1: 0.8745163 --CurValF1: 0.8745163 --Patience: 02 --F1 improved: 0.8745163\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 010 --LR: 9e-05 --MaxValF1: 0.8745163 --CurValF1: 0.8744493 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 011 --LR: 3e-05 --MaxValF1: 0.8745163 --CurValF1: 0.8738292 --Patience: 02\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 012 --LR: 8e-06 --MaxValF1: 0.8745163 --CurValF1: 0.8738292 --Patience: 03\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 013 --LR: 2e-06 --MaxValF1: 0.8745163 --CurValF1: 0.8738292 --Patience: 04\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 014 --LR: 7e-07 --MaxValF1: 0.8745163 --CurValF1: 0.8738292 --Patience: 05\n",
      "Training stopped due to the patience parameter. --Patience: 05\n",
      "Fold: 01 out of 05 completed.\n",
      "Local System Time: 10:37 AM\n",
      "2025-05-23 10:37:22\n",
      "Pretrained Embeddings: 14132 hits (4675 misses)\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "Epoch: 001 --LR: 1e-03 --MaxValF1: 0.8536854 --CurValF1: 0.8536854 --Patience: 01 --F1 improved: 0.8536854\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 002 --LR: 1e-03 --MaxValF1: 0.8555494 --CurValF1: 0.8555494 --Patience: 01 --F1 improved: 0.8555494\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 003 --LR: 1e-03 --MaxValF1: 0.8555494 --CurValF1: 0.8549451 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 004 --LR: 3e-04 --MaxValF1: 0.8569851 --CurValF1: 0.8569851 --Patience: 02 --F1 improved: 0.8569851\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 005 --LR: 3e-04 --MaxValF1: 0.8584071 --CurValF1: 0.8584071 --Patience: 01 --F1 improved: 0.8584071\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 006 --LR: 3e-04 --MaxValF1: 0.8590604 --CurValF1: 0.8590604 --Patience: 01 --F1 improved: 0.8590604\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 007 --LR: 3e-04 --MaxValF1: 0.8597388 --CurValF1: 0.8597388 --Patience: 01 --F1 improved: 0.8597388\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 008 --LR: 3e-04 --MaxValF1: 0.8616780 --CurValF1: 0.8616780 --Patience: 01 --F1 improved: 0.8616780\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 009 --LR: 3e-04 --MaxValF1: 0.8651163 --CurValF1: 0.8651163 --Patience: 01 --F1 improved: 0.8651163\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 010 --LR: 3e-04 --MaxValF1: 0.8651163 --CurValF1: 0.8592342 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 011 --LR: 9e-05 --MaxValF1: 0.8653061 --CurValF1: 0.8653061 --Patience: 02 --F1 improved: 0.8653061\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 012 --LR: 9e-05 --MaxValF1: 0.8653957 --CurValF1: 0.8653957 --Patience: 01 --F1 improved: 0.8653957\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 013 --LR: 9e-05 --MaxValF1: 0.8671738 --CurValF1: 0.8671738 --Patience: 01 --F1 improved: 0.8671738\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 014 --LR: 9e-05 --MaxValF1: 0.8682984 --CurValF1: 0.8682984 --Patience: 01 --F1 improved: 0.8682984\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 015 --LR: 9e-05 --MaxValF1: 0.8682984 --CurValF1: 0.8679465 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 016 --LR: 3e-05 --MaxValF1: 0.8692082 --CurValF1: 0.8692082 --Patience: 02 --F1 improved: 0.8692082\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 017 --LR: 3e-05 --MaxValF1: 0.8692621 --CurValF1: 0.8692621 --Patience: 01 --F1 improved: 0.8692621\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 018 --LR: 3e-05 --MaxValF1: 0.8692621 --CurValF1: 0.8676815 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 019 --LR: 8e-06 --MaxValF1: 0.8692621 --CurValF1: 0.8681898 --Patience: 02\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 020 --LR: 2e-06 --MaxValF1: 0.8692621 --CurValF1: 0.8685446 --Patience: 03\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 021 --LR: 7e-07 --MaxValF1: 0.8692621 --CurValF1: 0.8681898 --Patience: 04\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 022 --LR: 2e-07 --MaxValF1: 0.8692621 --CurValF1: 0.8681898 --Patience: 05\n",
      "Training stopped due to the patience parameter. --Patience: 05\n",
      "Fold: 02 out of 05 completed.\n",
      "Local System Time: 10:41 AM\n",
      "2025-05-23 10:41:55\n",
      "Pretrained Embeddings: 14040 hits (4592 misses)\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "Epoch: 001 --LR: 1e-03 --MaxValF1: 0.8554151 --CurValF1: 0.8554151 --Patience: 01 --F1 improved: 0.8554151\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 002 --LR: 1e-03 --MaxValF1: 0.8595411 --CurValF1: 0.8595411 --Patience: 01 --F1 improved: 0.8595411\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 003 --LR: 1e-03 --MaxValF1: 0.8627678 --CurValF1: 0.8627678 --Patience: 01 --F1 improved: 0.8627678\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 004 --LR: 1e-03 --MaxValF1: 0.8627678 --CurValF1: 0.8592509 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 005 --LR: 3e-04 --MaxValF1: 0.8627678 --CurValF1: 0.8627002 --Patience: 02\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 006 --LR: 9e-05 --MaxValF1: 0.8630849 --CurValF1: 0.8630849 --Patience: 03 --F1 improved: 0.8630849\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 007 --LR: 9e-05 --MaxValF1: 0.8634006 --CurValF1: 0.8634006 --Patience: 01 --F1 improved: 0.8634006\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 008 --LR: 9e-05 --MaxValF1: 0.8634006 --CurValF1: 0.8620889 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 009 --LR: 3e-05 --MaxValF1: 0.8638985 --CurValF1: 0.8638985 --Patience: 02 --F1 improved: 0.8638985\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 010 --LR: 3e-05 --MaxValF1: 0.8638985 --CurValF1: 0.8636884 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 011 --LR: 8e-06 --MaxValF1: 0.8638985 --CurValF1: 0.8628801 --Patience: 02\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 012 --LR: 2e-06 --MaxValF1: 0.8638985 --CurValF1: 0.8631459 --Patience: 03\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 013 --LR: 7e-07 --MaxValF1: 0.8641273 --CurValF1: 0.8641273 --Patience: 04 --F1 improved: 0.8641273\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 014 --LR: 7e-07 --MaxValF1: 0.8641273 --CurValF1: 0.8641273 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 015 --LR: 2e-07 --MaxValF1: 0.8641273 --CurValF1: 0.8641273 --Patience: 02\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 016 --LR: 7e-08 --MaxValF1: 0.8641273 --CurValF1: 0.8634812 --Patience: 03\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 017 --LR: 2e-08 --MaxValF1: 0.8641273 --CurValF1: 0.8634812 --Patience: 04\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 018 --LR: 6e-09 --MaxValF1: 0.8641273 --CurValF1: 0.8634812 --Patience: 05\n",
      "Training stopped due to the patience parameter. --Patience: 05\n",
      "Fold: 03 out of 05 completed.\n",
      "Local System Time: 10:45 AM\n",
      "2025-05-23 10:45:38\n",
      "Pretrained Embeddings: 14124 hits (4616 misses)\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "Epoch: 001 --LR: 1e-03 --MaxValF1: 0.8686534 --CurValF1: 0.8686534 --Patience: 01 --F1 improved: 0.8686534\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 002 --LR: 1e-03 --MaxValF1: 0.8686534 --CurValF1: 0.8684353 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 003 --LR: 3e-04 --MaxValF1: 0.8730791 --CurValF1: 0.8730791 --Patience: 02 --F1 improved: 0.8730791\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 004 --LR: 3e-04 --MaxValF1: 0.8752834 --CurValF1: 0.8752834 --Patience: 01 --F1 improved: 0.8752834\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 005 --LR: 3e-04 --MaxValF1: 0.8756567 --CurValF1: 0.8756567 --Patience: 01 --F1 improved: 0.8756567\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 006 --LR: 3e-04 --MaxValF1: 0.8756567 --CurValF1: 0.8754407 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 007 --LR: 9e-05 --MaxValF1: 0.8759605 --CurValF1: 0.8759605 --Patience: 02 --F1 improved: 0.8759605\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 008 --LR: 9e-05 --MaxValF1: 0.8762322 --CurValF1: 0.8762322 --Patience: 01 --F1 improved: 0.8762322\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 009 --LR: 9e-05 --MaxValF1: 0.8762322 --CurValF1: 0.8757526 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 010 --LR: 3e-05 --MaxValF1: 0.8762322 --CurValF1: 0.8760965 --Patience: 02\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 011 --LR: 8e-06 --MaxValF1: 0.8762322 --CurValF1: 0.8760965 --Patience: 03\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 012 --LR: 2e-06 --MaxValF1: 0.8765771 --CurValF1: 0.8765771 --Patience: 04 --F1 improved: 0.8765771\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 013 --LR: 2e-06 --MaxValF1: 0.8765771 --CurValF1: 0.8765771 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 014 --LR: 7e-07 --MaxValF1: 0.8765771 --CurValF1: 0.8765771 --Patience: 02\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 015 --LR: 2e-07 --MaxValF1: 0.8765771 --CurValF1: 0.8765771 --Patience: 03\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 016 --LR: 7e-08 --MaxValF1: 0.8765771 --CurValF1: 0.8765771 --Patience: 04\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 017 --LR: 2e-08 --MaxValF1: 0.8765771 --CurValF1: 0.8765771 --Patience: 05\n",
      "Training stopped due to the patience parameter. --Patience: 05\n",
      "Fold: 04 out of 05 completed.\n",
      "Local System Time: 10:49 AM\n",
      "2025-05-23 10:49:08\n",
      "Pretrained Embeddings: 14144 hits (4707 misses)\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "Epoch: 001 --LR: 1e-03 --MaxValF1: 0.8731628 --CurValF1: 0.8731628 --Patience: 01 --F1 improved: 0.8731628\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 002 --LR: 1e-03 --MaxValF1: 0.8758242 --CurValF1: 0.8758242 --Patience: 01 --F1 improved: 0.8758242\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 003 --LR: 1e-03 --MaxValF1: 0.8758242 --CurValF1: 0.8700873 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 004 --LR: 3e-04 --MaxValF1: 0.8758242 --CurValF1: 0.8725055 --Patience: 02\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 005 --LR: 9e-05 --MaxValF1: 0.8758242 --CurValF1: 0.8728860 --Patience: 03\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 006 --LR: 3e-05 --MaxValF1: 0.8758242 --CurValF1: 0.8722707 --Patience: 04\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step\n",
      "Epoch: 007 --LR: 8e-06 --MaxValF1: 0.8758242 --CurValF1: 0.8724100 --Patience: 05\n",
      "Training stopped due to the patience parameter. --Patience: 05\n",
      "Fold: 05 out of 05 completed.\n",
      "Local System Time: 10:50 AM\n",
      "Total runtime: 0 hrs 16 mins 12.06 secs\n",
      "Accuracy: 0.7720929853521407\n",
      "\n",
      "UNT 0 Precision: 0.6546917218086572\n",
      "UNT 0 Recall: 0.17603605337439057\n",
      "UNT 0 F1-Score: 0.26937599861288963\n",
      "\n",
      "TIN 1 Precision: 0.7819308735269012\n",
      "TIN 1 Recall: 0.9677006192901461\n",
      "TIN 1 F1-Score: 0.864748642076243\n",
      "\n",
      "Weighted Avg Precision: 0.7504925060641354\n",
      "Weighted Avg Recall: 0.7720929853521407\n",
      "Weighted Avg F1-Score: 0.7176423771666282\n",
      "\n",
      "Macro  Precision: 0.7183112976677792\n",
      "Macro  Recall: 0.5718683363322683\n",
      "Macro  F1-Score: 0.5670623203445664\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings( 'ignore' )\n",
    "import datetime\n",
    "from tensorflow.keras.layers import Input, Reshape, Embedding, BatchNormalization\n",
    "start_time = time.time()\n",
    "print( 'Local System Time: {}'.format( time.strftime( \"%I:%M %p\", time.localtime() ) ) )\n",
    "\n",
    "valaccuracy, valprecision, valrecall, valf1, valcm = [], [], [], [], []\n",
    "testaccuracy, testprecision, testrecall, testf1, testcm = [], [], [], [], []\n",
    "com_text, com_label, com_predicted, com_prob = [], [], [], []\n",
    "com_indices = []\n",
    "hist = {}\n",
    "reports = []\n",
    "\n",
    "skf = StratifiedKFold( n_splits=5, random_state=0, shuffle=True )\n",
    "print(skf)\n",
    "\n",
    "fold = 1\n",
    "for train_index, test_index in skf.split( df[ xcolumn ], df[ ycolumn ] ):\n",
    "    # seprating train and test sets\n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    xtrain = df.loc[ train_index ][ xcolumn ].values\n",
    "    xtest = df.loc[ test_index ][ xcolumn ].values\n",
    "\n",
    "    ytrain = df.loc[ train_index ][ ycolumn ].values\n",
    "    ytest = df.loc[ test_index ][ ycolumn ].values\n",
    "\n",
    "    # splitting train and validation sets\n",
    "    xtrain, xval, ytrain, yval = train_test_split( xtrain, ytrain, test_size=0.15, random_state=0 )\n",
    "\n",
    "    # tokenization with keras tokenizer\n",
    "    tokenizer = text.Tokenizer(  )\n",
    "    tokenizer.fit_on_texts( np.append( xtrain, xval ) )\n",
    "\n",
    "    xtrain = tokenizer.texts_to_sequences( xtrain )\n",
    "    xval = tokenizer.texts_to_sequences( xval )\n",
    "    xtest = tokenizer.texts_to_sequences( xtest )\n",
    "\n",
    "    # pad the tokenized sequences\n",
    "    xtrain = sequence.pad_sequences( xtrain, maxlen=MAX_LEN )\n",
    "    xval = sequence.pad_sequences( xval, maxlen=MAX_LEN )\n",
    "    xtest = sequence.pad_sequences( xtest, maxlen=MAX_LEN )\n",
    "\n",
    "    # check if pre-trained word embeddings flag is true\n",
    "    if PRE_TRAINED_FLAG == True:\n",
    "        EMBEDDING_MATRIX = get_vectors(\n",
    "            tokenizer=tokenizer, emb_mean=emb_mean, emb_std=emb_std, embed_size=EMBED_SIZE\n",
    "        )\n",
    "\n",
    "    # define a model\n",
    "    EMBED_INP_SIZE = len( tokenizer.word_index ) + 1\n",
    "    model = CNN_George(\n",
    "        max_len=MAX_LEN, embed_inp=EMBED_INP_SIZE, embed_size=EMBED_SIZE,\n",
    "        embedding_matrix=EMBEDDING_MATRIX, embed_trainable=EMBED_TRAINABLE,\n",
    "        emb_weights_init=EMB_WEIGHTS_INIT, optimizer='adam'\n",
    "    )\n",
    "\n",
    "    # save model summaries and model architecture diagrams in the first fold only\n",
    "    if fold == 1:\n",
    "       # plot_model( model=model, to_file='{}/{}.png'.format( modelsummaries, modelname ), show_shapes=False )\n",
    "\n",
    "        with open( '{}/{}.txt'.format( modelsummaries, modelname ), 'w' ) as s:\n",
    "            with redirect_stdout( s ):model.summary()\n",
    "    # Change the type of LR_RATE to float\n",
    "    #LR_RATE = float(LR_RATE)\n",
    "    #K.set_value( model.optimizer.learning_rate, LR_RATE )\n",
    "    LR_RATE = float(LR_RATE)\n",
    "    if isinstance(model.optimizer.learning_rate, tf.Variable):\n",
    "      K.set_value(model.optimizer.learning_rate, LR_RATE)\n",
    "    else:\n",
    "      model.optimizer.learning_rate = LR_RATE  # just assign directly\n",
    "    # train the model with callbacks for early stopping\n",
    "    f1callback = F1_score_callback( val_data=( xval, yval ), filepath=modelpath + modelname + str( fold ) + \".keras\",\n",
    "        patience=PATIENCE, decay=DECAY, decay_rate=DECAY_RATE, decay_after=DECAY_AFTER )\n",
    "    histmodel = model.fit(xtrain, ytrain, batch_size=BATCH, epochs=NEPOCHS, verbose=0, callbacks=[ f1callback ] )\n",
    "    # save history of all folds\n",
    "    hist[ 'fold' + str( fold ) ] = histmodel.history.copy()\n",
    "    # delete trained model object\n",
    "    del model, histmodel, f1callback\n",
    "    EMBEDDING_MATRIX = []\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    # delete pre trained embeddings from the memory\n",
    "    if ( PRE_TRAINED_FLAG == True ) and ( fold == skf.n_splits ):\n",
    "        del EMBEDDINGS_INDEX\n",
    "        gc.collect()\n",
    "\n",
    "    # load saved model\n",
    "    loaded_model = load_model( modelpath + modelname + str( fold ) + \".keras\")\n",
    "\n",
    "    # get predictions (probabilities) for validation and test sets respectively\n",
    "    valpredictions = loaded_model.predict( xval, verbose=0, batch_size=BATCH )\n",
    "    testpredictions = loaded_model.predict( xtest, verbose=0, batch_size=BATCH )\n",
    "\n",
    "    # delete loaded model\n",
    "    del loaded_model\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    # optimizer threshold on validation set\n",
    "    threshold = optimize_threshold( yval, valpredictions )\n",
    "\n",
    "    # save accuracy, precision, recall, f1 and confusion matrices\n",
    "    vallabels = ( valpredictions >= threshold ).astype( 'int32' )\n",
    "    testlabels = ( testpredictions >= threshold ).astype( 'int32' )\n",
    "\n",
    "    testaccuracy.append( accuracy_score( ytest, testlabels ) )\n",
    "    testprecision.append( precision_score( ytest, testlabels ) )\n",
    "    testrecall.append( recall_score( ytest, testlabels ) )\n",
    "    testf1.append( f1_score( ytest, testlabels ) )\n",
    "    testcm.append( confusion_matrix( ytest, testlabels ) )\n",
    "    reports.append(classification_report( ytest, testlabels, output_dict=True, zero_division=0, target_names=['UNT 0', 'TIN 1']))\n",
    "\n",
    "    print( 'Fold: {:02d} out of {:02d} completed.'.format( fold, skf.get_n_splits() ) )\n",
    "    print( 'Local System Time: {}'.format( time.strftime( \"%I:%M %p\", time.localtime() ) ) )\n",
    "\n",
    "    fold = fold + 1\n",
    "time_took = time.time() - start_time\n",
    "print( f\"Total runtime: { hms_string( time_took ) }\" )\n",
    "WriteResutls(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLnGNQ44tsVg",
    "outputId": "8f5021b6-31d2-4862-daa9-14819ae5d792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words in Pretrained Embeddings:  1154697\n",
      "Pretrained Embeddings mean: -0.0023497287  std:  0.08804372\n"
     ]
    }
   ],
   "source": [
    "modelname = 'MCBiGRU-ft'\n",
    "modelpath = './Saved Models/' + modelname + '/'\n",
    "modelresults = './Model Results'\n",
    "modelsummaries = './Model - Summaries-Figures'\n",
    "DIRECTORIES_TO_BE_CREATED = [ modelpath, modelresults, modelsummaries ]\n",
    "for directory in DIRECTORIES_TO_BE_CREATED:\n",
    "    if not os.path.exists( directory ): os.makedirs( directory )\n",
    "# hyper parameters for this model\n",
    "MAX_LEN = 128\n",
    "EMBED_SIZE = 300\n",
    "EMBED_TRAINABLE = False\n",
    "\n",
    "EMB_WEIGHTS_INIT = 'he_normal'\n",
    "DRPT = 0.4\n",
    "CONV_WEIGHTS_INIT = 'he_uniform'\n",
    "CONV_ACT = 'elu'\n",
    "FC_WEIGHTS_INIT = 'he_uniform'\n",
    "FC_ACT = 'elu'\n",
    "LR_RATE = 1e-3\n",
    "OPTIMIZER = 'adam'\n",
    "\n",
    "BATCH = 32\n",
    "NEPOCHS = 30\n",
    "PATIENCE = 5\n",
    "DECAY = True\n",
    "DECAY_RATE = 0.3\n",
    "DECAY_AFTER = 1\n",
    "\n",
    "if PRE_TRAINED_FLAG == True:\n",
    "    EMBEDDINGS_INDEX = dict( get_coefs( *o.strip().split() ) for o in open( EMBEDDING_FILE, encoding='utf-8' )  if len(o)>19 )\n",
    "    print( 'Total Words in Pretrained Embeddings: ', len( EMBEDDINGS_INDEX.values() ) )\n",
    "    all_embs = np.stack( list(EMBEDDINGS_INDEX.values()) )\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    print( 'Pretrained Embeddings mean:', emb_mean, ' std: ', emb_std )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EL-SRntutsVj",
    "outputId": "1fb59c3e-bce0-458c-9521-62edd8528843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local System Time: 12:13 PM\n",
      "StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
      "2025-05-23 12:13:26\n",
      "Pretrained Embeddings: 14041 hits (4664 misses)\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">+----------------------------------------------------------------------------------------------------------+\n",
       "|<span style=\"font-weight: bold\"> Layer (type)                  </span>|<span style=\"font-weight: bold\"> Output Shape              </span>|<span style=\"font-weight: bold\">         Param # </span>|<span style=\"font-weight: bold\"> Connected to               </span>|\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | -                          |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)          |       <span style=\"color: #00af00; text-decoration-color: #00af00\">5,611,800</span> | input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          |          <span style=\"color: #00af00; text-decoration-color: #00af00\">38,528</span> | embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          |          <span style=\"color: #00af00; text-decoration-color: #00af00\">76,928</span> | embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          |         <span style=\"color: #00af00; text-decoration-color: #00af00\">115,328</span> | embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          |         <span style=\"color: #00af00; text-decoration-color: #00af00\">192,128</span> | embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">123</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          |         <span style=\"color: #00af00; text-decoration-color: #00af00\">230,528</span> | embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">124</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">123</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)          |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| max_pooling1d_1               | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            |\n",
       "| (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| max_pooling1d_2               | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            |\n",
       "| (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| max_pooling1d_3               | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            |\n",
       "| (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| max_pooling1d_4               | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            |\n",
       "| (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)                |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)               |         <span style=\"color: #00af00; text-decoration-color: #00af00\">396,000</span> | max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| bidirectional_1               | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)               |         <span style=\"color: #00af00; text-decoration-color: #00af00\">396,000</span> | max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      |\n",
       "| (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)               |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| bidirectional_2               | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)               |         <span style=\"color: #00af00; text-decoration-color: #00af00\">396,000</span> | max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      |\n",
       "| (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)               |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| bidirectional_3               | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)               |         <span style=\"color: #00af00; text-decoration-color: #00af00\">396,000</span> | max_pooling1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      |\n",
       "| (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)               |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| bidirectional_4               | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)               |         <span style=\"color: #00af00; text-decoration-color: #00af00\">396,000</span> | max_pooling1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      |\n",
       "| (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)               |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)               |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)               |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)               |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)               |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)               |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | bidirectional_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)              |               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> | dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           |\n",
       "|                               |                           |                 | dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           |\n",
       "|                               |                           |                 | dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           |\n",
       "|                               |                           |                 | dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           |\n",
       "|                               |                           |                 | dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)              |       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,002,000</span> | concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| batch_normalization           | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)              |           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,000</span> | dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                |\n",
       "| (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               | (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 |           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,001</span> | batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  |\n",
       "+----------------------------------------------------------------------------------------------------------+\n",
       "</pre>\n"
      ],
      "text/plain": [
       "+----------------------------------------------------------------------------------------------------------+\n",
       "|\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m|\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| input_layer (\u001b[38;5;33mInputLayer\u001b[0m)      | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               |               \u001b[38;5;34m0\u001b[0m | -                          |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| embedding (\u001b[38;5;33mEmbedding\u001b[0m)         | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m300\u001b[0m)          |       \u001b[38;5;34m5,611,800\u001b[0m | input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| conv1d (\u001b[38;5;33mConv1D\u001b[0m)               | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)          |          \u001b[38;5;34m38,528\u001b[0m | embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)             | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m128\u001b[0m)          |          \u001b[38;5;34m76,928\u001b[0m | embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)             | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m128\u001b[0m)          |         \u001b[38;5;34m115,328\u001b[0m | embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)             | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m128\u001b[0m)          |         \u001b[38;5;34m192,128\u001b[0m | embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)             | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m123\u001b[0m, \u001b[38;5;34m128\u001b[0m)          |         \u001b[38;5;34m230,528\u001b[0m | embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout (\u001b[38;5;33mDropout\u001b[0m)             | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)          |               \u001b[38;5;34m0\u001b[0m | conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_2 (\u001b[38;5;33mDropout\u001b[0m)           | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m128\u001b[0m)          |               \u001b[38;5;34m0\u001b[0m | conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_4 (\u001b[38;5;33mDropout\u001b[0m)           | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m128\u001b[0m)          |               \u001b[38;5;34m0\u001b[0m | conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_6 (\u001b[38;5;33mDropout\u001b[0m)           | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m124\u001b[0m, \u001b[38;5;34m128\u001b[0m)          |               \u001b[38;5;34m0\u001b[0m | conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_8 (\u001b[38;5;33mDropout\u001b[0m)           | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m123\u001b[0m, \u001b[38;5;34m128\u001b[0m)          |               \u001b[38;5;34m0\u001b[0m | conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)  | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)           |               \u001b[38;5;34m0\u001b[0m | dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| max_pooling1d_1               | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)           |               \u001b[38;5;34m0\u001b[0m | dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            |\n",
       "| (\u001b[38;5;33mMaxPooling1D\u001b[0m)                |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| max_pooling1d_2               | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)           |               \u001b[38;5;34m0\u001b[0m | dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            |\n",
       "| (\u001b[38;5;33mMaxPooling1D\u001b[0m)                |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| max_pooling1d_3               | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m)           |               \u001b[38;5;34m0\u001b[0m | dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            |\n",
       "| (\u001b[38;5;33mMaxPooling1D\u001b[0m)                |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| max_pooling1d_4               | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           |               \u001b[38;5;34m0\u001b[0m | dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            |\n",
       "| (\u001b[38;5;33mMaxPooling1D\u001b[0m)                |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| bidirectional (\u001b[38;5;33mBidirectional\u001b[0m) | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)               |         \u001b[38;5;34m396,000\u001b[0m | max_pooling1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| bidirectional_1               | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)               |         \u001b[38;5;34m396,000\u001b[0m | max_pooling1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      |\n",
       "| (\u001b[38;5;33mBidirectional\u001b[0m)               |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| bidirectional_2               | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)               |         \u001b[38;5;34m396,000\u001b[0m | max_pooling1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      |\n",
       "| (\u001b[38;5;33mBidirectional\u001b[0m)               |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| bidirectional_3               | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)               |         \u001b[38;5;34m396,000\u001b[0m | max_pooling1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      |\n",
       "| (\u001b[38;5;33mBidirectional\u001b[0m)               |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| bidirectional_4               | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)               |         \u001b[38;5;34m396,000\u001b[0m | max_pooling1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      |\n",
       "| (\u001b[38;5;33mBidirectional\u001b[0m)               |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)               |               \u001b[38;5;34m0\u001b[0m | bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_3 (\u001b[38;5;33mDropout\u001b[0m)           | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)               |               \u001b[38;5;34m0\u001b[0m | bidirectional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_5 (\u001b[38;5;33mDropout\u001b[0m)           | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)               |               \u001b[38;5;34m0\u001b[0m | bidirectional_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_7 (\u001b[38;5;33mDropout\u001b[0m)           | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)               |               \u001b[38;5;34m0\u001b[0m | bidirectional_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dropout_9 (\u001b[38;5;33mDropout\u001b[0m)           | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)               |               \u001b[38;5;34m0\u001b[0m | bidirectional_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)              |               \u001b[38;5;34m0\u001b[0m | dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           |\n",
       "|                               |                           |                 | dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           |\n",
       "|                               |                           |                 | dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           |\n",
       "|                               |                           |                 | dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           |\n",
       "|                               |                           |                 | dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dense (\u001b[38;5;33mDense\u001b[0m)                 | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)              |       \u001b[38;5;34m4,002,000\u001b[0m | concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| batch_normalization           | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2000\u001b[0m)              |           \u001b[38;5;34m8,000\u001b[0m | dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                |\n",
       "| (\u001b[38;5;33mBatchNormalization\u001b[0m)          |                           |                 |                            |\n",
       "|-------------------------------+---------------------------+-----------------+----------------------------|\n",
       "| dense_1 (\u001b[38;5;33mDense\u001b[0m)               | (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 |           \u001b[38;5;34m2,001\u001b[0m | batch_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  |\n",
       "+----------------------------------------------------------------------------------------------------------+\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,257,241</span> (46.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,257,241\u001b[0m (46.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,641,441</span> (25.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,641,441\u001b[0m (25.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,615,800</span> (21.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,615,800\u001b[0m (21.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 --LR: 1e-03 --MaxValF1: 0.8673139 --CurValF1: 0.8673139 --Patience: 01 --F1 improved: 0.8673139\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002 --LR: 1e-03 --MaxValF1: 0.8685776 --CurValF1: 0.8685776 --Patience: 01 --F1 improved: 0.8685776\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step\n",
      "Epoch: 003 --LR: 1e-03 --MaxValF1: 0.8685776 --CurValF1: 0.8654781 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step\n",
      "Epoch: 004 --LR: 3e-04 --MaxValF1: 0.8685776 --CurValF1: 0.8668464 --Patience: 02\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step\n",
      "Epoch: 005 --LR: 9e-05 --MaxValF1: 0.8685776 --CurValF1: 0.8681081 --Patience: 03\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step\n",
      "Epoch: 006 --LR: 3e-05 --MaxValF1: 0.8685776 --CurValF1: 0.8668831 --Patience: 04\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step\n",
      "Epoch: 007 --LR: 8e-06 --MaxValF1: 0.8685776 --CurValF1: 0.8671706 --Patience: 05\n",
      "Training stopped due to the patience parameter. --Patience: 05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 01 out of 05 completed.\n",
      "Local System Time: 12:20 PM\n",
      "2025-05-23 12:20:14\n",
      "Pretrained Embeddings: 14132 hits (4675 misses)\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 --LR: 1e-03 --MaxValF1: 0.8531547 --CurValF1: 0.8531547 --Patience: 01 --F1 improved: 0.8531547\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step\n",
      "Epoch: 002 --LR: 1e-03 --MaxValF1: 0.8531547 --CurValF1: 0.8519934 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step\n",
      "Epoch: 003 --LR: 3e-04 --MaxValF1: 0.8531547 --CurValF1: 0.8529251 --Patience: 02\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step\n",
      "Epoch: 004 --LR: 9e-05 --MaxValF1: 0.8531547 --CurValF1: 0.8529412 --Patience: 03\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005 --LR: 3e-05 --MaxValF1: 0.8535179 --CurValF1: 0.8535179 --Patience: 04 --F1 improved: 0.8535179\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step\n",
      "Epoch: 006 --LR: 3e-05 --MaxValF1: 0.8535179 --CurValF1: 0.8529251 --Patience: 01\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007 --LR: 8e-06 --MaxValF1: 0.8538813 --CurValF1: 0.8538813 --Patience: 02 --F1 improved: 0.8538813\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# train the model with callbacks for early stopping\u001b[39;00m\n\u001b[32m     67\u001b[39m f1callback = F1_score_callback(val_data=( xval, yval ), filepath=filepath,\n\u001b[32m     68\u001b[39m     patience=PATIENCE, decay=DECAY, decay_rate=DECAY_RATE, decay_after=DECAY_AFTER)\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m histmodel = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43mf1callback\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# save history of all folds\u001b[39;00m\n\u001b[32m     72\u001b[39m hist[ \u001b[33m'\u001b[39m\u001b[33mfold\u001b[39m\u001b[33m'\u001b[39m + \u001b[38;5;28mstr\u001b[39m( fold ) ] = histmodel.history.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Execute this cell\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "start_time = time.time()\n",
    "print( 'Local System Time: {}'.format( time.strftime( \"%I:%M %p\", time.localtime() ) ) )\n",
    "\n",
    "valaccuracy, valprecision, valrecall, valf1, valcm = [], [], [], [], []\n",
    "testaccuracy, testprecision, testrecall, testf1, testcm = [], [], [], [], []\n",
    "com_text, com_label, com_predicted, com_prob = [], [], [], []\n",
    "com_indices = []\n",
    "hist = {}\n",
    "reports = []\n",
    "\n",
    "skf = StratifiedKFold( n_splits=5, random_state=0, shuffle=True )\n",
    "print(skf)\n",
    "fold = 1\n",
    "for train_index, test_index in skf.split( df[ xcolumn ], df[ ycolumn ] ):\n",
    "    # seprating train and test sets\n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    xtrain = df.loc[ train_index ][ xcolumn ].values\n",
    "    xtest = df.loc[ test_index ][ xcolumn ].values\n",
    "\n",
    "    ytrain = df.loc[ train_index ][ ycolumn ].values\n",
    "    ytest = df.loc[ test_index ][ ycolumn ].values\n",
    "\n",
    "    # splitting train and validation sets\n",
    "    xtrain, xval, ytrain, yval = train_test_split( xtrain, ytrain, test_size=0.15, random_state=0 )\n",
    "\n",
    "    # tokenization with keras tokenizer\n",
    "    tokenizer = text.Tokenizer(  )\n",
    "    tokenizer.fit_on_texts( np.append( xtrain, xval ) )\n",
    "\n",
    "    xtrain = tokenizer.texts_to_sequences( xtrain )\n",
    "    xval = tokenizer.texts_to_sequences( xval )\n",
    "    xtest = tokenizer.texts_to_sequences( xtest )\n",
    "\n",
    "    # pad the tokenized sequences\n",
    "    xtrain = sequence.pad_sequences( xtrain, maxlen=MAX_LEN )\n",
    "    xval = sequence.pad_sequences( xval, maxlen=MAX_LEN )\n",
    "    xtest = sequence.pad_sequences( xtest, maxlen=MAX_LEN )\n",
    "\n",
    "    # check if pre-trained word embeddings flag is true\n",
    "    if PRE_TRAINED_FLAG == True:\n",
    "        EMBEDDING_MATRIX = get_vectors(\n",
    "            tokenizer=tokenizer, emb_mean=emb_mean, emb_std=emb_std, embed_size=EMBED_SIZE\n",
    "        )\n",
    "\n",
    "    # define a model\n",
    "    EMBED_INP_SIZE = len( tokenizer.word_index ) + 1\n",
    "    model = MCBiGRU(max_len=MAX_LEN, embed_inp=EMBED_INP_SIZE, embed_size=EMBED_SIZE,\n",
    "        embedding_matrix=EMBEDDING_MATRIX, embed_trainable=EMBED_TRAINABLE, drpt=DRPT, emb_weights_init=EMB_WEIGHTS_INIT,\n",
    "        conv_weights_init=CONV_WEIGHTS_INIT, conv_act=CONV_ACT,fc_weights_init=FC_WEIGHTS_INIT, fc_act=FC_ACT, optimizer=OPTIMIZER )\n",
    "\n",
    "    # save model summaries and model architecture diagrams in the first fold only\n",
    "    if fold == 1:\n",
    "        plot_model( model=model, to_file='{}/{}.png'.format( modelsummaries, modelname ), show_shapes=False )\n",
    "\n",
    "        with open( '{}/{}.txt'.format( modelsummaries, modelname ), 'w' ) as s:\n",
    "            with redirect_stdout( s ):model.summary()\n",
    "\n",
    "    if isinstance(model.optimizer.learning_rate, tf.Variable):\n",
    "      K.set_value(model.optimizer.learning_rate, LR_RATE)\n",
    "    else:\n",
    "      model.optimizer.learning_rate = LR_RATE\n",
    "    filepath = modelpath + modelname + str( fold ) + \".h5\"\n",
    "\n",
    "    # train the model with callbacks for early stopping\n",
    "    f1callback = F1_score_callback(val_data=( xval, yval ), filepath=filepath,\n",
    "        patience=PATIENCE, decay=DECAY, decay_rate=DECAY_RATE, decay_after=DECAY_AFTER)\n",
    "    histmodel = model.fit(xtrain, ytrain, batch_size=BATCH, epochs=NEPOCHS, verbose=0, callbacks=[ f1callback ] )\n",
    "\n",
    "    # save history of all folds\n",
    "    hist[ 'fold' + str( fold ) ] = histmodel.history.copy()\n",
    "\n",
    "    # delete trained model object\n",
    "    del model, histmodel, f1callback\n",
    "    EMBEDDING_MATRIX = []\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    # delete pre trained embeddings from the memory\n",
    "    if ( PRE_TRAINED_FLAG == True ) and ( fold == skf.n_splits ):\n",
    "        del EMBEDDINGS_INDEX\n",
    "        gc.collect()\n",
    "\n",
    "    # load saved model\n",
    "    loaded_model = load_model( filepath )\n",
    "\n",
    "    # get predictions (probabilities) for validation and test sets respectively\n",
    "    valpredictions = loaded_model.predict( xval, verbose=0, batch_size=BATCH )\n",
    "    testpredictions = loaded_model.predict( xtest, verbose=0, batch_size=BATCH )\n",
    "\n",
    "    # delete loaded model\n",
    "    del loaded_model\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    # optimizer threshold on validation set\n",
    "    threshold = optimize_threshold( yval, valpredictions )\n",
    "\n",
    "    # save accuracy, precision, recall, f1 and confusion matrices\n",
    "    vallabels = ( valpredictions >= threshold ).astype( 'int32' )\n",
    "    testlabels = ( testpredictions >= threshold ).astype( 'int32' )\n",
    "\n",
    "    valaccuracy.append( accuracy_score( yval, vallabels ) )\n",
    "    valprecision.append( precision_score( yval, vallabels ) )\n",
    "    valrecall.append( recall_score( yval, vallabels ) )\n",
    "    valf1.append( f1_score( yval, vallabels ) )\n",
    "    valcm.append( confusion_matrix( yval, vallabels ) )\n",
    "\n",
    "    testaccuracy.append( accuracy_score( ytest, testlabels ) )\n",
    "    testprecision.append( precision_score( ytest, testlabels ) )\n",
    "    testrecall.append( recall_score( ytest, testlabels ) )\n",
    "    testf1.append( f1_score( ytest, testlabels ) )\n",
    "    testcm.append( confusion_matrix( ytest, testlabels ) )\n",
    "    reports.append(classification_report( ytest, testlabels, output_dict=True, zero_division=0, target_names=['UNT 0', 'TIN 1']))\n",
    "\n",
    "\n",
    "    print( 'Fold: {:02d} out of {:02d} completed.'.format( fold, skf.get_n_splits() ) )\n",
    "    print( 'Local System Time: {}'.format( time.strftime( \"%I:%M %p\", time.localtime() ) ) )\n",
    "\n",
    "    fold = fold + 1\n",
    "time_took = time.time() - start_time\n",
    "print( f\"Total runtime: { hms_string( time_took ) }\" )\n",
    "WriteResutls(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhIQqAZglOfX"
   },
   "outputs": [],
   "source": [
    "# hyper parameters for this model\n",
    "MAX_LEN = 100\n",
    "EMBED_SIZE = 300\n",
    "EMBED_TRAINABLE = False\n",
    "EMB_WEIGHTS_INIT = 'he_normal'\n",
    "SPDRPT = 0.3\n",
    "DRPT = 0.1\n",
    "CONV_WEIGHTS_INIT = 'he_uniform'\n",
    "CONV_ACT = 'elu'\n",
    "FC_WEIGHTS_INIT = 'he_uniform'\n",
    "FC_ACT = 'elu'\n",
    "LR_RATE = 1e-3\n",
    "OPTIMIZER = 'adam'\n",
    "BATCH = 32\n",
    "NEPOCHS = 30\n",
    "PATIENCE = 5\n",
    "DECAY = True\n",
    "DECAY_RATE = 0.3\n",
    "DECAY_AFTER = 1\n",
    "\n",
    "modelname = 'CNN_RUT-ft'\n",
    "modelpath = './Saved Models/{}/'.format( modelname )\n",
    "modelresults = './Model Results'\n",
    "modelsummaries = './Model - Summaries-Figures'\n",
    "DIRECTORIES_TO_BE_CREATED = [ modelpath, modelresults, modelsummaries ]\n",
    "for directory in DIRECTORIES_TO_BE_CREATED:\n",
    "    if not os.path.exists( directory ):os.makedirs( directory )\n",
    "\n",
    "if PRE_TRAINED_FLAG == True:\n",
    "    EMBEDDINGS_INDEX = dict( get_coefs( *o.strip().split() ) for o in open( EMBEDDING_FILE, encoding='utf-8' )  if len(o)>19 )\n",
    "    print( 'Total Words in Pretrained Embeddings: ', len( EMBEDDINGS_INDEX.values() ) )\n",
    "    all_embs = np.stack( list(EMBEDDINGS_INDEX.values()) )\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    print( 'Pretrained Embeddings mean:', emb_mean, ' std: ', emb_std )\n",
    "\n",
    "def CNN_RUT(\n",
    "    max_len=100, embed_inp=10000, embed_size=300, embedding_matrix=[], embed_trainable=False,\n",
    "    spdrpt=.1, drpt=.1, emb_weights_init='', conv_weights_init='', conv_act='', fc_weights_init='',\n",
    "    fc_act='', optimizer='' ):\n",
    "\n",
    "    filter_sizes = [ 1,2,3,4,5 ]\n",
    "    num_filters = 32\n",
    "\n",
    "    inp = Input( shape=( max_len, ) )\n",
    "    if embedding_matrix is None:\n",
    "        x = Embedding( input_dim=embed_inp, output_dim=embed_size,\n",
    "                      embeddings_initializer=emb_weights_init, trainable=embed_trainable )( inp )\n",
    "    else:\n",
    "        x = Embedding( input_dim=embed_inp, output_dim=embed_size,\n",
    "                      weights=[ embedding_matrix ], trainable=embed_trainable )( inp )\n",
    "\n",
    "    x = SpatialDropout1D( spdrpt )( x )\n",
    "    x = Reshape( ( max_len, embed_size, 1 ) )( x )\n",
    "    pooled = [  ]\n",
    "    for j,i in enumerate( filter_sizes ):\n",
    "        conv = Conv2D( num_filters, kernel_size=( i, embed_size ), activation=conv_act )( x )\n",
    "        globalmax = GlobalMaxPooling2D(  )( conv )\n",
    "        pooled.append( globalmax )\n",
    "    z = Concatenate( axis=1 )( pooled )\n",
    "    z = Dropout( drpt )( z )\n",
    "    fc1 = Dense( 100, activation=fc_act, kernel_initializer=fc_weights_init )( z )\n",
    "    fc2 = Dense( 50, activation=fc_act, kernel_initializer=fc_weights_init )( fc1 )\n",
    "    outp = Dense( 1, activation='sigmoid' )( fc2 )\n",
    "\n",
    "    model = Model( inputs=inp, outputs=outp )\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYYwuWG5lWNf"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings( 'ignore' )\n",
    "start_time = time.time()\n",
    "print( 'Local System Time: {}'.format( time.strftime( \"%I:%M %p\", time.localtime() ) ) )\n",
    "\n",
    "valaccuracy, valprecision, valrecall, valf1, valcm = [], [], [], [], []\n",
    "testaccuracy, testprecision, testrecall, testf1, testcm = [], [], [], [], []\n",
    "com_text, com_label, com_predicted, com_prob = [], [], [], []\n",
    "reports = []\n",
    "hist = {}\n",
    "skf = StratifiedKFold( n_splits=5, random_state=0, shuffle=True )\n",
    "print(skf)\n",
    "fold = 1\n",
    "for train_index, test_index in skf.split( df[ xcolumn ], df[ ycolumn ] ):\n",
    "    # seprating train and test sets\n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    xtrain = df.loc[ train_index ][ xcolumn ].values\n",
    "    xtest = df.loc[ test_index ][ xcolumn ].values\n",
    "\n",
    "    ytrain = df.loc[ train_index ][ ycolumn ].values\n",
    "    ytest = df.loc[ test_index ][ ycolumn ].values\n",
    "\n",
    "    # splitting train and validation sets\n",
    "    xtrain, xval, ytrain, yval = train_test_split( xtrain, ytrain, test_size=0.15, random_state=0 )\n",
    "\n",
    "    # tokenization with keras tokenizer\n",
    "    tokenizer = text.Tokenizer(  )\n",
    "    tokenizer.fit_on_texts( np.append( xtrain, xval ) )\n",
    "\n",
    "    xtrain = tokenizer.texts_to_sequences( xtrain )\n",
    "    xval = tokenizer.texts_to_sequences( xval )\n",
    "    xtest = tokenizer.texts_to_sequences( xtest )\n",
    "\n",
    "    # pad the tokenized sequences\n",
    "    xtrain = sequence.pad_sequences( xtrain, maxlen=MAX_LEN )\n",
    "    xval = sequence.pad_sequences( xval, maxlen=MAX_LEN )\n",
    "    xtest = sequence.pad_sequences( xtest, maxlen=MAX_LEN )\n",
    "\n",
    "    # check if pre-trained word embeddings flag is true\n",
    "    if PRE_TRAINED_FLAG == True:\n",
    "        EMBEDDING_MATRIX = get_vectors(tokenizer=tokenizer, emb_mean=emb_mean, emb_std=emb_std, embed_size=EMBED_SIZE)\n",
    "\n",
    "    # define a model\n",
    "    EMBED_INP_SIZE = len( tokenizer.word_index ) + 1\n",
    "    model = CNN_RUT(max_len=MAX_LEN, embed_inp=EMBED_INP_SIZE, embed_size=EMBED_SIZE,\n",
    "        embedding_matrix=EMBEDDING_MATRIX, embed_trainable=EMBED_TRAINABLE, spdrpt=SPDRPT,\n",
    "        drpt=DRPT, emb_weights_init=EMB_WEIGHTS_INIT, conv_weights_init=CONV_WEIGHTS_INIT,\n",
    "        conv_act=CONV_ACT, fc_weights_init=FC_WEIGHTS_INIT, fc_act=FC_ACT, optimizer=OPTIMIZER     )\n",
    "\n",
    "    # save model summaries and model architecture diagrams in the first fold only\n",
    "    if fold == 1:\n",
    "        #plot_model( model=model, to_file='{}/{}.png'.format( modelsummaries, modelname ), show_shapes=False )\n",
    "\n",
    "        with open( '{}/{}.txt'.format( modelsummaries, modelname ), 'w' ) as s:\n",
    "            with redirect_stdout( s ):model.summary()\n",
    "\n",
    "    if isinstance(model.optimizer.learning_rate, tf.Variable):\n",
    "      K.set_value(model.optimizer.learning_rate, LR_RATE)\n",
    "    else:\n",
    "      model.optimizer.learning_rate = LR_RATE\n",
    "    modelpath = modelpath + modelname + str( fold ) + \".keras\"\n",
    "\n",
    "    # train the model with callbacks for early stopping\n",
    "    f1callback = F1_score_callback(\n",
    "        val_data=( xval, yval ), filepath=modelpath,\n",
    "        patience=PATIENCE, decay=DECAY, decay_rate=DECAY_RATE, decay_after=DECAY_AFTER\n",
    "    )\n",
    "    histmodel = model.fit(\n",
    "        xtrain, ytrain, batch_size=BATCH, epochs=NEPOCHS, verbose=0, callbacks=[ f1callback ]\n",
    "    )\n",
    "\n",
    "    # save history of all folds\n",
    "    hist[ 'fold' + str( fold ) ] = histmodel.history.copy()\n",
    "\n",
    "    # delete trained model object\n",
    "    del model, histmodel, f1callback\n",
    "    EMBEDDING_MATRIX = []\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    # delete pre trained embeddings from the memory\n",
    "    if ( PRE_TRAINED_FLAG == True ) and ( fold == skf.n_splits ):\n",
    "        del EMBEDDINGS_INDEX\n",
    "        gc.collect()\n",
    "\n",
    "    # load saved model\n",
    "    loaded_model = load_model( modelpath )\n",
    "\n",
    "    # get predictions (probabilities) for validation and test sets respectively\n",
    "    valpredictions = loaded_model.predict( xval, verbose=0, batch_size=BATCH )\n",
    "    testpredictions = loaded_model.predict( xtest, verbose=0, batch_size=BATCH )\n",
    "\n",
    "    # delete loaded model\n",
    "    del loaded_model\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    # optimizer threshold on validation set\n",
    "    threshold = optimize_threshold( yval, valpredictions )\n",
    "\n",
    "    # save accuracy, precision, recall, f1 and confusion matrices\n",
    "    vallabels = ( valpredictions >= threshold ).astype( 'int32' )\n",
    "    testlabels = ( testpredictions >= threshold ).astype( 'int32' )\n",
    "\n",
    "    valaccuracy.append( accuracy_score( yval, vallabels ) )\n",
    "    valprecision.append( precision_score( yval, vallabels ) )\n",
    "    valrecall.append( recall_score( yval, vallabels ) )\n",
    "    valf1.append( f1_score( yval, vallabels ) )\n",
    "    valcm.append( confusion_matrix( yval, vallabels ) )\n",
    "\n",
    "    testaccuracy.append( accuracy_score( ytest, testlabels ) )\n",
    "    testprecision.append( precision_score( ytest, testlabels ) )\n",
    "    testrecall.append( recall_score( ytest, testlabels ) )\n",
    "    testf1.append( f1_score( ytest, testlabels ) )\n",
    "    testcm.append( confusion_matrix( ytest, testlabels ) )\n",
    "    reports.append(classification_report( ytest, testlabels, output_dict=True, zero_division=0, target_names=['UNT 0', 'TIN 1']))\n",
    "\n",
    "    print( 'Fold: {:02d} out of {:02d} completed.'.format( fold, skf.get_n_splits() ) )\n",
    "    print( 'Local System Time: {}'.format( time.strftime( \"%I:%M %p\", time.localtime() ) ) )\n",
    "\n",
    "    fold = fold + 1\n",
    "time_took = time.time() - start_time\n",
    "print( f\"Total runtime: { hms_string( time_took ) }\" )\n",
    "WriteResutls(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rtl1kQ2qhk-"
   },
   "outputs": [],
   "source": [
    "# hyper parameters for this model\n",
    "\n",
    "MAX_LEN = 128\n",
    "EMBED_SIZE = 300\n",
    "EMBED_TRAINABLE = False\n",
    "EMB_WEIGHTS_INIT = 'he_normal'\n",
    "SPDRPT = 0.4\n",
    "DRPT = 0.2\n",
    "FC_WEIGHTS_INIT = 'he_uniform'\n",
    "FC_ACT = 'elu'\n",
    "LR_RATE = 1e-3\n",
    "OPTIMIZER = 'adam'\n",
    "GRU_UNITS = 100\n",
    "BATCH = 32\n",
    "NEPOCHS = 30\n",
    "PATIENCE = 5\n",
    "DECAY = True\n",
    "DECAY_RATE = 0.3\n",
    "DECAY_AFTER = 1\n",
    "\n",
    "modelname = 'BGRU-ft'\n",
    "modelpath = './Saved Models/' + modelname + '/'\n",
    "modelresults = './Model Results'\n",
    "modelsummaries = './Model - Summaries-Figures'\n",
    "DIRECTORIES_TO_BE_CREATED = [ modelpath, modelresults, modelsummaries ]\n",
    "for directory in DIRECTORIES_TO_BE_CREATED:\n",
    "    if not os.path.exists( directory ):os.makedirs( directory )\n",
    "\n",
    "if PRE_TRAINED_FLAG == True:\n",
    "    EMBEDDINGS_INDEX = dict( get_coefs( *o.strip().split() ) for o in open( EMBEDDING_FILE, encoding='utf-8' )  if len(o)>19 )\n",
    "    print( 'Total Words in Pretrained Embeddings: ', len( EMBEDDINGS_INDEX.values() ) )\n",
    "    all_embs = np.stack( list(EMBEDDINGS_INDEX.values()) )\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    print( 'Pretrained Embeddings mean:', emb_mean, ' std: ', emb_std )\n",
    "\n",
    "def BGRU(\n",
    "    max_len=100, embed_inp=10000, embed_size=300, embedding_matrix=[], embed_trainable=False,\n",
    "    spdrpt=.1, drpt=.1, emb_weights_init='', fc_weights_init='', fc_act='', optimizer='', gru_units=32 ):\n",
    "\n",
    "    inp = Input( shape=( max_len, ) )\n",
    "    if embedding_matrix is None:\n",
    "        x = Embedding( input_dim=embed_inp, output_dim=embed_size,\n",
    "                      embeddings_initializer=emb_weights_init, trainable=embed_trainable )( inp )\n",
    "    else:\n",
    "        x = Embedding( input_dim=embed_inp, output_dim=embed_size,\n",
    "                      weights=[ embedding_matrix ], trainable=embed_trainable )( inp )\n",
    "\n",
    "    x = SpatialDropout1D( spdrpt )( x )\n",
    "    z = Bidirectional( GRU( gru_units ) )( x )\n",
    "    z = Dropout( drpt )( z )\n",
    "    fc1 = Dense( 100, activation=fc_act, kernel_initializer=fc_weights_init )( z )\n",
    "    fc2 = Dense( 50, activation=fc_act, kernel_initializer=fc_weights_init )( fc1 )\n",
    "    output = Dense( 1, activation='sigmoid' )( fc2 )\n",
    "    model = Model( inputs=inp, outputs=output )\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcSV9Caxqlys"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings( 'ignore' )\n",
    "start_time = time.time()\n",
    "print( 'Local System Time: {}'.format( time.strftime( \"%I:%M %p\", time.localtime() ) ) )\n",
    "\n",
    "valaccuracy, valprecision, valrecall, valf1, valcm = [], [], [], [], []\n",
    "testaccuracy, testprecision, testrecall, testf1, testcm = [], [], [], [], []\n",
    "com_text, com_label, com_predicted, com_prob = [], [], [], []\n",
    "com_indices = []\n",
    "hist = {}\n",
    "reports = []\n",
    "skf = StratifiedKFold( n_splits=5, random_state=0, shuffle=True )\n",
    "print(skf)\n",
    "fold = 1\n",
    "for train_index, test_index in skf.split( df[ xcolumn ], df[ ycolumn ] ):\n",
    "    # seprating train and test sets\n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    xtrain = df.loc[ train_index ][ xcolumn ].values\n",
    "    xtest = df.loc[ test_index ][ xcolumn ].values\n",
    "\n",
    "    ytrain = df.loc[ train_index ][ ycolumn ].values\n",
    "    ytest = df.loc[ test_index ][ ycolumn ].values\n",
    "\n",
    "    # splitting train and validation sets\n",
    "    xtrain, xval, ytrain, yval = train_test_split( xtrain, ytrain, test_size=0.15, random_state=0 )\n",
    "\n",
    "    # tokenization with keras tokenizer\n",
    "    tokenizer = text.Tokenizer(  )\n",
    "    tokenizer.fit_on_texts( np.append( xtrain, xval ) )\n",
    "\n",
    "    xtrain = tokenizer.texts_to_sequences( xtrain )\n",
    "    xval = tokenizer.texts_to_sequences( xval )\n",
    "    xtest = tokenizer.texts_to_sequences( xtest )\n",
    "\n",
    "    # pad the tokenized sequences\n",
    "    xtrain = sequence.pad_sequences( xtrain, maxlen=MAX_LEN )\n",
    "    xval = sequence.pad_sequences( xval, maxlen=MAX_LEN )\n",
    "    xtest = sequence.pad_sequences( xtest, maxlen=MAX_LEN )\n",
    "\n",
    "    # check if pre-trained word embeddings flag is true\n",
    "    if PRE_TRAINED_FLAG == True:\n",
    "        EMBEDDING_MATRIX = get_vectors(tokenizer=tokenizer, emb_mean=emb_mean, emb_std=emb_std, embed_size=EMBED_SIZE)\n",
    "\n",
    "    # define a model\n",
    "    EMBED_INP_SIZE = len( tokenizer.word_index ) + 1\n",
    "    model = BGRU( max_len=MAX_LEN, embed_inp=EMBED_INP_SIZE, embed_size=EMBED_SIZE,\n",
    "        embedding_matrix=EMBEDDING_MATRIX, embed_trainable=EMBED_TRAINABLE, spdrpt=SPDRPT, drpt=DRPT, emb_weights_init=EMB_WEIGHTS_INIT,\n",
    "        fc_weights_init=FC_WEIGHTS_INIT, fc_act=FC_ACT, optimizer=OPTIMIZER, gru_units=GRU_UNITS )\n",
    "\n",
    "    # save model summaries and model architecture diagrams in the first fold only\n",
    "    if fold == 1:\n",
    "        plot_model( model=model, to_file='{}/{}.png'.format( modelsummaries, modelname ), show_shapes=False )\n",
    "\n",
    "        with open( '{}/{}.txt'.format( modelsummaries, modelname ), 'w' ) as s:\n",
    "            with redirect_stdout( s ): model.summary()\n",
    "\n",
    "    if isinstance(model.optimizer.learning_rate, tf.Variable):\n",
    "      K.set_value(model.optimizer.learning_rate, LR_RATE)\n",
    "    else:\n",
    "      model.optimizer.learning_rate = LR_RATE\n",
    "    modelpath = modelpath + modelname + str( fold ) + \".keras\"\n",
    "    # train the model with callbacks for early stopping\n",
    "    f1callback = F1_score_callback( val_data=( xval, yval ), filepath=modelpath,\n",
    "        patience=PATIENCE, decay=DECAY, decay_rate=DECAY_RATE, decay_after=DECAY_AFTER  )\n",
    "    histmodel = model.fit( xtrain, ytrain, batch_size=BATCH, epochs=NEPOCHS, verbose=0, callbacks=[ f1callback ] )\n",
    "\n",
    "    # save history of all folds\n",
    "    hist[ 'fold' + str( fold ) ] = histmodel.history.copy()\n",
    "\n",
    "    # delete trained model object\n",
    "    del model, histmodel, f1callback\n",
    "    EMBEDDING_MATRIX = []\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    # delete pre trained embeddings from the memory\n",
    "    if ( PRE_TRAINED_FLAG == True ) and ( fold == skf.n_splits ):\n",
    "        del EMBEDDINGS_INDEX\n",
    "        gc.collect()\n",
    "\n",
    "    # load saved model\n",
    "    loaded_model = load_model( modelpath )\n",
    "\n",
    "    # get predictions (probabilities) for validation and test sets respectively\n",
    "    valpredictions = loaded_model.predict( xval, verbose=0, batch_size=BATCH )\n",
    "    testpredictions = loaded_model.predict( xtest, verbose=0, batch_size=BATCH )\n",
    "\n",
    "    # delete loaded model\n",
    "    del loaded_model\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    # optimizer threshold on validation set\n",
    "    threshold = optimize_threshold( yval, valpredictions )\n",
    "\n",
    "    # save accuracy, precision, recall, f1 and confusion matrices\n",
    "    vallabels = ( valpredictions >= threshold ).astype( 'int32' )\n",
    "    testlabels = ( testpredictions >= threshold ).astype( 'int32' )\n",
    "\n",
    "    valaccuracy.append( accuracy_score( yval, vallabels ) )\n",
    "    valprecision.append( precision_score( yval, vallabels ) )\n",
    "    valrecall.append( recall_score( yval, vallabels ) )\n",
    "    valf1.append( f1_score( yval, vallabels ) )\n",
    "    valcm.append( confusion_matrix( yval, vallabels ) )\n",
    "\n",
    "    testaccuracy.append( accuracy_score( ytest, testlabels ) )\n",
    "    testprecision.append( precision_score( ytest, testlabels ) )\n",
    "    testrecall.append( recall_score( ytest, testlabels ) )\n",
    "    testf1.append( f1_score( ytest, testlabels ) )\n",
    "    testcm.append( confusion_matrix( ytest, testlabels ) )\n",
    "    reports.append(classification_report( ytest, testlabels, output_dict=True, zero_division=0, target_names=['UNT 0', 'TIN 1']))\n",
    "    print( 'Fold: {:02d} out of {:02d} completed.'.format( fold, skf.get_n_splits() ) )\n",
    "    print( 'Local System Time: {}'.format( time.strftime( \"%I:%M %p\", time.localtime() ) ) )\n",
    "\n",
    "    fold = fold + 1\n",
    "time_took = time.time() - start_time\n",
    "print( f\"Total runtime: { hms_string( time_took ) }\" )\n",
    "WriteResutls(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PaD8B7j_rCTT"
   },
   "outputs": [],
   "source": [
    "# hyper parameters for this model\n",
    "\n",
    "MAX_LEN = 128\n",
    "EMBED_SIZE = 300\n",
    "EMBED_TRAINABLE = False\n",
    "EMB_WEIGHTS_INIT = 'he_normal'\n",
    "SPDRPT = 0.4\n",
    "DRPT = 0.2\n",
    "FC_WEIGHTS_INIT = 'he_uniform'\n",
    "FC_ACT = 'elu'\n",
    "LR_RATE = 1e-3\n",
    "OPTIMIZER = 'adam'\n",
    "LSTM_UNITS = 100\n",
    "BATCH = 32\n",
    "NEPOCHS = 30\n",
    "PATIENCE = 5\n",
    "DECAY = True\n",
    "DECAY_RATE = 0.3\n",
    "DECAY_AFTER = 1\n",
    "\n",
    "modelname = 'BLSTM-ft'\n",
    "modelpath = './Saved Models/' + modelname + '/'\n",
    "modelresults = './Model Results'\n",
    "modelsummaries = './Model - Summaries-Figures'\n",
    "DIRECTORIES_TO_BE_CREATED = [ modelpath, modelresults, modelsummaries ]\n",
    "for directory in DIRECTORIES_TO_BE_CREATED:\n",
    "    if not os.path.exists( directory ): os.makedirs( directory )\n",
    "\n",
    "if PRE_TRAINED_FLAG == True:\n",
    "    EMBEDDINGS_INDEX = dict( get_coefs( *o.strip().split() ) for o in open( EMBEDDING_FILE, encoding='utf-8' )  if len(o)>19 )\n",
    "    print( 'Total Words in Pretrained Embeddings: ', len( EMBEDDINGS_INDEX.values() ) )\n",
    "    all_embs = np.stack( list(EMBEDDINGS_INDEX.values()) )\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    print( 'Pretrained Embeddings mean:', emb_mean, ' std: ', emb_std )\n",
    "\n",
    "def BLSTM(\n",
    "    max_len=100, embed_inp=10000, embed_size=300, embedding_matrix=[], embed_trainable=False,\n",
    "    spdrpt=.1, drpt=.1, emb_weights_init='', fc_weights_init='', fc_act='', optimizer='', lstm_units=32 ):\n",
    "\n",
    "    inp = Input( shape=( max_len, ) )\n",
    "    if embedding_matrix is None:\n",
    "        x = Embedding( input_dim=embed_inp, output_dim=embed_size,\n",
    "                      embeddings_initializer=emb_weights_init, trainable=embed_trainable )( inp )\n",
    "    else:\n",
    "        x = Embedding( input_dim=embed_inp, output_dim=embed_size,\n",
    "                      weights=[ embedding_matrix ], trainable=embed_trainable )( inp )\n",
    "\n",
    "    x = SpatialDropout1D( spdrpt )( x )\n",
    "    z = Bidirectional( LSTM( lstm_units ) )( x )\n",
    "    z = Dropout( drpt )( z )\n",
    "    fc1 = Dense( 100, activation=fc_act, kernel_initializer=fc_weights_init )( z )\n",
    "    fc2 = Dense( 50, activation=fc_act, kernel_initializer=fc_weights_init )( fc1 )\n",
    "    output = Dense( 1, activation='sigmoid' )( fc2 )\n",
    "\n",
    "    model = Model( inputs=inp, outputs=output )\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqEuW-DarLMr"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings( 'ignore' )\n",
    "start_time = time.time()\n",
    "\n",
    "valaccuracy, valprecision, valrecall, valf1, valcm = [], [], [], [], []\n",
    "testaccuracy, testprecision, testrecall, testf1, testcm = [], [], [], [], []\n",
    "com_text, com_label, com_predicted, com_prob = [], [], [], []\n",
    "\n",
    "skf = StratifiedKFold( n_splits=5, random_state=0, shuffle=True )\n",
    "print(skf)\n",
    "reports = []\n",
    "fold = 1\n",
    "for train_index, test_index in skf.split( df[ xcolumn ], df[ ycolumn ] ):\n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # seprating train and test sets\n",
    "    xtrain = df.loc[ train_index ][ xcolumn ].values\n",
    "    xtest = df.loc[ test_index ][ xcolumn ].values\n",
    "\n",
    "    ytrain = df.loc[ train_index ][ ycolumn ].values\n",
    "    ytest = df.loc[ test_index ][ ycolumn ].values\n",
    "\n",
    "    # splitting train and validation sets\n",
    "    xtrain, xval, ytrain, yval = train_test_split( xtrain, ytrain, test_size=0.15, random_state=0 )\n",
    "\n",
    "    # tokenization with keras tokenizer\n",
    "    tokenizer = text.Tokenizer(  )\n",
    "    tokenizer.fit_on_texts( np.append( xtrain, xval ) )\n",
    "\n",
    "    xtrain = tokenizer.texts_to_sequences( xtrain )\n",
    "    xval = tokenizer.texts_to_sequences( xval )\n",
    "    xtest = tokenizer.texts_to_sequences( xtest )\n",
    "\n",
    "    # pad the tokenized sequences\n",
    "    xtrain = sequence.pad_sequences( xtrain, maxlen=MAX_LEN )\n",
    "    xval = sequence.pad_sequences( xval, maxlen=MAX_LEN )\n",
    "    xtest = sequence.pad_sequences( xtest, maxlen=MAX_LEN )\n",
    "\n",
    "    # check if pre-trained word embeddings flag is true\n",
    "    if PRE_TRAINED_FLAG == True:\n",
    "        EMBEDDING_MATRIX = get_vectors(\n",
    "            tokenizer=tokenizer, emb_mean=emb_mean, emb_std=emb_std, embed_size=EMBED_SIZE\n",
    "        )\n",
    "\n",
    "    # define a model\n",
    "    EMBED_INP_SIZE = len( tokenizer.word_index ) + 1\n",
    "    model = BLSTM(\n",
    "        max_len=MAX_LEN, embed_inp=EMBED_INP_SIZE, embed_size=EMBED_SIZE,\n",
    "        embedding_matrix=EMBEDDING_MATRIX, embed_trainable=EMBED_TRAINABLE,\n",
    "        spdrpt=SPDRPT, drpt=DRPT, emb_weights_init=EMB_WEIGHTS_INIT,\n",
    "        fc_weights_init=FC_WEIGHTS_INIT, fc_act=FC_ACT, optimizer=OPTIMIZER, lstm_units=LSTM_UNITS\n",
    "    )\n",
    "\n",
    "    # save model summaries and model architecture diagrams in the first fold only\n",
    "    if fold == 1:\n",
    "        plot_model( model=model, to_file='{}/{}.png'.format( modelsummaries, modelname ), show_shapes=False )\n",
    "\n",
    "        with open( '{}/{}.txt'.format( modelsummaries, modelname ), 'w' ) as s:\n",
    "            with redirect_stdout( s ):\n",
    "                model.summary()\n",
    "\n",
    "    if isinstance(model.optimizer.learning_rate, tf.Variable):\n",
    "      K.set_value(model.optimizer.learning_rate, LR_RATE)\n",
    "    else:\n",
    "      model.optimizer.learning_rate = LR_RATE\n",
    "\n",
    "    # train the model with callbacks for early stopping\n",
    "    f1callback = F1_score_callback(\n",
    "        val_data=( xval, yval ), filepath=modelpath + modelname + str( fold )+\".keras\",\n",
    "        patience=PATIENCE, decay=DECAY, decay_rate=DECAY_RATE, decay_after=DECAY_AFTER\n",
    "    )\n",
    "    histmodel = model.fit(\n",
    "        xtrain, ytrain, batch_size=BATCH, epochs=NEPOCHS, verbose=0, callbacks=[ f1callback ]\n",
    "    )\n",
    "\n",
    "    # save history of all folds\n",
    "    hist[ 'fold' + str( fold ) ] = histmodel.history.copy()\n",
    "\n",
    "    # delete trained model object\n",
    "    del model, histmodel, f1callback\n",
    "    EMBEDDING_MATRIX = []\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    # delete pre trained embeddings from the memory\n",
    "    if ( PRE_TRAINED_FLAG == True ) and ( fold == skf.n_splits ):\n",
    "        del EMBEDDINGS_INDEX\n",
    "        gc.collect()\n",
    "\n",
    "    # load saved model\n",
    "    loaded_model = load_model( modelpath + modelname + str( fold ) + \".keras\" )\n",
    "\n",
    "    # get predictions (probabilities) for validation and test sets respectively\n",
    "    valpredictions = loaded_model.predict( xval, verbose=0, batch_size=BATCH )\n",
    "    testpredictions = loaded_model.predict( xtest, verbose=0, batch_size=BATCH )\n",
    "\n",
    "    # delete loaded model\n",
    "    del loaded_model\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    # optimizer threshold on validation set\n",
    "    threshold = optimize_threshold( yval, valpredictions )\n",
    "\n",
    "    # save accuracy, precision, recall, f1 and confusion matrices\n",
    "    vallabels = ( valpredictions >= threshold ).astype( 'int32' )\n",
    "    testlabels = ( testpredictions >= threshold ).astype( 'int32' )\n",
    "\n",
    "    valaccuracy.append( accuracy_score( yval, vallabels ) )\n",
    "    valprecision.append( precision_score( yval, vallabels ) )\n",
    "    valrecall.append( recall_score( yval, vallabels ) )\n",
    "    valf1.append( f1_score( yval, vallabels ) )\n",
    "    valcm.append( confusion_matrix( yval, vallabels ) )\n",
    "\n",
    "    testaccuracy.append( accuracy_score( ytest, testlabels ) )\n",
    "    testprecision.append( precision_score( ytest, testlabels ) )\n",
    "    testrecall.append( recall_score( ytest, testlabels ) )\n",
    "    testf1.append( f1_score( ytest, testlabels ) )\n",
    "    testcm.append( confusion_matrix( ytest, testlabels ) )\n",
    "    reports.append(classification_report( ytest, testlabels, output_dict=True, zero_division=0, target_names=['UNT 0', 'TIN 1']))\n",
    "    print( 'Fold: {:02d} out of {:02d} completed.'.format( fold, skf.get_n_splits() ) )\n",
    "    print( 'Local System Time: {}'.format( time.strftime( \"%I:%M %p\", time.localtime() ) ) )\n",
    "\n",
    "    fold = fold + 1\n",
    "time_took = time.time() - start_time\n",
    "print( f\"Total runtime: { hms_string( time_took ) }\" )\n",
    "WriteResutls(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nl92pSZ13zyg"
   },
   "outputs": [],
   "source": [
    "# hyper parameters for this model\n",
    "\n",
    "MAX_LEN = 128\n",
    "EMBED_SIZE = 300\n",
    "EMBED_TRAINABLE = False\n",
    "EMB_WEIGHTS_INIT = 'he_normal'\n",
    "SPDRPT = 0.35\n",
    "DRPT = 0.2\n",
    "FC_WEIGHTS_INIT = 'he_uniform'\n",
    "FC_ACT = 'elu'\n",
    "LR_RATE = 1e-3\n",
    "OPTIMIZER = 'adam'\n",
    "FCL_LOSS_ALP = 0.25\n",
    "FCL_LOSS_GAM = 5\n",
    "BATCH = 32\n",
    "NEPOCHS = 30\n",
    "PATIENCE = 5\n",
    "DECAY = True\n",
    "DECAY_RATE = 0.3\n",
    "DECAY_AFTER = 1\n",
    "\n",
    "modelname = 'BGRU_P-ft'\n",
    "modelpath = './Saved Models/' + modelname + '/'\n",
    "modelresults = './Model Results'\n",
    "modelsummaries = './Model - Summaries-Figures'\n",
    "DIRECTORIES_TO_BE_CREATED = [ modelpath, modelresults, modelsummaries ]\n",
    "for directory in DIRECTORIES_TO_BE_CREATED:\n",
    "    if not os.path.exists( directory ):\n",
    "        os.makedirs( directory )\n",
    "\n",
    "if PRE_TRAINED_FLAG == True:\n",
    "    EMBEDDINGS_INDEX = dict( get_coefs( *o.strip().split() ) for o in open( EMBEDDING_FILE, encoding='utf-8' )  if len(o)>19 )\n",
    "    print( 'Total Words in Pretrained Embeddings: ', len( EMBEDDINGS_INDEX.values() ) )\n",
    "    all_embs = np.stack( list(EMBEDDINGS_INDEX.values()) )\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    print( 'Pretrained Embeddings mean:', emb_mean, ' std: ', emb_std )\n",
    "\n",
    "def BGRU_P(\n",
    "    max_len=100, embed_inp=10000, embed_size=300, embedding_matrix=[], embed_trainable=False,\n",
    "    spdrpt=.1, drpt=.1, emb_weights_init='', fc_weights_init='', fc_act='', optimizer='',\n",
    "    fcl_loss_alp=.1, fcl_loss_gam=1 ):\n",
    "\n",
    "    inp = Input( shape=( max_len, ) )\n",
    "    if embedding_matrix is None:\n",
    "        x = Embedding( input_dim=embed_inp, output_dim=embed_size,\n",
    "                      embeddings_initializer=emb_weights_init, trainable=embed_trainable )( inp )\n",
    "    else:\n",
    "        x = Embedding( input_dim=embed_inp, output_dim=embed_size,\n",
    "                      weights=[ embedding_matrix ], trainable=embed_trainable )( inp )\n",
    "\n",
    "    x = SpatialDropout1D( spdrpt )( x )\n",
    "    x1 = Bidirectional( GRU( 128, return_sequences=True ) )(x)\n",
    "    x2 = Bidirectional( GRU( 64, return_sequences=True ) )(x)\n",
    "\n",
    "    conc = concatenate( [ x1, x2 ] )\n",
    "\n",
    "    pooled = [  ]\n",
    "\n",
    "    avg_pool = GlobalAveragePooling1D(  )(conc)\n",
    "    max_pool = GlobalMaxPooling1D(  )(conc)\n",
    "\n",
    "    pooled.append( avg_pool )\n",
    "    pooled.append( max_pool )\n",
    "\n",
    "    x = Concatenate( axis=1 )( pooled )\n",
    "    x = Dropout( drpt ) ( x )\n",
    "\n",
    "    fc1 = Dense( 100, activation=fc_act, kernel_initializer=fc_weights_init )( x )\n",
    "    fc2 = Dense( 50, activation=fc_act, kernel_initializer=fc_weights_init )( fc1 )\n",
    "    output = Dense( 1, activation='sigmoid' )( fc2 )\n",
    "\n",
    "    model = Model( inputs=inp, outputs=output )\n",
    "\n",
    "    model.compile(loss=[ focal_loss( alpha=fcl_loss_alp, gamma=fcl_loss_gam ) ],\n",
    "        optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0F4pBroeuVY0"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings( 'ignore' )\n",
    "start_time = time.time()\n",
    "print( 'Local System Time: {}'.format( time.strftime( \"%I:%M %p\", time.localtime() ) ) )\n",
    "\n",
    "valaccuracy, valprecision, valrecall, valf1, valcm = [], [], [], [], []\n",
    "testaccuracy, testprecision, testrecall, testf1, testcm = [], [], [], [], []\n",
    "com_text, com_label, com_predicted, com_prob = [], [], [], []\n",
    "com_indices = []\n",
    "hist = {}\n",
    "reports = []\n",
    "skf = StratifiedKFold( n_splits=5, random_state=0, shuffle=True )\n",
    "print(skf)\n",
    "\n",
    "fold = 1\n",
    "for train_index, test_index in skf.split( df[ xcolumn ], df[ ycolumn ] ):\n",
    "    # seprating train and test sets\n",
    "    xtrain = df.loc[ train_index ][ xcolumn ].values\n",
    "    xtest = df.loc[ test_index ][ xcolumn ].values\n",
    "\n",
    "    ytrain = df.loc[ train_index ][ ycolumn ].values\n",
    "    ytest = df.loc[ test_index ][ ycolumn ].values\n",
    "\n",
    "    # splitting train and validation sets\n",
    "    xtrain, xval, ytrain, yval = train_test_split( xtrain, ytrain, test_size=0.15, random_state=0 )\n",
    "\n",
    "    # tokenization with keras tokenizer\n",
    "    tokenizer = text.Tokenizer(  )\n",
    "    tokenizer.fit_on_texts( np.append( xtrain, xval ) )\n",
    "\n",
    "    xtrain = tokenizer.texts_to_sequences( xtrain )\n",
    "    xval = tokenizer.texts_to_sequences( xval )\n",
    "    xtest = tokenizer.texts_to_sequences( xtest )\n",
    "\n",
    "    # pad the tokenized sequences\n",
    "    xtrain = sequence.pad_sequences( xtrain, maxlen=MAX_LEN )\n",
    "    xval = sequence.pad_sequences( xval, maxlen=MAX_LEN )\n",
    "    xtest = sequence.pad_sequences( xtest, maxlen=MAX_LEN )\n",
    "\n",
    "    # check if pre-trained word embeddings flag is true\n",
    "    if PRE_TRAINED_FLAG == True:\n",
    "        EMBEDDING_MATRIX = get_vectors(\n",
    "            tokenizer=tokenizer, emb_mean=emb_mean, emb_std=emb_std, embed_size=EMBED_SIZE\n",
    "        )\n",
    "\n",
    "    # define a model\n",
    "    EMBED_INP_SIZE = len( tokenizer.word_index ) + 1\n",
    "    model = BGRU_P(\n",
    "        max_len=MAX_LEN, embed_inp=EMBED_INP_SIZE, embed_size=EMBED_SIZE,\n",
    "        embedding_matrix=EMBEDDING_MATRIX, embed_trainable=EMBED_TRAINABLE,\n",
    "        spdrpt=SPDRPT, drpt=DRPT, emb_weights_init=EMB_WEIGHTS_INIT, fc_weights_init=FC_WEIGHTS_INIT,\n",
    "        fc_act=FC_ACT, optimizer=OPTIMIZER, fcl_loss_alp=FCL_LOSS_ALP, fcl_loss_gam=FCL_LOSS_GAM\n",
    "    )\n",
    "\n",
    "    # save model summaries and model architecture diagrams in the first fold only\n",
    "    if fold == 1:\n",
    "        plot_model( model=model, to_file='{}/{}.png'.format( modelsummaries, modelname ), show_shapes=False )\n",
    "\n",
    "        with open( '{}/{}.txt'.format( modelsummaries, modelname ), 'w' ) as s:\n",
    "            with redirect_stdout( s ):\n",
    "                model.summary()\n",
    "\n",
    "    if isinstance(model.optimizer.learning_rate, tf.Variable):\n",
    "      K.set_value(model.optimizer.learning_rate, LR_RATE)\n",
    "    else:\n",
    "      model.optimizer.learning_rate = LR_RATE\n",
    "\n",
    "    # train the model with callbacks for early stopping\n",
    "    f1callback = F1_score_callback(\n",
    "        val_data=( xval, yval ), filepath=modelpath + modelname + str( fold ) + \".keras\",\n",
    "        patience=PATIENCE, decay=DECAY, decay_rate=DECAY_RATE, decay_after=DECAY_AFTER\n",
    "    )\n",
    "    histmodel = model.fit(\n",
    "        xtrain, ytrain, batch_size=BATCH, epochs=NEPOCHS, verbose=0, callbacks=[ f1callback ]\n",
    "    )\n",
    "\n",
    "    # save history of all folds\n",
    "    hist[ 'fold' + str( fold ) ] = histmodel.history.copy()\n",
    "\n",
    "    # delete trained model object\n",
    "    del model, histmodel, f1callback\n",
    "    EMBEDDING_MATRIX = []\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    # delete pre trained embeddings from the memory\n",
    "    if ( PRE_TRAINED_FLAG == True ) and ( fold == skf.n_splits ):\n",
    "        del EMBEDDINGS_INDEX\n",
    "        gc.collect()\n",
    "\n",
    "    # load saved model\n",
    "    custt_obss = { 'focal_loss_fixed' : focal_loss( alpha=FCL_LOSS_ALP, gamma=FCL_LOSS_GAM ) }\n",
    "    loaded_model = load_model( modelpath + modelname + str( fold )+\".keras\", custom_objects=custt_obss )\n",
    "\n",
    "    # get predictions (probabilities) for validation and test sets respectively\n",
    "    valpredictions = loaded_model.predict( xval, verbose=0, batch_size=BATCH )\n",
    "    testpredictions = loaded_model.predict( xtest, verbose=0, batch_size=BATCH )\n",
    "\n",
    "    # delete loaded model\n",
    "    del loaded_model, custt_obss\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    # optimizer threshold on validation set\n",
    "    threshold = optimize_threshold( yval, valpredictions )\n",
    "\n",
    "    # save accuracy, precision, recall, f1 and confusion matrices\n",
    "    vallabels = ( valpredictions >= threshold ).astype( 'int32' )\n",
    "    testlabels = ( testpredictions >= threshold ).astype( 'int32' )\n",
    "\n",
    "    valaccuracy.append( accuracy_score( yval, vallabels ) )\n",
    "    valprecision.append( precision_score( yval, vallabels ) )\n",
    "    valrecall.append( recall_score( yval, vallabels ) )\n",
    "    valf1.append( f1_score( yval, vallabels ) )\n",
    "    valcm.append( confusion_matrix( yval, vallabels ) )\n",
    "\n",
    "    testaccuracy.append( accuracy_score( ytest, testlabels ) )\n",
    "    testprecision.append( precision_score( ytest, testlabels ) )\n",
    "    testrecall.append( recall_score( ytest, testlabels ) )\n",
    "    testf1.append( f1_score( ytest, testlabels ) )\n",
    "    testcm.append( confusion_matrix( ytest, testlabels ) )\n",
    "    reports.append(classification_report( ytest, testlabels, output_dict=True, zero_division=0, target_names=['UNT 0', 'TIN 1']))\n",
    "\n",
    "    print( 'Fold: {:02d} out of {:02d} completed.'.format( fold, skf.get_n_splits() ) )\n",
    "    print( 'Local System Time: {}'.format( time.strftime( \"%I:%M %p\", time.localtime() ) ) )\n",
    "\n",
    "    fold = fold + 1\n",
    "time_took = time.time() - start_time\n",
    "print( f\"Total runtime: { hms_string( time_took ) }\" )\n",
    "WriteResutls(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDpxy9gLuVZ2"
   },
   "outputs": [],
   "source": [
    "# hyper parameters for this model\n",
    "\n",
    "MAX_LEN = 128\n",
    "EMBED_SIZE = 300\n",
    "EMBED_TRAINABLE = False\n",
    "EMB_WEIGHTS_INIT = 'he_normal'\n",
    "LR_RATE = 1e-3\n",
    "OPTIMIZER = 'adam'\n",
    "KER_REGULARIZER = 'L1L2'\n",
    "DRPT = 0.3\n",
    "\n",
    "BATCH = 32\n",
    "NEPOCHS = 30\n",
    "PATIENCE = 5\n",
    "DECAY = True\n",
    "DECAY_RATE = 0.3\n",
    "DECAY_AFTER = 1\n",
    "\n",
    "modelname = 'CNN_GRU-ft'\n",
    "modelpath = './Saved Models/' + modelname + '/'\n",
    "modelresults = './Model Results'\n",
    "modelsummaries = './Model - Summaries-Figures'\n",
    "\n",
    "DIRECTORIES_TO_BE_CREATED = [ modelpath, modelresults, modelsummaries ]\n",
    "for directory in DIRECTORIES_TO_BE_CREATED:\n",
    "    if not os.path.exists( directory ):\n",
    "        os.makedirs( directory )\n",
    "\n",
    "if PRE_TRAINED_FLAG == True:\n",
    "    EMBEDDINGS_INDEX = dict( get_coefs( *o.strip().split() ) for o in open( EMBEDDING_FILE, encoding='utf-8' )  if len(o)>19 )\n",
    "    print( 'Total Words in Pretrained Embeddings: ', len( EMBEDDINGS_INDEX.values() ) )\n",
    "    all_embs = np.stack( list(EMBEDDINGS_INDEX.values()) )\n",
    "    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n",
    "    print( 'Pretrained Embeddings mean:', emb_mean, ' std: ', emb_std )\n",
    "\n",
    "def CNN_GRU(\n",
    "    max_len=100, embed_inp=10000, embed_size=300, embedding_matrix=[], embed_trainable=False,\n",
    "    drpt=.1, emb_weights_init='', optimizer='', ker_regularizer='' ):\n",
    "\n",
    "    inp = Input( shape=( max_len, ) )\n",
    "    if embedding_matrix is None:\n",
    "        x = Embedding( input_dim=embed_inp, output_dim=embed_size,\n",
    "                      embeddings_initializer=emb_weights_init, trainable=embed_trainable )( inp )\n",
    "    else:\n",
    "        x = Embedding( input_dim=embed_inp, output_dim=embed_size,\n",
    "                      weights=[ embedding_matrix ], trainable=embed_trainable )( inp )\n",
    "\n",
    "    x = Dropout( drpt )( x )\n",
    "    conv = Conv1D( filters=100, kernel_size=4, padding='same', activation='relu',\n",
    "                  kernel_regularizer=ker_regularizer )( x )\n",
    "    pool = MaxPooling1D( pool_size=4 )( conv )\n",
    "    gru = GRU( 100, return_sequences=True )( pool )\n",
    "    z = GlobalMaxPooling1D(  )( gru )\n",
    "    output = Dense( 1, activation='sigmoid', kernel_regularizer=ker_regularizer )( z )\n",
    "\n",
    "    model = Model( inputs=inp, outputs=output )\n",
    "\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZNZlDTHwH1P"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings( 'ignore' )\n",
    "start_time = time.time()\n",
    "print( 'Local System Time: {}'.format( time.strftime( \"%I:%M %p\", time.localtime() ) ) )\n",
    "\n",
    "valaccuracy, valprecision, valrecall, valf1, valcm = [], [], [], [], []\n",
    "testaccuracy, testprecision, testrecall, testf1, testcm = [], [], [], [], []\n",
    "com_text, com_label, com_predicted, com_prob = [], [], [], []\n",
    "com_indices = []\n",
    "hist = {}\n",
    "reports = []\n",
    "skf = StratifiedKFold( n_splits=5, random_state=0, shuffle=True )\n",
    "print(skf)\n",
    "\n",
    "fold = 1\n",
    "for train_index, test_index in skf.split( df[ xcolumn ], df[ ycolumn ] ):\n",
    "    # seprating train and test sets\n",
    "    print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    xtrain = df.loc[ train_index ][ xcolumn ].values\n",
    "    xtest = df.loc[ test_index ][ xcolumn ].values\n",
    "\n",
    "    ytrain = df.loc[ train_index ][ ycolumn ].values\n",
    "    ytest = df.loc[ test_index ][ ycolumn ].values\n",
    "\n",
    "    # splitting train and validation sets\n",
    "    xtrain, xval, ytrain, yval = train_test_split( xtrain, ytrain, test_size=0.15, random_state=0 )\n",
    "\n",
    "    # tokenization with keras tokenizer\n",
    "    tokenizer = text.Tokenizer(  )\n",
    "    tokenizer.fit_on_texts( np.append( xtrain, xval ) )\n",
    "\n",
    "    xtrain = tokenizer.texts_to_sequences( xtrain )\n",
    "    xval = tokenizer.texts_to_sequences( xval )\n",
    "    xtest = tokenizer.texts_to_sequences( xtest )\n",
    "\n",
    "    # pad the tokenized sequences\n",
    "    xtrain = sequence.pad_sequences( xtrain, maxlen=MAX_LEN )\n",
    "    xval = sequence.pad_sequences( xval, maxlen=MAX_LEN )\n",
    "    xtest = sequence.pad_sequences( xtest, maxlen=MAX_LEN )\n",
    "\n",
    "    # check if pre-trained word embeddings flag is true\n",
    "    if PRE_TRAINED_FLAG == True:\n",
    "        EMBEDDING_MATRIX = get_vectors(\n",
    "            tokenizer=tokenizer, emb_mean=emb_mean, emb_std=emb_std, embed_size=EMBED_SIZE\n",
    "        )\n",
    "\n",
    "    # define a model\n",
    "    EMBED_INP_SIZE = len( tokenizer.word_index ) + 1\n",
    "    model = CNN_GRU( max_len=MAX_LEN, embed_inp=EMBED_INP_SIZE, embed_size=EMBED_SIZE,\n",
    "        embedding_matrix=EMBEDDING_MATRIX, embed_trainable=EMBED_TRAINABLE,\n",
    "        emb_weights_init=EMB_WEIGHTS_INIT, optimizer=OPTIMIZER,\n",
    "        ker_regularizer=KER_REGULARIZER, drpt=DRPT)\n",
    "\n",
    "    # save model summaries and model architecture diagrams in the first fold only\n",
    "    if fold == 1:\n",
    "        plot_model( model=model, to_file='{}/{}.png'.format( modelsummaries, modelname ), show_shapes=False )\n",
    "\n",
    "        with open( '{}/{}.txt'.format( modelsummaries, modelname ), 'w' ) as s:\n",
    "            with redirect_stdout( s ):\n",
    "                model.summary()\n",
    "\n",
    "    if isinstance(model.optimizer.learning_rate, tf.Variable):\n",
    "      K.set_value(model.optimizer.learning_rate, LR_RATE)\n",
    "    else:\n",
    "      model.optimizer.learning_rate = LR_RATE\n",
    "    filepath = modelpath + modelname + str( fold ) + \".keras\"\n",
    "\n",
    "    # train the model with callbacks for early stopping\n",
    "    f1callback = F1_score_callback(val_data=( xval, yval ), filepath=filepath,patience=PATIENCE, decay=DECAY, decay_rate=DECAY_RATE, decay_after=DECAY_AFTER)\n",
    "    histmodel = model.fit(xtrain, ytrain, batch_size=BATCH, epochs=NEPOCHS, verbose=0, callbacks=[ f1callback ])\n",
    "\n",
    "    # save history of all folds\n",
    "    hist[ 'fold' + str( fold ) ] = histmodel.history.copy()\n",
    "\n",
    "    # delete trained model object\n",
    "    del model, histmodel, f1callback\n",
    "    EMBEDDING_MATRIX = []\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "    # delete pre trained embeddings from the memory\n",
    "    if ( PRE_TRAINED_FLAG == True ) and ( fold == skf.n_splits ):\n",
    "        del EMBEDDINGS_INDEX\n",
    "        gc.collect()\n",
    "\n",
    "    # load saved model\n",
    "    loaded_model = load_model( filepath )\n",
    "\n",
    "    # get predictions (probabilities) for validation and test sets respectively\n",
    "    valpredictions = loaded_model.predict( xval, verbose=0, batch_size=BATCH )\n",
    "    testpredictions = loaded_model.predict( xtest, verbose=0, batch_size=BATCH )\n",
    "\n",
    "    # delete loaded model\n",
    "    del loaded_model\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    # optimizer threshold on validation set\n",
    "    threshold = optimize_threshold( yval, valpredictions )\n",
    "\n",
    "    # save accuracy, precision, recall, f1 and confusion matrices\n",
    "    vallabels = ( valpredictions >= threshold ).astype( 'int32' )\n",
    "    testlabels = ( testpredictions >= threshold ).astype( 'int32' )\n",
    "\n",
    "    valaccuracy.append( accuracy_score( yval, vallabels ) )\n",
    "    valprecision.append( precision_score( yval, vallabels ) )\n",
    "    valrecall.append( recall_score( yval, vallabels ) )\n",
    "    valf1.append( f1_score( yval, vallabels ) )\n",
    "    valcm.append( confusion_matrix( yval, vallabels ) )\n",
    "\n",
    "    testaccuracy.append( accuracy_score( ytest, testlabels ) )\n",
    "    testprecision.append( precision_score( ytest, testlabels ) )\n",
    "    testrecall.append( recall_score( ytest, testlabels ) )\n",
    "    testf1.append( f1_score( ytest, testlabels ) )\n",
    "    testcm.append( confusion_matrix( ytest, testlabels ) )\n",
    "    reports.append(classification_report( ytest, testlabels, output_dict=True, zero_division=0, target_names=['UNT 0', 'TIN 1']))\n",
    "\n",
    "    print( 'Fold: {:02d} out of {:02d} completed.'.format( fold, skf.get_n_splits() ) )\n",
    "    print( 'Local System Time: {}'.format( time.strftime( \"%I:%M %p\", time.localtime() ) ) )\n",
    "\n",
    "    fold = fold + 1\n",
    "time_took = time.time() - start_time\n",
    "print( f\"Total runtime: { hms_string( time_took ) }\" )\n",
    "WriteResutls(reports)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
