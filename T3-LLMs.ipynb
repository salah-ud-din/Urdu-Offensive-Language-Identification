{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzvqAc0ozC37"
   },
   "source": [
    "PyTorch Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6594 entries, 0 to 6593\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  6594 non-null   int64 \n",
      " 1   Tweet       6594 non-null   object\n",
      " 2   Tag         6594 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 154.7+ KB\n",
      "None\n",
      "Index(['Unnamed: 0', 'Tweet', 'Tag'], dtype='object') (6594, 3)\n",
      "[1 2 3]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import gc, os,time,numpy as np, pandas as pd, datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel, logging\n",
    "\n",
    "# ------------ GPU Setup ------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if device.type == 'cuda':torch.cuda.empty_cache()\n",
    "\n",
    "# ------------- Hyperparameters ------------\n",
    "MAX_LEN = 128\n",
    "BERT_TRAINABLE = True\n",
    "DRPT = 0.4\n",
    "FC_ACT = 'elu'\n",
    "LR_RATE = 1e-5\n",
    "BATCH = 32\n",
    "NEPOCHS = 20\n",
    "PATIENCE = 4\n",
    "DECAY = True\n",
    "DECAY_RATE = 0.3\n",
    "DECAY_AFTER = 1\n",
    "\n",
    "modelname = 'hfFineTuneBert'\n",
    "modelpath = os.path.join('.', 'Saved Models', modelname)\n",
    "modelresults = os.path.join('.', 'Model Results')\n",
    "modelsummaries = os.path.join('.', 'Model - Summaries-Figures')\n",
    "for d in [modelpath, modelresults, modelsummaries]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# ---------------- Utils ---------------------\n",
    "def hms_string(sec):\n",
    "    h = int(sec // 3600)\n",
    "    m = int((sec % 3600) // 60)\n",
    "    s = sec % 60\n",
    "    return f\"{h} hrs {m:02d} mins {s:05.2f} secs\"\n",
    "########################################################\n",
    "def WriteResutls(reports):\n",
    "  unt0 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  tin1 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  Oth2 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  macroavg = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  weightedavg = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  accu = []\n",
    "  for report in reports:\n",
    "    for k,v in report.items():\n",
    "      if 'IND' in k:\n",
    "        unt0['precision'].append(v['precision'])\n",
    "        unt0['recall'].append(v['recall'])\n",
    "        unt0['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'GRP' in k:\n",
    "        tin1['precision'].append(v['precision'])\n",
    "        tin1['recall'].append(v['recall'])\n",
    "        tin1['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'OTH' in k:\n",
    "        Oth2['precision'].append(v['precision'])\n",
    "        Oth2['recall'].append(v['recall'])\n",
    "        Oth2['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'macro avg' in k:\n",
    "        macroavg['precision'].append(v['precision'])\n",
    "        macroavg['recall'].append(v['recall'])\n",
    "        macroavg['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'weighted avg' in k:\n",
    "        weightedavg['precision'].append(v['precision'])\n",
    "        weightedavg['recall'].append(v['recall'])\n",
    "        weightedavg['f1-score'].append(v['f1-score'])\n",
    "      elif 'accuracy' in k:\n",
    "        accu.append(v)\n",
    "\n",
    "  print('Accuracy:',np.mean(accu))\n",
    "  print(\"\")\n",
    "  print('IND 1 Precision:',np.mean(unt0['precision']))\n",
    "  print('IND 1 Recall:',np.mean(unt0['recall']))\n",
    "  print('IND 1 F1-Score:',np.mean(unt0['f1-score']))\n",
    "  print(\"\")\n",
    "  print('GRP 2 Precision:',np.mean(tin1['precision']))\n",
    "  print('GRP 2 Recall:',np.mean(tin1['recall']))\n",
    "  print('GRP 2 F1-Score:',np.mean(tin1['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('OTH 3 Precision:',np.mean(Oth2['precision']))\n",
    "  print('OTH 3 Recall:',np.mean(Oth2['recall']))\n",
    "  print('OTH 3 F1-Score:',np.mean(Oth2['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('Weighted Avg Precision:',np.mean(weightedavg['precision']))\n",
    "  print('Weighted Avg Recall:',np.mean(weightedavg['recall']))\n",
    "  print('Weighted Avg F1-Score:',np.mean(weightedavg['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('Macro  Precision:',np.mean(macroavg['precision']))\n",
    "  print('Macro  Recall:',np.mean(macroavg['recall']))\n",
    "  print('Macro  F1-Score:',np.mean(macroavg['f1-score']))\n",
    "\n",
    "  file = open( result_path, mode='a' )\n",
    "  file.write( modelname+ ' ( '+ datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") +') \\n' )\n",
    "  file.write( 'Accuracy:'+str(np.mean(accu))+'\\n' )\n",
    "  file.write('IND 1 Precision:'+str(np.mean(unt0['precision']))+'\\n' )\n",
    "  file.write('IND 1 Recall:'+str(np.mean(unt0['recall']))+'\\n' )\n",
    "  file.write('IND 1 F1-Score:'+str(np.mean(unt0['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('GRP 2 Precision:'+str(np.mean(tin1['precision']))+'\\n' )\n",
    "  file.write('GRP 2 Recall:'+str(np.mean(tin1['recall']))+'\\n' )\n",
    "  file.write('GRP 2 F1-Score:'+str(np.mean(tin1['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('OTH 3 Precision:'+str(np.mean(Oth2['precision']))+'\\n' )\n",
    "  file.write('OTH 3 Recall:'+str(np.mean(Oth2['recall']))+'\\n' )\n",
    "  file.write('OTH 3 F1-Score:'+str(np.mean(Oth2['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('Weighted Avg Precision:'+str(np.mean(weightedavg['precision']))+'\\n' )\n",
    "  file.write('Weighted Avg Recall:'+str(np.mean(weightedavg['recall']))+'\\n' )\n",
    "  file.write('Weighted Avg F1-Score:'+str(np.mean(weightedavg['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('Macro  Precision:'+str(np.mean(macroavg['precision']))+'\\n' )\n",
    "  file.write('Macro  Recall:'+str(np.mean(macroavg['recall']))+'\\n' )\n",
    "  file.write('Macro  F1-Score:'+str(np.mean(macroavg['f1-score']))+'\\n' )\n",
    "  file.close()\n",
    "  print(\"Done\")\n",
    "######################################################################################\n",
    "\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "# ----------- Dataset Class ----------------\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)   # changed to long for CrossEntropy\n",
    "        return item\n",
    "\n",
    "# -------- Model Definition ----------------\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, model_name, dropout_rate=DRPT, num_classes=3):  # num_classes=3\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name, config=config)\n",
    "        if not BERT_TRAINABLE:\n",
    "            for p in self.bert.parameters(): p.requires_grad = False\n",
    "        hidden = self.bert.config.hidden_size\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(hidden, hidden)\n",
    "        self.act = nn.ELU()\n",
    "        self.out = nn.Linear(hidden, num_classes)   # output size = num_classes\n",
    "        # he_uniform init\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.kaiming_uniform_(self.out.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.out.bias)\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        o = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = o.pooler_output if hasattr(o, 'pooler_output') else o.last_hidden_state[:,0]\n",
    "        x = self.dropout(pooled)\n",
    "        x = self.act(self.fc1(x))\n",
    "        return self.out(x)   # raw logits for CrossEntropyLoss\n",
    "\n",
    "# -------------- Data Loading ---------------\n",
    "result_path =  r'C:\\Users\\mojua\\Desktop\\DL-Code\\T3-LLM-Classification-Result.csv'\n",
    "file_path = r'C:\\Users\\mojua\\Desktop\\DL-Code\\Dataset\\Offensive-24K-T3.xlsx'\n",
    "\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "df['Tweet'] = df['Tweet'].astype(str)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df.info())\n",
    "print(df.columns, df.shape)\n",
    "print(df.Tag.unique())\n",
    "df['Tag'] = df['Tag'].replace({1: 0, 2: 1, 3: 2})\n",
    "print(df.Tag.unique())\n",
    "xcolumn = 'Tweet'\n",
    "ycolumn = 'Tag'\n",
    "\n",
    "# ----------- Tokenizer & Config ------------\n",
    "bertmodelname = 'bert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(bertmodelname, use_fast=True)\n",
    "config = AutoConfig.from_pretrained(bertmodelname)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local System Time: 12:42 PM\n",
      "Fold1 Ep1/20 - ValMacroF1=0.5350 Pat=0\n",
      "Fold1 Ep2/20 - ValMacroF1=0.6852 Pat=0\n",
      "Fold1 Ep3/20 - ValMacroF1=0.7021 Pat=0\n",
      "Fold1 Ep4/20 - ValMacroF1=0.7368 Pat=0\n",
      "Fold1 Ep5/20 - ValMacroF1=0.7050 Pat=1\n",
      "Fold1 Ep6/20 - ValMacroF1=0.7090 Pat=2\n",
      "Fold1 Ep7/20 - ValMacroF1=0.7176 Pat=3\n",
      "Fold1 Ep8/20 - ValMacroF1=0.7231 Pat=4\n",
      "Stopping early at epoch 8\n",
      "Completed fold 1/5\n",
      "Fold2 Ep1/20 - ValMacroF1=0.5043 Pat=0\n",
      "Fold2 Ep2/20 - ValMacroF1=0.6575 Pat=0\n",
      "Fold2 Ep3/20 - ValMacroF1=0.7249 Pat=0\n",
      "Fold2 Ep4/20 - ValMacroF1=0.7295 Pat=0\n",
      "Fold2 Ep5/20 - ValMacroF1=0.7412 Pat=0\n",
      "Fold2 Ep6/20 - ValMacroF1=0.7155 Pat=1\n",
      "Fold2 Ep7/20 - ValMacroF1=0.7155 Pat=2\n",
      "Fold2 Ep8/20 - ValMacroF1=0.7287 Pat=3\n",
      "Fold2 Ep9/20 - ValMacroF1=0.7356 Pat=4\n",
      "Stopping early at epoch 9\n",
      "Completed fold 2/5\n",
      "Fold3 Ep1/20 - ValMacroF1=0.4871 Pat=0\n",
      "Fold3 Ep2/20 - ValMacroF1=0.6681 Pat=0\n",
      "Fold3 Ep3/20 - ValMacroF1=0.7053 Pat=0\n",
      "Fold3 Ep4/20 - ValMacroF1=0.6938 Pat=1\n",
      "Fold3 Ep5/20 - ValMacroF1=0.6715 Pat=2\n",
      "Fold3 Ep6/20 - ValMacroF1=0.6703 Pat=3\n",
      "Fold3 Ep7/20 - ValMacroF1=0.6685 Pat=4\n",
      "Stopping early at epoch 7\n",
      "Completed fold 3/5\n",
      "Fold4 Ep1/20 - ValMacroF1=0.4929 Pat=0\n",
      "Fold4 Ep2/20 - ValMacroF1=0.6783 Pat=0\n",
      "Fold4 Ep3/20 - ValMacroF1=0.7076 Pat=0\n",
      "Fold4 Ep4/20 - ValMacroF1=0.7154 Pat=0\n",
      "Fold4 Ep5/20 - ValMacroF1=0.7111 Pat=1\n",
      "Fold4 Ep6/20 - ValMacroF1=0.7158 Pat=0\n",
      "Fold4 Ep7/20 - ValMacroF1=0.7136 Pat=1\n",
      "Fold4 Ep8/20 - ValMacroF1=0.7164 Pat=0\n",
      "Fold4 Ep9/20 - ValMacroF1=0.7192 Pat=0\n",
      "Fold4 Ep10/20 - ValMacroF1=0.7136 Pat=1\n",
      "Fold4 Ep11/20 - ValMacroF1=0.7215 Pat=0\n",
      "Fold4 Ep12/20 - ValMacroF1=0.7159 Pat=1\n",
      "Fold4 Ep13/20 - ValMacroF1=0.7221 Pat=0\n",
      "Fold4 Ep14/20 - ValMacroF1=0.7180 Pat=1\n",
      "Fold4 Ep15/20 - ValMacroF1=0.7178 Pat=2\n",
      "Fold4 Ep16/20 - ValMacroF1=0.7178 Pat=3\n",
      "Fold4 Ep17/20 - ValMacroF1=0.7178 Pat=4\n",
      "Stopping early at epoch 17\n",
      "Completed fold 4/5\n",
      "Fold5 Ep1/20 - ValMacroF1=0.4929 Pat=0\n",
      "Fold5 Ep2/20 - ValMacroF1=0.6940 Pat=0\n",
      "Fold5 Ep3/20 - ValMacroF1=0.7105 Pat=0\n",
      "Fold5 Ep4/20 - ValMacroF1=0.7364 Pat=0\n",
      "Fold5 Ep5/20 - ValMacroF1=0.7283 Pat=1\n",
      "Fold5 Ep6/20 - ValMacroF1=0.7239 Pat=2\n",
      "Fold5 Ep7/20 - ValMacroF1=0.7218 Pat=3\n",
      "Fold5 Ep8/20 - ValMacroF1=0.7256 Pat=4\n",
      "Stopping early at epoch 8\n",
      "Completed fold 5/5\n",
      "Accuracy: 0.8474359225099255\n",
      "\n",
      "IND 1 Precision: 0.9151811234349528\n",
      "IND 1 Recall: 0.9127835051546391\n",
      "IND 1 F1-Score: 0.9139122483631157\n",
      "\n",
      "GRP 2 Precision: 0.679141211923773\n",
      "GRP 2 Recall: 0.7106328539966317\n",
      "GRP 2 F1-Score: 0.6925480612223278\n",
      "\n",
      "OTH 3 Precision: 0.6196300563236047\n",
      "OTH 3 Recall: 0.554\n",
      "OTH 3 F1-Score: 0.5798818202520424\n",
      "\n",
      "Weighted Avg Precision: 0.8482442305620277\n",
      "Weighted Avg Recall: 0.8474359225099255\n",
      "Weighted Avg F1-Score: 0.846821418594911\n",
      "\n",
      "Macro  Precision: 0.7379841305607769\n",
      "Macro  Recall: 0.7258054530504235\n",
      "Macro  F1-Score: 0.7287807099458287\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# --------- K-Fold Training ----------------\n",
    "skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "# Metrics storage (macro-averaged for multi-class)\n",
    "valf1 = []\n",
    "reports = []\n",
    "\n",
    "start = time.time()\n",
    "print(\"Local System Time:\", time.strftime(\"%I:%M %p\", time.localtime()))\n",
    "\n",
    "for fold, (tr, te) in enumerate(skf.split(df[xcolumn], df[ycolumn]), 1):\n",
    "    xtr = df.loc[tr, xcolumn].tolist(); ytr = df.loc[tr, ycolumn].values\n",
    "    xte = df.loc[te, xcolumn].tolist(); yte = df.loc[te, ycolumn].values\n",
    "    xtr, xv, ytr, yv = train_test_split(xtr, ytr, test_size=0.15, random_state=0)\n",
    "\n",
    "    # tokenize\n",
    "    enc_tr = tokenizer(xtr, padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    enc_v  = tokenizer(xv,  padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    enc_te = tokenizer(xte, padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "    # datasets & loaders\n",
    "    dt_tr = TextDataset(enc_tr, ytr); lt = DataLoader(dt_tr, batch_size=BATCH, shuffle=True)\n",
    "    dt_v  = TextDataset(enc_v,  yv); lv = DataLoader(dt_v, batch_size=BATCH)\n",
    "    dt_te = TextDataset(enc_te, yte); le = DataLoader(dt_te, batch_size=BATCH)\n",
    "\n",
    "    # model, loss, opt\n",
    "    model = BertClassifier(bertmodelname).to(device)\n",
    "    crit = nn.CrossEntropyLoss()   # changed to CrossEntropy\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=LR_RATE)\n",
    "\n",
    "    best_f, pt = -np.inf, 0\n",
    "\n",
    "    # train\n",
    "    for e in range(NEPOCHS):\n",
    "        model.train()\n",
    "        for b in lt:\n",
    "            opt.zero_grad()\n",
    "            ids = b['input_ids'].to(device); m = b['attention_mask'].to(device)\n",
    "            lbls = b['labels'].to(device)\n",
    "            logits = model(ids, m)\n",
    "            loss = crit(logits, lbls)\n",
    "            loss.backward(); opt.step()\n",
    "\n",
    "        # val\n",
    "        model.eval(); vp, vt = [], []\n",
    "        with torch.no_grad():\n",
    "            for b in lv:\n",
    "                ids = b['input_ids'].to(device); m = b['attention_mask'].to(device)\n",
    "                logits = model(ids, m)\n",
    "                preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "                vp.extend(preds.tolist()); vt.extend(b['labels'].cpu().numpy().tolist())\n",
    "\n",
    "       \n",
    "        valf1.append(f1_score(vt, vp, average='macro'))       \n",
    "        vm = valf1[-1]\n",
    "        if vm > best_f:\n",
    "            best_f, pt = vm, 0\n",
    "            torch.save(model.state_dict(), os.path.join(modelpath, f\"{modelname}_fold{fold}.bin\"))\n",
    "        else:\n",
    "            pt += 1\n",
    "        if DECAY and pt % DECAY_AFTER == 0 and pt != 0:\n",
    "            for g in opt.param_groups: g['lr'] *= DECAY_RATE\n",
    "        print(f\"Fold{fold} Ep{e+1}/{NEPOCHS} - ValMacroF1={vm:.4f} Pat={pt}\")\n",
    "        if pt >= PATIENCE:\n",
    "            print(f\"Stopping early at epoch {e+1}\")\n",
    "            break\n",
    "\n",
    "    # test eval\n",
    "    model.load_state_dict(torch.load(os.path.join(modelpath, f\"{modelname}_fold{fold}.bin\")))\n",
    "    model.eval(); tp, tt = [], []\n",
    "    with torch.no_grad():\n",
    "        for b in le:\n",
    "            ids = b['input_ids'].to(device); m = b['attention_mask'].to(device)\n",
    "            logits = model(ids, m)\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            tp.extend(preds.tolist()); tt.extend(b['labels'].cpu().numpy().tolist())\n",
    "\n",
    "    #testcm.append(confusion_matrix(tt, tp))\n",
    "    reports.append(classification_report( tt, tp, output_dict=True, zero_division=0,labels=[0, 1, 2], target_names=['IND 0', 'GRP 1', 'OTH 2']))\n",
    "    \n",
    "    print(f\"Completed fold {fold}/5\")\n",
    "    del model; torch.cuda.empty_cache(); gc.collect()\n",
    "    \n",
    "WriteResutls(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Index(['Unnamed: 0', 'Tweet', 'Tag'], dtype='object') (6594, 3)\n",
      "[1 2 3]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import gc, os,time,numpy as np, pandas as pd, datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, MT5EncoderModel, logging, AutoConfig, AutoModel\n",
    "# ------------ GPU Setup ------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if device.type == 'cuda':torch.cuda.empty_cache()\n",
    "\n",
    "# ---------- Hyperparameters ---------\n",
    "MAX_LEN = 128\n",
    "EMBED_SIZE = 768\n",
    "BERT_TRAINABLE = True\n",
    "DRPT = 0.4\n",
    "FC_ACT = 'elu'\n",
    "LR_RATE = 6e-5\n",
    "BATCH = 30  # reduced to lower GPU memory usage\n",
    "NEPOCHS = 20\n",
    "PATIENCE = 4\n",
    "DECAY = True\n",
    "DECAY_RATE = 0.3\n",
    "DECAY_AFTER = 1\n",
    "NUM_CLASSES = 3 \n",
    "\n",
    "modelname = 'hfFineTuneMT5'\n",
    "modelpath = os.path.join('.', 'Saved Models', modelname)\n",
    "modelresults = os.path.join('.', 'Model Results')\n",
    "modelsummaries = os.path.join('.', 'Model - Summaries-Figures')\n",
    "for d in [modelpath, modelresults, modelsummaries]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# ------------ Utils ----------------\n",
    "def hms_string(sec):\n",
    "    h = int(sec // 3600)\n",
    "    m = int((sec % 3600) // 60)\n",
    "    s = sec % 60\n",
    "    return f\"{h} hrs {m:02d} mins {s:05.2f} secs\"\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "# -------- Dataset Class -----------\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# -------- Model Definition --------      \n",
    "class MT5Classifier(nn.Module):\n",
    "    def __init__(self, model_name, dropout_rate=DRPT, num_classes=NUM_CLASSES):\n",
    "        super().__init__()\n",
    "        self.encoder = MT5EncoderModel.from_pretrained(model_name)\n",
    "        if not BERT_TRAINABLE:\n",
    "            for p in self.encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "        hidden = self.encoder.config.hidden_size\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(hidden, hidden)\n",
    "        self.act = nn.ELU()\n",
    "        self.out = nn.Linear(hidden, num_classes)    # output layer for multi-class\n",
    "        # init\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.kaiming_uniform_(self.out.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.out.bias)\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pool = out.last_hidden_state[:, 0]\n",
    "        x = self.dropout(pool)\n",
    "        x = self.act(self.fc1(x))\n",
    "        return self.out(x)   # raw logits\n",
    "\n",
    "# --------- Data Loading ------------\n",
    "########################################################\n",
    "def WriteResutls(reports):\n",
    "  unt0 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  tin1 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  Oth2 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  macroavg = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  weightedavg = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  accu = []\n",
    "  for report in reports:\n",
    "    for k,v in report.items():\n",
    "      if 'IND' in k:\n",
    "        unt0['precision'].append(v['precision'])\n",
    "        unt0['recall'].append(v['recall'])\n",
    "        unt0['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'GRP' in k:\n",
    "        tin1['precision'].append(v['precision'])\n",
    "        tin1['recall'].append(v['recall'])\n",
    "        tin1['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'OTH' in k:\n",
    "        Oth2['precision'].append(v['precision'])\n",
    "        Oth2['recall'].append(v['recall'])\n",
    "        Oth2['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'macro avg' in k:\n",
    "        macroavg['precision'].append(v['precision'])\n",
    "        macroavg['recall'].append(v['recall'])\n",
    "        macroavg['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'weighted avg' in k:\n",
    "        weightedavg['precision'].append(v['precision'])\n",
    "        weightedavg['recall'].append(v['recall'])\n",
    "        weightedavg['f1-score'].append(v['f1-score'])\n",
    "      elif 'accuracy' in k:\n",
    "        accu.append(v)\n",
    "\n",
    "  print('Accuracy:',np.mean(accu))\n",
    "  print(\"\")\n",
    "  print('IND 1 Precision:',np.mean(unt0['precision']))\n",
    "  print('IND 1 Recall:',np.mean(unt0['recall']))\n",
    "  print('IND 1 F1-Score:',np.mean(unt0['f1-score']))\n",
    "  print(\"\")\n",
    "  print('GRP 2 Precision:',np.mean(tin1['precision']))\n",
    "  print('GRP 2 Recall:',np.mean(tin1['recall']))\n",
    "  print('GRP 2 F1-Score:',np.mean(tin1['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('OTH 3 Precision:',np.mean(Oth2['precision']))\n",
    "  print('OTH 3 Recall:',np.mean(Oth2['recall']))\n",
    "  print('OTH 3 F1-Score:',np.mean(Oth2['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('Weighted Avg Precision:',np.mean(weightedavg['precision']))\n",
    "  print('Weighted Avg Recall:',np.mean(weightedavg['recall']))\n",
    "  print('Weighted Avg F1-Score:',np.mean(weightedavg['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('Macro  Precision:',np.mean(macroavg['precision']))\n",
    "  print('Macro  Recall:',np.mean(macroavg['recall']))\n",
    "  print('Macro  F1-Score:',np.mean(macroavg['f1-score']))\n",
    "\n",
    "  file = open( result_path, mode='a' )\n",
    "  file.write( modelname+ ' ( '+ datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") +') \\n' )\n",
    "  file.write( 'Accuracy:'+str(np.mean(accu))+'\\n' )\n",
    "  file.write('IND 1 Precision:'+str(np.mean(unt0['precision']))+'\\n' )\n",
    "  file.write('IND 1 Recall:'+str(np.mean(unt0['recall']))+'\\n' )\n",
    "  file.write('IND 1 F1-Score:'+str(np.mean(unt0['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('GRP 2 Precision:'+str(np.mean(tin1['precision']))+'\\n' )\n",
    "  file.write('GRP 2 Recall:'+str(np.mean(tin1['recall']))+'\\n' )\n",
    "  file.write('GRP 2 F1-Score:'+str(np.mean(tin1['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('OTH 3 Precision:'+str(np.mean(Oth2['precision']))+'\\n' )\n",
    "  file.write('OTH 3 Recall:'+str(np.mean(Oth2['recall']))+'\\n' )\n",
    "  file.write('OTH 3 F1-Score:'+str(np.mean(Oth2['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('Weighted Avg Precision:'+str(np.mean(weightedavg['precision']))+'\\n' )\n",
    "  file.write('Weighted Avg Recall:'+str(np.mean(weightedavg['recall']))+'\\n' )\n",
    "  file.write('Weighted Avg F1-Score:'+str(np.mean(weightedavg['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('Macro  Precision:'+str(np.mean(macroavg['precision']))+'\\n' )\n",
    "  file.write('Macro  Recall:'+str(np.mean(macroavg['recall']))+'\\n' )\n",
    "  file.write('Macro  F1-Score:'+str(np.mean(macroavg['f1-score']))+'\\n' )\n",
    "  file.close()\n",
    "  print(\"Done\")\n",
    "######################################################################################\n",
    "# -------------- Data Loading ---------------\n",
    "result_path =  r'C:\\Users\\mojua\\Desktop\\DL-Code\\T3-LLM-Classification-Result.csv'\n",
    "file_path = r'C:\\Users\\mojua\\Desktop\\DL-Code\\Dataset\\Offensive-24K-T3.xlsx'\n",
    "\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "df['Tweet'] = df['Tweet'].astype(str)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.columns, df.shape)\n",
    "print(df.Tag.unique())\n",
    "df['Tag'] = df['Tag'].replace({1: 0, 2: 1, 3: 2})\n",
    "print(df.Tag.unique())\n",
    "xcolumn = 'Tweet'\n",
    "ycolumn = 'Tag'\n",
    "# --------- Tokenizer Setup --------\n",
    "bertmodelname = 'google/mt5-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(bertmodelname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 01:08 PM\n",
      "Fold1 Ep1: Val MacroF1=0.2955 Pat=0\n",
      "Fold1 Ep2: Val MacroF1=0.3455 Pat=0\n",
      "Fold1 Ep3: Val MacroF1=0.3784 Pat=0\n",
      "Fold1 Ep4: Val MacroF1=0.4874 Pat=0\n",
      "Fold1 Ep5: Val MacroF1=0.4095 Pat=1\n",
      "Fold1 Ep6: Val MacroF1=0.5169 Pat=0\n",
      "Fold1 Ep7: Val MacroF1=0.5014 Pat=1\n",
      "Fold1 Ep8: Val MacroF1=0.5157 Pat=2\n",
      "Fold1 Ep9: Val MacroF1=0.4949 Pat=3\n",
      "Fold1 Ep10: Val MacroF1=0.4962 Pat=4\n",
      "Stopping early at epoch 10\n",
      "Fold1 done at 01:17 PM\n",
      "Fold2 Ep1: Val MacroF1=0.2843 Pat=0\n",
      "Fold2 Ep2: Val MacroF1=0.2843 Pat=1\n",
      "Fold2 Ep3: Val MacroF1=0.2843 Pat=2\n",
      "Fold2 Ep4: Val MacroF1=0.2843 Pat=3\n",
      "Fold2 Ep5: Val MacroF1=0.2843 Pat=4\n",
      "Stopping early at epoch 5\n",
      "Fold2 done at 01:27 PM\n",
      "Fold3 Ep1: Val MacroF1=0.2953 Pat=0\n",
      "Fold3 Ep2: Val MacroF1=0.3122 Pat=0\n",
      "Fold3 Ep3: Val MacroF1=0.4014 Pat=0\n",
      "Fold3 Ep4: Val MacroF1=0.4532 Pat=0\n",
      "Fold3 Ep5: Val MacroF1=0.4529 Pat=1\n",
      "Fold3 Ep6: Val MacroF1=0.4725 Pat=0\n",
      "Fold3 Ep7: Val MacroF1=0.4825 Pat=0\n",
      "Fold3 Ep8: Val MacroF1=0.4782 Pat=1\n",
      "Fold3 Ep9: Val MacroF1=0.4740 Pat=2\n",
      "Fold3 Ep10: Val MacroF1=0.4649 Pat=3\n",
      "Fold3 Ep11: Val MacroF1=0.4652 Pat=4\n",
      "Stopping early at epoch 11\n",
      "Fold3 done at 01:48 PM\n",
      "Fold4 Ep1: Val MacroF1=0.2789 Pat=0\n",
      "Fold4 Ep2: Val MacroF1=0.3754 Pat=0\n",
      "Fold4 Ep3: Val MacroF1=0.4233 Pat=0\n",
      "Fold4 Ep4: Val MacroF1=0.4684 Pat=0\n",
      "Fold4 Ep5: Val MacroF1=0.6178 Pat=0\n",
      "Fold4 Ep6: Val MacroF1=0.6979 Pat=0\n",
      "Fold4 Ep7: Val MacroF1=0.7023 Pat=0\n",
      "Fold4 Ep8: Val MacroF1=0.7324 Pat=0\n",
      "Fold4 Ep9: Val MacroF1=0.7301 Pat=1\n",
      "Fold4 Ep10: Val MacroF1=0.7432 Pat=0\n",
      "Fold4 Ep11: Val MacroF1=0.7577 Pat=0\n",
      "Fold4 Ep12: Val MacroF1=0.7605 Pat=0\n",
      "Fold4 Ep13: Val MacroF1=0.7537 Pat=1\n",
      "Fold4 Ep14: Val MacroF1=0.7614 Pat=0\n",
      "Fold4 Ep15: Val MacroF1=0.7496 Pat=1\n",
      "Fold4 Ep16: Val MacroF1=0.7496 Pat=2\n",
      "Fold4 Ep17: Val MacroF1=0.7496 Pat=3\n",
      "Fold4 Ep18: Val MacroF1=0.7502 Pat=4\n",
      "Stopping early at epoch 18\n",
      "Fold4 done at 02:26 PM\n",
      "Fold5 Ep1: Val MacroF1=0.2833 Pat=0\n",
      "Fold5 Ep2: Val MacroF1=0.3350 Pat=0\n",
      "Fold5 Ep3: Val MacroF1=0.3651 Pat=0\n",
      "Fold5 Ep4: Val MacroF1=0.3783 Pat=0\n",
      "Fold5 Ep5: Val MacroF1=0.3902 Pat=0\n",
      "Fold5 Ep6: Val MacroF1=0.4368 Pat=0\n",
      "Fold5 Ep7: Val MacroF1=0.4568 Pat=0\n",
      "Fold5 Ep8: Val MacroF1=0.4251 Pat=1\n",
      "Fold5 Ep9: Val MacroF1=0.4312 Pat=2\n",
      "Fold5 Ep10: Val MacroF1=0.4449 Pat=3\n",
      "Fold5 Ep11: Val MacroF1=0.4489 Pat=4\n",
      "Stopping early at epoch 11\n",
      "Fold5 done at 02:50 PM\n",
      "Total runtime: 1 hrs 42 mins 04.92 secs\n",
      "Accuracy: 0.7773712324023465\n",
      "\n",
      "IND 1 Precision: 0.7993770446261149\n",
      "IND 1 Recall: 0.9655670103092783\n",
      "IND 1 F1-Score: 0.8721620748606366\n",
      "\n",
      "GRP 2 Precision: 0.5233591800356507\n",
      "GRP 2 Recall: 0.2619769400181371\n",
      "GRP 2 F1-Score: 0.3198688459885487\n",
      "\n",
      "OTH 3 Precision: 0.45108743249160704\n",
      "OTH 3 Recall: 0.23399999999999999\n",
      "OTH 3 F1-Score: 0.2938233476141294\n",
      "\n",
      "Weighted Avg Precision: 0.7208860515800649\n",
      "Weighted Avg Recall: 0.7773712324023465\n",
      "Weighted Avg F1-Score: 0.7241228251615126\n",
      "\n",
      "Macro  Precision: 0.5912745523844575\n",
      "Macro  Recall: 0.4871813167758051\n",
      "Macro  F1-Score: 0.4952847561544383\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# --- K-Fold Training -------------\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "val_f1_macro, test_f1_macro = [], []\n",
    "start = time.time()\n",
    "print('Start:', time.strftime(\"%I:%M %p\"))\n",
    "reports = []\n",
    "for fold, (tr, te) in enumerate(skf.split(df[xcolumn], df[ycolumn]), 1):\n",
    "    # split\n",
    "    X_tr = df.loc[tr, xcolumn].tolist()\n",
    "    y_tr = df.loc[tr, ycolumn].values\n",
    "    X_te = df.loc[te, xcolumn].tolist()\n",
    "    y_te = df.loc[te, ycolumn].values\n",
    "    # train/val split\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X_tr, y_tr, test_size=0.15, random_state=0\n",
    "    )\n",
    "    # encodings\n",
    "    enc_tr = tokenizer(X_tr, padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    enc_val = tokenizer(X_val, padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    enc_te = tokenizer(X_te, padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    # datasets\n",
    "    ds_tr = TextDataset(enc_tr, y_tr)\n",
    "    ds_val = TextDataset(enc_val, y_val)\n",
    "    ds_te = TextDataset(enc_te, y_te)\n",
    "\n",
    "    # dataloaders\n",
    "    ld_tr = DataLoader(ds_tr, batch_size=BATCH, shuffle=True, pin_memory=True)\n",
    "    ld_val = DataLoader(ds_val, batch_size=BATCH, pin_memory=True)\n",
    "    ld_te = DataLoader(ds_te, batch_size=BATCH, pin_memory=True)\n",
    "\n",
    "    # model, loss, optimizer\n",
    "    model = MT5Classifier(bertmodelname).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR_RATE)\n",
    "    best_val_f1, patience = 0.0, 0\n",
    "    for epoch in range(NEPOCHS):\n",
    "        model.train()\n",
    "        for b in ld_tr:\n",
    "            optimizer.zero_grad()\n",
    "            ids = b['input_ids'].to(device)\n",
    "            masks = b['attention_mask'].to(device)\n",
    "            labels = b['labels'].to(device)\n",
    "\n",
    "            logits = model(ids, masks)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        vt, vp = [], []\n",
    "        with torch.no_grad():\n",
    "            for b in ld_val:\n",
    "                logits = model(b['input_ids'].to(device), b['attention_mask'].to(device))\n",
    "                preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "                vp.extend(preds.tolist())\n",
    "                vt.extend(b['labels'].cpu().numpy().tolist())       \n",
    "        f1m = f1_score(vt, vp, average='macro')\n",
    "        # save best\n",
    "        if f1m > best_val_f1:\n",
    "            best_val_f1, patience = f1m, 0\n",
    "            torch.save(model.state_dict(), os.path.join(modelpath, f\"{modelname}_fold{fold}.pt\"))\n",
    "        else:\n",
    "            patience += 1\n",
    "            if DECAY and patience % DECAY_AFTER == 0:\n",
    "                for g in optimizer.param_groups:\n",
    "                    g['lr'] *= DECAY_RATE\n",
    "\n",
    "        print(f\"Fold{fold} Ep{epoch+1}: Val MacroF1={f1m:.4f} Pat={patience}\")\n",
    "        if patience >= PATIENCE:\n",
    "            print(f\"Stopping early at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # test\n",
    "    model.load_state_dict(torch.load(os.path.join(modelpath, f\"{modelname}_fold{fold}.pt\")))\n",
    "    model.eval()\n",
    "    tt, tp = [], []\n",
    "    with torch.no_grad():\n",
    "        for b in ld_te:\n",
    "            logits = model(b['input_ids'].to(device), b['attention_mask'].to(device))\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            tp.extend(preds.tolist())\n",
    "            tt.extend(b['labels'].cpu().numpy().tolist())\n",
    "    \n",
    "   # testcm.append(confusion_matrix(tt, tp))\n",
    "    reports.append(classification_report( tt, tp, output_dict=True, zero_division=0,labels=[0, 1, 2], target_names=['IND 0', 'GRP 1', 'OTH 2']))\n",
    "    print(f\"Fold{fold} done at {time.strftime('%I:%M %p')}\")\n",
    "\n",
    "    # cleanup\n",
    "    del model, optimizer, criterion\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"Total runtime: {hms_string(time.time()-start)}\")\n",
    "WriteResutls(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start from here in case of failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "   Unnamed: 0                                              Tweet  Tag\n",
      "0           3                   USER گھٹیا انسان دنیا ہی چھوڑ دو    1\n",
      "1          11  USER PMLN میں آپ کے بارے میں میری بہتر راۓ تھی...    1\n",
      "2          20  ہمیں تو آج تک سمجھ نہیں آئی کہ کم عقل عیسائی ح...    2\n",
      "3          21  کیا پتہ اس گدھے کو بھی ہینڈلرز کی طرف سے گرین ...    1\n",
      "4          25  USER ون آن ون والی پہلے اپنی اوقات تو کر لو۔ ی...    1\n",
      "[1 2 3]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc, os,time, numpy as np,pandas as pd, datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel, logging\n",
    "# ------------- GPU Setup ------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if device.type == 'cuda': torch.cuda.empty_cache()\n",
    "# ---------- Hyperparameters ---------\n",
    "MAX_LEN = 128\n",
    "EMBED_SIZE = 768\n",
    "BERT_TRAINABLE = True\n",
    "DRPT = 0.4\n",
    "FC_ACT = 'elu'\n",
    "LR_RATE = 9e-6\n",
    "BATCH = 32\n",
    "NEPOCHS = 20\n",
    "PATIENCE = 5\n",
    "DECAY = True\n",
    "DECAY_RATE = 0.3\n",
    "DECAY_AFTER = 1\n",
    "num_classes = 3\n",
    "\n",
    "modelname = 'hfFineTuneMuril'\n",
    "modelpath = os.path.join('.', 'Saved Models', modelname)\n",
    "modelresults = os.path.join('.', 'Model Results')\n",
    "modelsummaries = os.path.join('.', 'Model - Summaries-Figures')\n",
    "for d in [modelpath, modelresults, modelsummaries]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# ---------- Utils ------------------\n",
    "def hms_string(sec):\n",
    "    h = int(sec // 3600)\n",
    "    m = int((sec % 3600) // 60)\n",
    "    s = sec % 60\n",
    "    return f\"{h} hrs {m:02d} mins {s:05.2f} secs\"\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# -------- Dataset Class -----------\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __len__(self): return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# ------- Model Definition ----------\n",
    "class MurilClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_classes, dropout_rate=DRPT):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        if not BERT_TRAINABLE:\n",
    "            for p in self.bert.parameters(): p.requires_grad = False\n",
    "        hidden = self.bert.config.hidden_size\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(hidden, hidden)\n",
    "        self.act = nn.ELU()\n",
    "        self.out = nn.Linear(hidden, num_classes)\n",
    "        # he_uniform init\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.kaiming_uniform_(self.out.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.out.bias)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        o = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = o.pooler_output if hasattr(o, 'pooler_output') and o.pooler_output is not None else o.last_hidden_state[:,0]\n",
    "        x = self.dropout(pooled)\n",
    "        x = self.act(self.fc1(x))\n",
    "        return self.out(x)  # logits\n",
    "        \n",
    "# ---------- Data Loading -----------\n",
    "########################################################\n",
    "def WriteResutls(reports):\n",
    "\n",
    "  unt0 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  tin1 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  Oth2 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  macroavg = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  weightedavg = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  accu = []\n",
    "  for report in reports:\n",
    "    for k,v in report.items():\n",
    "      if 'IND' in k:\n",
    "        unt0['precision'].append(v['precision'])\n",
    "        unt0['recall'].append(v['recall'])\n",
    "        unt0['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'GRP' in k:\n",
    "        tin1['precision'].append(v['precision'])\n",
    "        tin1['recall'].append(v['recall'])\n",
    "        tin1['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'OTH' in k:\n",
    "        Oth2['precision'].append(v['precision'])\n",
    "        Oth2['recall'].append(v['recall'])\n",
    "        Oth2['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'macro avg' in k:\n",
    "        macroavg['precision'].append(v['precision'])\n",
    "        macroavg['recall'].append(v['recall'])\n",
    "        macroavg['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'weighted avg' in k:\n",
    "        weightedavg['precision'].append(v['precision'])\n",
    "        weightedavg['recall'].append(v['recall'])\n",
    "        weightedavg['f1-score'].append(v['f1-score'])\n",
    "      elif 'accuracy' in k:\n",
    "        accu.append(v)\n",
    "\n",
    "  print('Accuracy:',np.mean(accu))\n",
    "  print(\"\")\n",
    "  print('IND 1 Precision:',np.mean(unt0['precision']))\n",
    "  print('IND 1 Recall:',np.mean(unt0['recall']))\n",
    "  print('IND 1 F1-Score:',np.mean(unt0['f1-score']))\n",
    "  print(\"\")\n",
    "  print('GRP 2 Precision:',np.mean(tin1['precision']))\n",
    "  print('GRP 2 Recall:',np.mean(tin1['recall']))\n",
    "  print('GRP 2 F1-Score:',np.mean(tin1['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('OTH 3 Precision:',np.mean(Oth2['precision']))\n",
    "  print('OTH 3 Recall:',np.mean(Oth2['recall']))\n",
    "  print('OTH 3 F1-Score:',np.mean(Oth2['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('Weighted Avg Precision:',np.mean(weightedavg['precision']))\n",
    "  print('Weighted Avg Recall:',np.mean(weightedavg['recall']))\n",
    "  print('Weighted Avg F1-Score:',np.mean(weightedavg['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('Macro  Precision:',np.mean(macroavg['precision']))\n",
    "  print('Macro  Recall:',np.mean(macroavg['recall']))\n",
    "  print('Macro  F1-Score:',np.mean(macroavg['f1-score']))\n",
    "\n",
    "  file = open( result_path, mode='a' )\n",
    "  file.write( modelname+ ' ( '+ datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") +') \\n' )\n",
    "  file.write( 'Accuracy:'+str(np.mean(accu))+'\\n' )\n",
    "  file.write('IND 1 Precision:'+str(np.mean(unt0['precision']))+'\\n' )\n",
    "  file.write('IND 1 Recall:'+str(np.mean(unt0['recall']))+'\\n' )\n",
    "  file.write('IND 1 F1-Score:'+str(np.mean(unt0['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('GRP 2 Precision:'+str(np.mean(tin1['precision']))+'\\n' )\n",
    "  file.write('GRP 2 Recall:'+str(np.mean(tin1['recall']))+'\\n' )\n",
    "  file.write('GRP 2 F1-Score:'+str(np.mean(tin1['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('OTH 3 Precision:'+str(np.mean(Oth2['precision']))+'\\n' )\n",
    "  file.write('OTH 3 Recall:'+str(np.mean(Oth2['recall']))+'\\n' )\n",
    "  file.write('OTH 3 F1-Score:'+str(np.mean(Oth2['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('Weighted Avg Precision:'+str(np.mean(weightedavg['precision']))+'\\n' )\n",
    "  file.write('Weighted Avg Recall:'+str(np.mean(weightedavg['recall']))+'\\n' )\n",
    "  file.write('Weighted Avg F1-Score:'+str(np.mean(weightedavg['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('Macro  Precision:'+str(np.mean(macroavg['precision']))+'\\n' )\n",
    "  file.write('Macro  Recall:'+str(np.mean(macroavg['recall']))+'\\n' )\n",
    "  file.write('Macro  F1-Score:'+str(np.mean(macroavg['f1-score']))+'\\n' )\n",
    "  file.close()\n",
    "  print(\"Done\")\n",
    "######################################################################################\n",
    "# -------------- Data Loading ---------------\n",
    "result_path =  r'C:\\Users\\mojua\\Desktop\\DL-Code\\T3-LLM-Classification-Result.csv'\n",
    "file_path = r'C:\\Users\\mojua\\Desktop\\DL-Code\\Dataset\\Offensive-24K-T3.xlsx'\n",
    "\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "df['Tweet'] = df['Tweet'].astype(str)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.head())\n",
    "print(df.Tag.unique())\n",
    "df['Tag'] = df['Tag'].replace({1: 0, 2: 1, 3: 2})\n",
    "print(df.Tag.unique())\n",
    "xcolumn = 'Tweet'\n",
    "ycolumn = 'Tag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 02:58 PM\n",
      "Fold1 Ep1/20 - ValMacroF1=0.2821 Pat=0\n",
      "Fold1 Ep2/20 - ValMacroF1=0.2821 Pat=1\n",
      "Fold1 Ep3/20 - ValMacroF1=0.2821 Pat=2\n",
      "Fold1 Ep4/20 - ValMacroF1=0.2821 Pat=3\n",
      "Fold1 Ep5/20 - ValMacroF1=0.2821 Pat=4\n",
      "Fold1 Ep6/20 - ValMacroF1=0.2821 Pat=5\n",
      "Completed fold 1/5\n",
      "Fold2 Ep1/20 - ValMacroF1=0.2843 Pat=0\n",
      "Fold2 Ep2/20 - ValMacroF1=0.2843 Pat=1\n",
      "Fold2 Ep3/20 - ValMacroF1=0.2843 Pat=2\n",
      "Fold2 Ep4/20 - ValMacroF1=0.2843 Pat=3\n",
      "Fold2 Ep5/20 - ValMacroF1=0.4752 Pat=0\n",
      "Fold2 Ep6/20 - ValMacroF1=0.4880 Pat=0\n",
      "Fold2 Ep7/20 - ValMacroF1=0.4807 Pat=1\n",
      "Fold2 Ep8/20 - ValMacroF1=0.4815 Pat=2\n",
      "Fold2 Ep9/20 - ValMacroF1=0.4797 Pat=3\n",
      "Fold2 Ep10/20 - ValMacroF1=0.4797 Pat=4\n",
      "Fold2 Ep11/20 - ValMacroF1=0.4797 Pat=5\n",
      "Completed fold 2/5\n",
      "Fold3 Ep1/20 - ValMacroF1=0.2860 Pat=0\n",
      "Fold3 Ep2/20 - ValMacroF1=0.2860 Pat=1\n",
      "Fold3 Ep3/20 - ValMacroF1=0.2860 Pat=2\n",
      "Fold3 Ep4/20 - ValMacroF1=0.4751 Pat=0\n",
      "Fold3 Ep5/20 - ValMacroF1=0.4759 Pat=0\n",
      "Fold3 Ep6/20 - ValMacroF1=0.4782 Pat=0\n",
      "Fold3 Ep7/20 - ValMacroF1=0.4812 Pat=0\n",
      "Fold3 Ep8/20 - ValMacroF1=0.4868 Pat=0\n",
      "Fold3 Ep9/20 - ValMacroF1=0.4874 Pat=0\n",
      "Fold3 Ep10/20 - ValMacroF1=0.4968 Pat=0\n",
      "Fold3 Ep11/20 - ValMacroF1=0.4899 Pat=1\n",
      "Fold3 Ep12/20 - ValMacroF1=0.4960 Pat=2\n",
      "Fold3 Ep13/20 - ValMacroF1=0.4965 Pat=3\n",
      "Fold3 Ep14/20 - ValMacroF1=0.4974 Pat=0\n",
      "Fold3 Ep15/20 - ValMacroF1=0.4974 Pat=1\n",
      "Fold3 Ep16/20 - ValMacroF1=0.4941 Pat=2\n",
      "Fold3 Ep17/20 - ValMacroF1=0.4941 Pat=3\n",
      "Fold3 Ep18/20 - ValMacroF1=0.4941 Pat=4\n",
      "Fold3 Ep19/20 - ValMacroF1=0.4941 Pat=5\n",
      "Completed fold 3/5\n",
      "Fold4 Ep1/20 - ValMacroF1=0.2790 Pat=0\n",
      "Fold4 Ep2/20 - ValMacroF1=0.2790 Pat=1\n",
      "Fold4 Ep3/20 - ValMacroF1=0.2790 Pat=2\n",
      "Fold4 Ep4/20 - ValMacroF1=0.2790 Pat=3\n",
      "Fold4 Ep5/20 - ValMacroF1=0.2790 Pat=4\n",
      "Fold4 Ep6/20 - ValMacroF1=0.2790 Pat=5\n",
      "Completed fold 4/5\n",
      "Fold5 Ep1/20 - ValMacroF1=0.2793 Pat=0\n",
      "Fold5 Ep2/20 - ValMacroF1=0.2793 Pat=1\n",
      "Fold5 Ep3/20 - ValMacroF1=0.2793 Pat=2\n",
      "Fold5 Ep4/20 - ValMacroF1=0.2793 Pat=3\n",
      "Fold5 Ep5/20 - ValMacroF1=0.2793 Pat=4\n",
      "Fold5 Ep6/20 - ValMacroF1=0.2793 Pat=5\n",
      "Completed fold 5/5\n",
      "Total runtime: 0 hrs 20 mins 38.01 secs\n",
      "Accuracy: 0.7575035577833484\n",
      "\n",
      "IND 1 Precision: 0.787358241333665\n",
      "IND 1 Recall: 0.9686597938144331\n",
      "IND 1 F1-Score: 0.8652946823851089\n",
      "\n",
      "GRP 2 Precision: 0.2098337359670314\n",
      "GRP 2 Recall: 0.23855421686746986\n",
      "GRP 2 F1-Score: 0.22100270616721263\n",
      "\n",
      "OTH 3 Precision: 0.0\n",
      "OTH 3 Recall: 0.0\n",
      "OTH 3 F1-Score: 0.0\n",
      "\n",
      "Weighted Avg Precision: 0.618722079475369\n",
      "Weighted Avg Recall: 0.7575035577833484\n",
      "Weighted Avg F1-Score: 0.6781579384094651\n",
      "\n",
      "Macro  Precision: 0.3323973257668988\n",
      "Macro  Recall: 0.40240467022730086\n",
      "Macro  F1-Score: 0.36209912951744055\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# ----- K-Fold Training -------------\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# ---------- Tokenizer -------------\n",
    "bertmodelname = 'google/muril-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(bertmodelname)\n",
    "# metrics storage\n",
    "reports = []\n",
    "val_f1 =[]\n",
    "start = time.time()\n",
    "print('Start:', time.strftime('%I:%M %p'))\n",
    "for fold, (tr, te) in enumerate(skf.split(df[xcolumn], df[ycolumn]), 1):\n",
    "    X_tr = df.loc[tr, xcolumn].tolist()\n",
    "    y_tr = df.loc[tr, ycolumn].values\n",
    "    X_te = df.loc[te, xcolumn].tolist()\n",
    "    y_te = df.loc[te, ycolumn].values\n",
    "\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(X_tr, y_tr, test_size=0.15, random_state=0)\n",
    "\n",
    "    enc_tr = tokenizer(X_tr,   padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    enc_val= tokenizer(X_val,  padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    enc_te = tokenizer(X_te,   padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "    ld_tr  = DataLoader(TextDataset(enc_tr, y_tr), batch_size=BATCH, shuffle=True)\n",
    "    ld_val = DataLoader(TextDataset(enc_val, y_val), batch_size=BATCH)\n",
    "    ld_te  = DataLoader(TextDataset(enc_te, y_te), batch_size=BATCH)\n",
    "\n",
    "    model = MurilClassifier(bertmodelname, num_classes).to(device)\n",
    "    crit  = nn.CrossEntropyLoss()\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=LR_RATE)\n",
    "    best_val_f1, patience = -np.inf, 0\n",
    "    for ep in range(NEPOCHS):\n",
    "        model.train()\n",
    "        for b in ld_tr:\n",
    "            opt.zero_grad()\n",
    "            ids    = b['input_ids'].to(device)\n",
    "            mask   = b['attention_mask'].to(device)\n",
    "            labels = b['labels'].to(device)\n",
    "            logits = model(ids, mask)\n",
    "            loss   = crit(logits, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        preds, trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for b in ld_val:\n",
    "                ids    = b['input_ids'].to(device)\n",
    "                mask   = b['attention_mask'].to(device)\n",
    "                logits = model(ids, mask).cpu().numpy()\n",
    "                preds.extend(np.argmax(logits, axis=1).tolist())\n",
    "                trues.extend(b['labels'].cpu().numpy().tolist()) \n",
    "        val_f1.append(       f1_score(trues, preds, average='macro'))\n",
    "        vf1 = val_f1[-1]\n",
    "        if vf1 > best_val_f1:\n",
    "            best_val_f1, patience = vf1, 0\n",
    "            torch.save(model.state_dict(), os.path.join(modelpath, f\"{modelname}_fold{fold}.pt\"))\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        if DECAY and patience % DECAY_AFTER == 0 and patience != 0:\n",
    "            for g in opt.param_groups:\n",
    "                g['lr'] *= DECAY_RATE\n",
    "\n",
    "        print(f\"Fold{fold} Ep{ep+1}/{NEPOCHS} - ValMacroF1={vf1:.4f} Pat={patience}\")\n",
    "        if patience >= PATIENCE:\n",
    "            break\n",
    "\n",
    "    # test evaluation\n",
    "    model.load_state_dict(torch.load(os.path.join(modelpath, f\"{modelname}_fold{fold}.pt\")))\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for b in ld_te:\n",
    "            ids    = b['input_ids'].to(device)\n",
    "            mask   = b['attention_mask'].to(device)\n",
    "            logits = model(ids, mask).cpu().numpy()\n",
    "            preds.extend(np.argmax(logits, axis=1).tolist())\n",
    "            trues.extend(b['labels'].cpu().numpy().tolist())\n",
    "    reports.append(classification_report( trues, preds, output_dict=True, zero_division=0,labels=[0, 1, 2], target_names=['IND 0', 'GRP 1', 'OTH 2']))\n",
    "    print(f\"Completed fold {fold}/5\")\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"Total runtime: {hms_string(time.time()-start)}\")\n",
    "WriteResutls(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "def WriteResutls(reports):\n",
    "  unt0 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  tin1 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  Oth2 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  macroavg = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  weightedavg = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  accu = []\n",
    "  for report in reports:\n",
    "    for k,v in report.items():\n",
    "      if 'IND' in k:\n",
    "        unt0['precision'].append(v['precision'])\n",
    "        unt0['recall'].append(v['recall'])\n",
    "        unt0['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'GRP' in k:\n",
    "        tin1['precision'].append(v['precision'])\n",
    "        tin1['recall'].append(v['recall'])\n",
    "        tin1['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'OTH' in k:\n",
    "        Oth2['precision'].append(v['precision'])\n",
    "        Oth2['recall'].append(v['recall'])\n",
    "        Oth2['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'macro avg' in k:\n",
    "        macroavg['precision'].append(v['precision'])\n",
    "        macroavg['recall'].append(v['recall'])\n",
    "        macroavg['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'weighted avg' in k:\n",
    "        weightedavg['precision'].append(v['precision'])\n",
    "        weightedavg['recall'].append(v['recall'])\n",
    "        weightedavg['f1-score'].append(v['f1-score'])\n",
    "      elif 'accuracy' in k:\n",
    "        accu.append(v)\n",
    "\n",
    "  print('Accuracy:',np.mean(accu))\n",
    "  print(\"\")\n",
    "  print('IND 1 Precision:',np.mean(unt0['precision']))\n",
    "  print('IND 1 Recall:',np.mean(unt0['recall']))\n",
    "  print('IND 1 F1-Score:',np.mean(unt0['f1-score']))\n",
    "  print(\"\")\n",
    "  print('GRP 2 Precision:',np.mean(tin1['precision']))\n",
    "  print('GRP 2 Recall:',np.mean(tin1['recall']))\n",
    "  print('GRP 2 F1-Score:',np.mean(tin1['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('OTH 3 Precision:',np.mean(Oth2['precision']))\n",
    "  print('OTH 3 Recall:',np.mean(Oth2['recall']))\n",
    "  print('OTH 3 F1-Score:',np.mean(Oth2['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('Weighted Avg Precision:',np.mean(weightedavg['precision']))\n",
    "  print('Weighted Avg Recall:',np.mean(weightedavg['recall']))\n",
    "  print('Weighted Avg F1-Score:',np.mean(weightedavg['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('Macro  Precision:',np.mean(macroavg['precision']))\n",
    "  print('Macro  Recall:',np.mean(macroavg['recall']))\n",
    "  print('Macro  F1-Score:',np.mean(macroavg['f1-score']))\n",
    "\n",
    "  file = open( result_path, mode='a' )\n",
    "  file.write( modelname+ ' ( '+ datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") +') \\n' )\n",
    "  file.write( 'Accuracy:'+str(np.mean(accu))+'\\n' )\n",
    "  file.write('IND 1 Precision:'+str(np.mean(unt0['precision']))+'\\n' )\n",
    "  file.write('IND 1 Recall:'+str(np.mean(unt0['recall']))+'\\n' )\n",
    "  file.write('IND 1 F1-Score:'+str(np.mean(unt0['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('GRP 2 Precision:'+str(np.mean(tin1['precision']))+'\\n' )\n",
    "  file.write('GRP 2 Recall:'+str(np.mean(tin1['recall']))+'\\n' )\n",
    "  file.write('GRP 2 F1-Score:'+str(np.mean(tin1['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('OTH 3 Precision:'+str(np.mean(Oth2['precision']))+'\\n' )\n",
    "  file.write('OTH 3 Recall:'+str(np.mean(Oth2['recall']))+'\\n' )\n",
    "  file.write('OTH 3 F1-Score:'+str(np.mean(Oth2['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('Weighted Avg Precision:'+str(np.mean(weightedavg['precision']))+'\\n' )\n",
    "  file.write('Weighted Avg Recall:'+str(np.mean(weightedavg['recall']))+'\\n' )\n",
    "  file.write('Weighted Avg F1-Score:'+str(np.mean(weightedavg['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('Macro  Precision:'+str(np.mean(macroavg['precision']))+'\\n' )\n",
    "  file.write('Macro  Recall:'+str(np.mean(macroavg['recall']))+'\\n' )\n",
    "  file.write('Macro  F1-Score:'+str(np.mean(macroavg['f1-score']))+'\\n' )\n",
    "  file.close()\n",
    "  print(\"Done\")\n",
    "######################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "um8bhzeKzC37",
    "outputId": "44e06191-3886-4dec-8eda-afb83ffa7fcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "[1 2 3]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "import gc, os, time, numpy as np, pandas as pd, datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaConfig, XLMRobertaModel, logging\n",
    "# ---------------- GPU Setup ----------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if device.type == 'cuda': torch.cuda.empty_cache()\n",
    "# ------------- Hyperparameters ------------\n",
    "MAX_LEN = 128\n",
    "EMBED_SIZE = 768  # same as hidden_size\n",
    "BERT_TRAINABLE = True\n",
    "DRPT = 0.4\n",
    "FC_WEIGHTS_INIT = 'he_uniform'\n",
    "FC_ACT = 'elu'\n",
    "LR_RATE = 9e-6\n",
    "BATCH = 32\n",
    "NEPOCHS = 20\n",
    "PATIENCE = 5\n",
    "DECAY = True\n",
    "DECAY_RATE = 0.3\n",
    "DECAY_AFTER = 1\n",
    "num_classes = 3\n",
    "\n",
    "result_path =  r'C:\\Users\\mojua\\Desktop\\DL-Code\\T3-LLM-Classification-Result.csv'\n",
    "file_path = r'C:\\Users\\mojua\\Desktop\\DL-Code\\Dataset\\Offensive-24K-T3.xlsx'\n",
    "modelname = 'hfFineTuneRoberta'\n",
    "\n",
    "modelpath = os.path.join('.', 'Saved Models', modelname)\n",
    "modelresults = os.path.join('.', 'Model Results')\n",
    "modelsummaries = os.path.join('.', 'Model - Summaries-Figures')\n",
    "for d in [modelpath, modelresults, modelsummaries]: os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# --------------- Utils ---------------------\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / 3600)\n",
    "    m = int((sec_elapsed % 3600) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return f\"{h} hrs {m:02d} mins {s:05.2f} secs\"\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# ----------- Dataset Class ----------------\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "class RobertaClassifier(nn.Module):\n",
    "    def __init__(self, model_name, num_classes, dropout_rate=DRPT):\n",
    "        super().__init__()\n",
    "        self.bert = XLMRobertaModel.from_pretrained(model_name)\n",
    "        if not BERT_TRAINABLE:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        hidden = self.bert.config.hidden_size\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(hidden, hidden)\n",
    "        self.act = nn.ELU()\n",
    "        self.out = nn.Linear(hidden, num_classes)\n",
    "        # he_uniform init\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.kaiming_uniform_(self.out.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.out.bias)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = outputs.last_hidden_state[:, 0]\n",
    "        x = self.dropout(pooled)\n",
    "        x = self.act(self.fc1(x))\n",
    "        return self.out(x)  # logits\n",
    "# -------------- Data Loading ---------------\n",
    "result_path =  r'C:\\Users\\mojua\\Desktop\\DL-Code\\T3-LLM-Classification-Result.csv'\n",
    "file_path = r'C:\\Users\\mojua\\Desktop\\DL-Code\\Dataset\\Offensive-24K-T3.xlsx'\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "df['Tweet'] = df['Tweet'].astype(str)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.Tag.unique())\n",
    "df['Tag'] = df['Tag'].replace({1: 0, 2: 1, 3: 2})\n",
    "print(df.Tag.unique())\n",
    "xcolumn = 'Tweet'\n",
    "ycolumn = 'Tag'\n",
    "# ----------- Tokenizer Setup --------------\n",
    "bertmodelname = 'xlm-roberta-base'\n",
    "tokenizer = XLMRobertaTokenizer.from_pretrained(bertmodelname)\n",
    "\n",
    "# -------- K-Fold Training -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local System Time: 04:02 PM\n",
      "Fold 1 Epoch 1/20 - Val Macro F1: 0.2821 - Pat: 0\n",
      "Fold 1 Epoch 2/20 - Val Macro F1: 0.4351 - Pat: 0\n",
      "Fold 1 Epoch 3/20 - Val Macro F1: 0.7352 - Pat: 0\n",
      "Fold 1 Epoch 4/20 - Val Macro F1: 0.7357 - Pat: 0\n",
      "Fold 1 Epoch 5/20 - Val Macro F1: 0.7498 - Pat: 0\n",
      "Fold 1 Epoch 6/20 - Val Macro F1: 0.7485 - Pat: 1\n",
      "Fold 1 Epoch 7/20 - Val Macro F1: 0.7652 - Pat: 0\n",
      "Fold 1 Epoch 8/20 - Val Macro F1: 0.7539 - Pat: 1\n",
      "Fold 1 Epoch 9/20 - Val Macro F1: 0.7708 - Pat: 0\n",
      "Fold 1 Epoch 10/20 - Val Macro F1: 0.7760 - Pat: 0\n",
      "Fold 1 Epoch 11/20 - Val Macro F1: 0.7653 - Pat: 1\n",
      "Fold 1 Epoch 12/20 - Val Macro F1: 0.7642 - Pat: 2\n",
      "Fold 1 Epoch 13/20 - Val Macro F1: 0.7642 - Pat: 3\n",
      "Fold 1 Epoch 14/20 - Val Macro F1: 0.7642 - Pat: 4\n",
      "Fold 1 Epoch 15/20 - Val Macro F1: 0.7642 - Pat: 5\n",
      "Stopping early at epoch 15\n",
      "Completed fold 1/5\n",
      "Fold 2 Epoch 1/20 - Val Macro F1: 0.2843 - Pat: 0\n",
      "Fold 2 Epoch 2/20 - Val Macro F1: 0.6873 - Pat: 0\n",
      "Fold 2 Epoch 3/20 - Val Macro F1: 0.7472 - Pat: 0\n",
      "Fold 2 Epoch 4/20 - Val Macro F1: 0.6995 - Pat: 1\n",
      "Fold 2 Epoch 5/20 - Val Macro F1: 0.7773 - Pat: 0\n",
      "Fold 2 Epoch 6/20 - Val Macro F1: 0.7547 - Pat: 1\n",
      "Fold 2 Epoch 7/20 - Val Macro F1: 0.7747 - Pat: 2\n",
      "Fold 2 Epoch 8/20 - Val Macro F1: 0.7716 - Pat: 3\n",
      "Fold 2 Epoch 9/20 - Val Macro F1: 0.7683 - Pat: 4\n",
      "Fold 2 Epoch 10/20 - Val Macro F1: 0.7683 - Pat: 5\n",
      "Stopping early at epoch 10\n",
      "Completed fold 2/5\n",
      "Fold 3 Epoch 1/20 - Val Macro F1: 0.2860 - Pat: 0\n",
      "Fold 3 Epoch 2/20 - Val Macro F1: 0.5114 - Pat: 0\n",
      "Fold 3 Epoch 3/20 - Val Macro F1: 0.6939 - Pat: 0\n",
      "Fold 3 Epoch 4/20 - Val Macro F1: 0.7116 - Pat: 0\n",
      "Fold 3 Epoch 5/20 - Val Macro F1: 0.7484 - Pat: 0\n",
      "Fold 3 Epoch 6/20 - Val Macro F1: 0.7370 - Pat: 1\n",
      "Fold 3 Epoch 7/20 - Val Macro F1: 0.7226 - Pat: 2\n",
      "Fold 3 Epoch 8/20 - Val Macro F1: 0.7090 - Pat: 3\n",
      "Fold 3 Epoch 9/20 - Val Macro F1: 0.7104 - Pat: 4\n",
      "Fold 3 Epoch 10/20 - Val Macro F1: 0.7111 - Pat: 5\n",
      "Stopping early at epoch 10\n",
      "Completed fold 3/5\n",
      "Fold 4 Epoch 1/20 - Val Macro F1: 0.4803 - Pat: 0\n",
      "Fold 4 Epoch 2/20 - Val Macro F1: 0.7008 - Pat: 0\n",
      "Fold 4 Epoch 3/20 - Val Macro F1: 0.7323 - Pat: 0\n",
      "Fold 4 Epoch 4/20 - Val Macro F1: 0.7280 - Pat: 1\n",
      "Fold 4 Epoch 5/20 - Val Macro F1: 0.7407 - Pat: 0\n",
      "Fold 4 Epoch 6/20 - Val Macro F1: 0.7409 - Pat: 0\n",
      "Fold 4 Epoch 7/20 - Val Macro F1: 0.7460 - Pat: 0\n",
      "Fold 4 Epoch 8/20 - Val Macro F1: 0.7281 - Pat: 1\n",
      "Fold 4 Epoch 9/20 - Val Macro F1: 0.7445 - Pat: 2\n",
      "Fold 4 Epoch 10/20 - Val Macro F1: 0.7409 - Pat: 3\n",
      "Fold 4 Epoch 11/20 - Val Macro F1: 0.7419 - Pat: 4\n",
      "Fold 4 Epoch 12/20 - Val Macro F1: 0.7419 - Pat: 5\n",
      "Stopping early at epoch 12\n",
      "Completed fold 4/5\n",
      "Fold 5 Epoch 1/20 - Val Macro F1: 0.2836 - Pat: 0\n",
      "Fold 5 Epoch 2/20 - Val Macro F1: 0.6139 - Pat: 0\n",
      "Fold 5 Epoch 3/20 - Val Macro F1: 0.7228 - Pat: 0\n",
      "Fold 5 Epoch 4/20 - Val Macro F1: 0.7773 - Pat: 0\n",
      "Fold 5 Epoch 5/20 - Val Macro F1: 0.7651 - Pat: 1\n",
      "Fold 5 Epoch 6/20 - Val Macro F1: 0.7654 - Pat: 2\n",
      "Fold 5 Epoch 7/20 - Val Macro F1: 0.7615 - Pat: 3\n",
      "Fold 5 Epoch 8/20 - Val Macro F1: 0.7608 - Pat: 4\n",
      "Fold 5 Epoch 9/20 - Val Macro F1: 0.7598 - Pat: 5\n",
      "Stopping early at epoch 9\n",
      "Completed fold 5/5\n",
      "Total runtime: 2 hrs 12 mins 41.69 secs\n",
      "Accuracy: 0.854717154785722\n",
      "\n",
      "IND 1 Precision: 0.9274937580855924\n",
      "IND 1 Recall: 0.9072164948453608\n",
      "IND 1 F1-Score: 0.9170535323793431\n",
      "\n",
      "GRP 2 Precision: 0.6843199486700888\n",
      "GRP 2 Recall: 0.7556289674828346\n",
      "GRP 2 F1-Score: 0.7172287209094066\n",
      "\n",
      "OTH 3 Precision: 0.6355144515376606\n",
      "OTH 3 Recall: 0.592\n",
      "OTH 3 F1-Score: 0.6095358712249552\n",
      "\n",
      "Weighted Avg Precision: 0.8594757519323986\n",
      "Weighted Avg Recall: 0.854717154785722\n",
      "Weighted Avg F1-Score: 0.8560362571871479\n",
      "\n",
      "Macro  Precision: 0.7491093860977807\n",
      "Macro  Recall: 0.7516151541093985\n",
      "Macro  F1-Score: 0.7479393748379016\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "reports = []\n",
    "valf1 = []\n",
    "start_time = time.time()\n",
    "print('Local System Time:', time.strftime('%I:%M %p', time.localtime()))\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(df[xcolumn], df[ycolumn]), 1):\n",
    "    x_train = df.loc[train_idx, xcolumn].tolist()\n",
    "    y_train = df.loc[train_idx, ycolumn].values\n",
    "    x_test = df.loc[test_idx, xcolumn].tolist()\n",
    "    y_test = df.loc[test_idx, ycolumn].values\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split( x_train, y_train, test_size=0.15, random_state=0)\n",
    "\n",
    "    train_enc = tokenizer(x_train, padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    val_enc   = tokenizer(x_val,   padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    test_enc  = tokenizer(x_test,  padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "    train_loader = DataLoader(TextDataset(train_enc, y_train), batch_size=BATCH, shuffle=True)\n",
    "    val_loader   = DataLoader(TextDataset(val_enc,   y_val),   batch_size=BATCH)\n",
    "    test_loader  = DataLoader(TextDataset(test_enc,  y_test),  batch_size=BATCH)\n",
    "\n",
    "    model = RobertaClassifier(bertmodelname, num_classes=num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR_RATE)\n",
    "\n",
    "    best_val_f1 = -np.inf\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(NEPOCHS):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            ids   = batch['input_ids'].to(device)\n",
    "            mask  = batch['attention_mask'].to(device)\n",
    "            labels= batch['labels'].to(device)\n",
    "            logits= model(ids, mask)\n",
    "            loss  = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds, val_trues = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                ids    = batch['input_ids'].to(device)\n",
    "                mask   = batch['attention_mask'].to(device)\n",
    "                trues  = batch['labels'].cpu().numpy()\n",
    "                logits = model(ids, mask).cpu().numpy()\n",
    "                preds  = np.argmax(logits, axis=1)\n",
    "                val_preds.extend(preds.tolist())\n",
    "                val_trues.extend(trues.tolist())\n",
    "\n",
    "        valf1.append(        f1_score(val_trues, val_preds, average='macro'))\n",
    "        vf1m = valf1[-1]\n",
    "        if vf1m > best_val_f1:\n",
    "            best_val_f1 = vf1m\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), os.path.join(modelpath, f\"{modelname}_fold{fold}.bin\"))\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if DECAY and patience_counter % DECAY_AFTER == 0 and patience_counter != 0:\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] *= DECAY_RATE\n",
    "\n",
    "        print(f\"Fold {fold} Epoch {epoch+1}/{NEPOCHS} - Val Macro F1: {vf1m:.4f} - Pat: {patience_counter}\")\n",
    "        if patience_counter >= PATIENCE:\n",
    "            print(f\"Stopping early at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # Test evaluation\n",
    "    model.load_state_dict(torch.load(os.path.join(modelpath, f\"{modelname}_fold{fold}.bin\")))\n",
    "    model.eval()\n",
    "    test_preds, test_trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            ids    = batch['input_ids'].to(device)\n",
    "            mask   = batch['attention_mask'].to(device)\n",
    "            trues  = batch['labels'].cpu().numpy()\n",
    "            logits = model(ids, mask).cpu().numpy()\n",
    "            preds  = np.argmax(logits, axis=1)\n",
    "            test_preds.extend(preds.tolist())\n",
    "            test_trues.extend(trues.tolist())\n",
    "            \n",
    "    reports.append(classification_report( test_trues, test_preds, output_dict=True, zero_division=0,labels=[0, 1, 2], target_names=['IND 0', 'GRP 1', 'OTH 2']))\n",
    "    print(f\"Completed fold {fold}/5\")\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "print(f\"Total runtime: {hms_string(time.time() - start_time)}\")\n",
    "WriteResutls(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rdee_Ajk5uEZ",
    "outputId": "d8997708-7fc6-45b9-a92b-a4d4b5623e48"
   },
   "outputs": [],
   "source": [
    "texts = df['Tweet'].tolist()\n",
    "# Get token lengths\n",
    "lengths = [len(tokenizer.encode(text, truncation=False)) for text in texts]\n",
    "# Percentiles\n",
    "p90 = int(np.percentile(lengths, 90))\n",
    "p95 = int(np.percentile(lengths, 95))\n",
    "p99 = int(np.percentile(lengths, 99))\n",
    "max_len = p95  # or use p90 for stricter cutoff\n",
    "\n",
    "print(f\"90th percentile length: {p90}\")\n",
    "print(f\"95th percentile length: {p95}\")\n",
    "print(f\"95th percentile length: {p99}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tRhHy24zC39"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc, os,time, numpy as np,pandas as pd, datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import torch,torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel, logging\n",
    "\n",
    "result_path =  r'C:\\Users\\mojua\\Desktop\\DL-Code\\T3-LLM-Classification-Result.csv'\n",
    "file_path = r'C:\\Users\\mojua\\Desktop\\DL-Code\\Dataset\\Offensive-24K-T3.xlsx'\n",
    "\n",
    "# ---------------- GPU Setup ----------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if device.type == 'cuda':torch.cuda.empty_cache()\n",
    "\n",
    "# --------- Hyperparameters ---------\n",
    "MAX_LEN = 128\n",
    "BERT_TRAINABLE = True\n",
    "DRPT = 0.4\n",
    "FC_ACT = 'elu'\n",
    "LR_RATE = 9e-6\n",
    "BATCH = 32\n",
    "NEPOCHS = 20\n",
    "PATIENCE = 4\n",
    "DECAY = True\n",
    "DECAY_RATE = 0.3\n",
    "DECAY_AFTER = 1\n",
    "\n",
    "modelname = 'hfFineTuneDistilBert'\n",
    "modelpath = os.path.join('.', 'Saved Models', modelname)\n",
    "for d in [modelpath, './Model Results', './Model - Summaries-Figures']:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "######################################################################################\n",
    "# -------- Utils --------\n",
    "def hms_string(sec):\n",
    "    h = int(sec // 3600)\n",
    "    m = int((sec % 3600) // 60)\n",
    "    s = sec % 60\n",
    "    return f\"{h} hrs {m:02d} mins {s:05.2f} secs\"\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# -------- Dataset --------\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings, self.labels = encodings, labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k,v in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "# -------- Model --------\n",
    "class DistilBertClassifier(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name, config=config)\n",
    "        if not BERT_TRAINABLE:\n",
    "            for p in self.bert.parameters(): p.requires_grad=False\n",
    "        hidden = self.bert.config.hidden_size\n",
    "        self.dropout = nn.Dropout(DRPT)\n",
    "        self.fc1 = nn.Linear(hidden, hidden)\n",
    "        self.act = nn.ELU()\n",
    "        self.out = nn.Linear(hidden, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        # he_uniform initialization\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.kaiming_uniform_(self.out.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.out.bias)\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        o = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = o.last_hidden_state[:,0]\n",
    "        x = self.dropout(pooled)\n",
    "        x = self.act(self.fc1(x))\n",
    "        return self.sig(self.out(x).squeeze(-1))\n",
    "\n",
    "# -------- Threshold --------\n",
    "def optimize_threshold(y_true, y_probs):\n",
    "    best_t, best_f = 0.5, 0\n",
    "    for t in np.arange(0.1,0.9,0.001):\n",
    "        p = (y_probs>=t).astype(int)\n",
    "        f = f1_score(y_true,p)\n",
    "        if f>best_f:\n",
    "            best_f, best_t = f, t\n",
    "    return best_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Data Loading --------\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "df['Tweet'] = df['Tweet'].astype(str)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.head())\n",
    "print(df.info(), df.shape)\n",
    "gc.collect()\n",
    "xcol, ycol = 'Tweet', 'Tag'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "def WriteResutls(reports):\n",
    "\n",
    "  unt0 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  tin1 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  Oth2 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  macroavg = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  weightedavg = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  accu = []\n",
    "  for report in reports:\n",
    "    for k,v in report.items():\n",
    "      if 'IND' in k:\n",
    "        unt0['precision'].append(v['precision'])\n",
    "        unt0['recall'].append(v['recall'])\n",
    "        unt0['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'GRP' in k:\n",
    "        tin1['precision'].append(v['precision'])\n",
    "        tin1['recall'].append(v['recall'])\n",
    "        tin1['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'OTH' in k:\n",
    "        Oth2['precision'].append(v['precision'])\n",
    "        Oth2['recall'].append(v['recall'])\n",
    "        Oth2['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'macro avg' in k:\n",
    "        macroavg['precision'].append(v['precision'])\n",
    "        macroavg['recall'].append(v['recall'])\n",
    "        macroavg['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'weighted avg' in k:\n",
    "        weightedavg['precision'].append(v['precision'])\n",
    "        weightedavg['recall'].append(v['recall'])\n",
    "        weightedavg['f1-score'].append(v['f1-score'])\n",
    "      elif 'accuracy' in k:\n",
    "        accu.append(v)\n",
    "\n",
    "  print('Accuracy:',np.mean(accu))\n",
    "  print(\"\")\n",
    "  print('IND 1 Precision:',np.mean(unt0['precision']))\n",
    "  print('IND 1 Recall:',np.mean(unt0['recall']))\n",
    "  print('IND 1 F1-Score:',np.mean(unt0['f1-score']))\n",
    "  print(\"\")\n",
    "  print('GRP 2 Precision:',np.mean(tin1['precision']))\n",
    "  print('GRP 2 Recall:',np.mean(tin1['recall']))\n",
    "  print('GRP 2 F1-Score:',np.mean(tin1['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('OTH 3 Precision:',np.mean(Oth2['precision']))\n",
    "  print('OTH 3 Recall:',np.mean(Oth2['recall']))\n",
    "  print('OTH 3 F1-Score:',np.mean(Oth2['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('Weighted Avg Precision:',np.mean(weightedavg['precision']))\n",
    "  print('Weighted Avg Recall:',np.mean(weightedavg['recall']))\n",
    "  print('Weighted Avg F1-Score:',np.mean(weightedavg['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('Macro  Precision:',np.mean(macroavg['precision']))\n",
    "  print('Macro  Recall:',np.mean(macroavg['recall']))\n",
    "  print('Macro  F1-Score:',np.mean(macroavg['f1-score']))\n",
    "\n",
    "  file = open( result_path, mode='a' )\n",
    "  file.write( modelname+ ' ( '+ datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") +') \\n' )\n",
    "  file.write( 'Accuracy:'+str(np.mean(accu))+'\\n' )\n",
    "  file.write('IND 1 Precision:'+str(np.mean(unt0['precision']))+'\\n' )\n",
    "  file.write('IND 1 Recall:'+str(np.mean(unt0['recall']))+'\\n' )\n",
    "  file.write('IND 1 F1-Score:'+str(np.mean(unt0['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('GRP 2 Precision:'+str(np.mean(tin1['precision']))+'\\n' )\n",
    "  file.write('GRP 2 Recall:'+str(np.mean(tin1['recall']))+'\\n' )\n",
    "  file.write('GRP 2 F1-Score:'+str(np.mean(tin1['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('OTH 3 Precision:'+str(np.mean(Oth2['precision']))+'\\n' )\n",
    "  file.write('OTH 3 Recall:'+str(np.mean(Oth2['recall']))+'\\n' )\n",
    "  file.write('OTH 3 F1-Score:'+str(np.mean(Oth2['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('Weighted Avg Precision:'+str(np.mean(weightedavg['precision']))+'\\n' )\n",
    "  file.write('Weighted Avg Recall:'+str(np.mean(weightedavg['recall']))+'\\n' )\n",
    "  file.write('Weighted Avg F1-Score:'+str(np.mean(weightedavg['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('Macro  Precision:'+str(np.mean(macroavg['precision']))+'\\n' )\n",
    "  file.write('Macro  Recall:'+str(np.mean(macroavg['recall']))+'\\n' )\n",
    "  file.write('Macro  F1-Score:'+str(np.mean(macroavg['f1-score']))+'\\n' )\n",
    "  file.close()\n",
    "  print(\"Done\")\n",
    "######################################################################################\n",
    "# -------- Training Loop --------\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# -------- Tokenizer & Config --------\n",
    "bertmodelname = 'distilbert-base-multilingual-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(bertmodelname)\n",
    "config = AutoConfig.from_pretrained(bertmodelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storage\n",
    "valacc, valprec, valrec, valf1, valcm = [], [], [], [], []\n",
    "val_prec_pc, val_rec_pc, val_f1_pc, val_f1_macro = [], [], [], []\n",
    "testacc, testprec, testrec, testf1, testcm = [], [], [], [], []\n",
    "test_prec_pc, test_rec_pc, test_f1_pc, test_f1_macro = [], [], [], []\n",
    "reports =  []\n",
    "start = time.time()\n",
    "for fold, (tr, te) in enumerate(skf.split(df[xcol], df[ycol]), 1):\n",
    "    Xtr = df.loc[tr, xcol].tolist()\n",
    "    ytr = df.loc[tr, ycol].values\n",
    "    Xte = df.loc[te, xcol].tolist()\n",
    "    yte = df.loc[te, ycol].values\n",
    "\n",
    "    Xtr, Xv, ytr, yv = train_test_split(Xtr, ytr, test_size=0.15, random_state=0)\n",
    "    enc_tr = tokenizer(Xtr, padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    enc_v  = tokenizer(Xv,  padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    enc_te = tokenizer(Xte, padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "    dt_tr = DataLoader(TextDataset(enc_tr, ytr), batch_size=BATCH, shuffle=True)\n",
    "    dt_v  = DataLoader(TextDataset(enc_v,  yv), batch_size=BATCH)\n",
    "    dt_te = DataLoader(TextDataset(enc_te, yte), batch_size=BATCH)\n",
    "\n",
    "    model = DistilBertClassifier(bertmodelname).to(device)\n",
    "    crit  = nn.BCELoss()\n",
    "    opt   = torch.optim.Adam(model.parameters(), lr=LR_RATE)\n",
    "    best_f, pat = -np.inf, 0\n",
    "\n",
    "    for ep in range(NEPOCHS):\n",
    "        model.train()\n",
    "        for b in dt_tr:\n",
    "            opt.zero_grad()\n",
    "            ids   = b['input_ids'].to(device)\n",
    "            mask  = b['attention_mask'].to(device)\n",
    "            labels= b['labels'].to(device)\n",
    "            probs = model(ids, mask)\n",
    "            loss  = crit(probs, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        # validation\n",
    "        model.eval()\n",
    "        vp, vt = [], []\n",
    "        with torch.no_grad():\n",
    "            for b in dt_v:\n",
    "                ids  = b['input_ids'].to(device)\n",
    "                mask = b['attention_mask'].to(device)\n",
    "                vp.extend(model(ids, mask).cpu().tolist())\n",
    "                vt.extend(b['labels'].cpu().tolist())\n",
    "        th    = optimize_threshold(np.array(vt), np.array(vp))\n",
    "        vpred = (np.array(vp) >= th).astype(int)\n",
    "        # record metrics\n",
    "        valacc.append(       accuracy_score(vt, vpred))\n",
    "        valprec.append(      precision_score(vt, vpred))\n",
    "        valrec.append(       recall_score(vt, vpred))\n",
    "        valf1.append(        f1_score(vt, vpred))\n",
    "        valcm.append(        confusion_matrix(vt, vpred))\n",
    "       \n",
    "        vf1m = f1_score(vt, vpred, average='macro')\n",
    "        val_f1_macro.append(vf1m)\n",
    "        # early stopping\n",
    "        if vf1m > best_f:\n",
    "            best_f, pat = vf1m, 0\n",
    "            torch.save(model.state_dict(),os.path.join(modelpath, f\"{modelname}_fold{fold}.bin\"))\n",
    "        else:\n",
    "            pat += 1\n",
    "        if DECAY and pat % DECAY_AFTER == 0 and pat != 0:\n",
    "            for g in opt.param_groups:\n",
    "                g['lr'] *= DECAY_RATE\n",
    "                \n",
    "        print(f\"Fold{fold} Ep{ep+1}/{NEPOCHS} - ValMacroF1={vf1m:.4f} Pat={pat}\")\n",
    "        if pat >= PATIENCE:\n",
    "            break\n",
    "\n",
    "    # test evaluation\n",
    "    model.load_state_dict(torch.load(os.path.join(modelpath, f\"{modelname}_fold{fold}.bin\")))\n",
    "    model.eval()\n",
    "    tp, tt = [], []\n",
    "    with torch.no_grad():\n",
    "        for b in dt_te:\n",
    "            ids  = b['input_ids'].to(device)\n",
    "            mask = b['attention_mask'].to(device)\n",
    "            tp.extend(model(ids, mask).cpu().tolist())\n",
    "            tt.extend(b['labels'].cpu().tolist())\n",
    "    tpred = (np.array(tp) >= th).astype(int)\n",
    "\n",
    "    testacc.append(       accuracy_score(tt, tpred))\n",
    "    testprec.append(      precision_score(tt, tpred))\n",
    "    testrec.append(       recall_score(tt, tpred))\n",
    "    testf1.append(        f1_score(tt, tpred))\n",
    "    testcm.append(        confusion_matrix(tt, tpred))\n",
    "    #reports.append(classification_report( tt, tpred, output_dict=True, zero_division=0, target_names=['UNT 0', 'TIN 1']))\n",
    "    reports.append(classification_report( tt, tpred, output_dict=True, zero_division=0,labels=[1, 2, 3], target_names=['IND 1', 'GRP 2', 'OTH 3']))\n",
    "    print(f\"Completed fold {fold}/5\")\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(\"Total runtime:\", hms_string(time.time() - start))\n",
    "WriteResutls(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from here after kernel restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc, os,time, numpy as np,pandas as pd, datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import torch,torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel, logging\n",
    "\n",
    "result_path =  r'C:\\Users\\mojua\\Desktop\\DL-Code\\T3-LLM-Classification-Result.csv'\n",
    "file_path = r'C:\\Users\\mojua\\Desktop\\DL-Code\\Dataset\\Offensive-24K-T3.xlsx'\n",
    "\n",
    "# ---------------- GPU Setup ----------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if device.type == 'cuda':torch.cuda.empty_cache()\n",
    "\n",
    "# --------- Hyperparameters ---------\n",
    "MAX_LEN = 128\n",
    "BERT_TRAINABLE = True\n",
    "DRPT = 0.4\n",
    "FC_ACT = 'elu'\n",
    "LR_RATE = 1e-5\n",
    "BATCH = 32\n",
    "NEPOCHS = 20\n",
    "PATIENCE = 4\n",
    "DECAY = True\n",
    "DECAY_RATE = 0.3\n",
    "DECAY_AFTER = 1\n",
    "modelname = 'hfFineTuneBert'\n",
    "bertmodelname = 'bert-base-multilingual-cased'\n",
    "\n",
    "modelpath = os.path.join('.', 'Saved Models', modelname)\n",
    "for d in [modelpath, './Model Results', './Model - Summaries-Figures']:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "#################################################################################\n",
    "# -------- Utils --------\n",
    "def hms_string(sec):\n",
    "    h = int(sec // 3600)\n",
    "    m = int((sec % 3600) // 60)\n",
    "    s = sec % 60\n",
    "    return f\"{h} hrs {m:02d} mins {s:05.2f} secs\"\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "# ----------- Dataset Class ----------------\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "# -------- Model Definition ----------------\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, model_name, dropout_rate=DRPT):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name, config=config)\n",
    "        if not BERT_TRAINABLE:\n",
    "            for p in self.bert.parameters(): p.requires_grad = False\n",
    "        hidden = self.bert.config.hidden_size\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(hidden, hidden)\n",
    "        self.act = nn.ELU()\n",
    "        self.out = nn.Linear(hidden, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        # he_uniform init\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.kaiming_uniform_(self.out.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.out.bias)\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        o = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = o.pooler_output if hasattr(o, 'pooler_output') else o.last_hidden_state[:,0]\n",
    "        x = self.dropout(pooled)\n",
    "        x = self.act(self.fc1(x))\n",
    "        return self.sig(self.out(x).squeeze(-1))\n",
    "\n",
    "# -------- Threshold Optimization -----------\n",
    "def optimize_threshold(y_true, y_probs):\n",
    "    best_t, best_f = 0.5, 0\n",
    "    for t in np.arange(0.1,0.9,0.001):\n",
    "        p = (y_probs>=t).astype(int)\n",
    "        f = f1_score(y_true, p, average='weighted')\n",
    "        if f>best_f: best_f, best_t = f, t\n",
    "    return best_t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do multi-class classification(specifically 3 classes) using the same model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc, os,time, numpy as np,pandas as pd, datetime\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import torch,torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel, logging\n",
    "\n",
    "result_path =  r'C:\\Users\\mojua\\Desktop\\DL-Code\\T3-LLM-Classification-Result.csv'\n",
    "file_path =  r'C:\\Users\\mojua\\Desktop\\DL-Code\\Dataset\\Offensive-24K-T3.xlsx'\n",
    "\n",
    "# ---------------- GPU Setup ----------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if device.type == 'cuda':torch.cuda.empty_cache()\n",
    "\n",
    "# --------- Hyperparameters ---------\n",
    "MAX_LEN = 128\n",
    "BERT_TRAINABLE = True\n",
    "DRPT = 0.4\n",
    "FC_ACT = 'elu'\n",
    "LR_RATE = 1e-5\n",
    "BATCH = 32\n",
    "NEPOCHS = 20\n",
    "PATIENCE = 4\n",
    "DECAY = True\n",
    "DECAY_RATE = 0.3\n",
    "DECAY_AFTER = 1\n",
    "modelname = 'hfFineTuneBert'\n",
    "bertmodelname = 'bert-base-multilingual-cased'\n",
    "\n",
    "modelpath = os.path.join('.', 'Saved Models', modelname)\n",
    "for d in [modelpath, './Model Results', './Model - Summaries-Figures']:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "#################################################################################\n",
    "# -------- Utils --------\n",
    "def hms_string(sec):\n",
    "    h = int(sec // 3600)\n",
    "    m = int((sec % 3600) // 60)\n",
    "    s = sec % 60\n",
    "    return f\"{h} hrs {m:02d} mins {s:05.2f} secs\"\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "# ----------- Dataset Class ----------------\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "config = AutoConfig.from_pretrained(bertmodelname)\n",
    "# -------- Model Definition ----------------\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, model_name, dropout_rate=DRPT):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name, config=config)\n",
    "        if not BERT_TRAINABLE:\n",
    "            for p in self.bert.parameters(): p.requires_grad = False\n",
    "        hidden = self.bert.config.hidden_size\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(hidden, hidden)\n",
    "        self.act = nn.ELU()\n",
    "        self.out = nn.Linear(hidden, 3)  # 3 output units for 3 classes\n",
    "        self.softmax = nn.Softmax(dim=1)  # Added softmax\n",
    "        # he_uniform init\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.kaiming_uniform_(self.out.weight, nonlinearity='linear')\n",
    "        nn.init.zeros_(self.out.bias)\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        o = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = o.pooler_output if hasattr(o, 'pooler_output') else o.last_hidden_state[:,0]\n",
    "        x = self.dropout(pooled)\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.out(x)\n",
    "        return self.softmax(x)  # Applied softmax to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def optimize_thresholds_multiclass(y_true, y_probs, average='weighted'):\n",
    "    \"\"\"\n",
    "    Optimize thresholds for multi-class classification\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (np.array): True class labels (0, 1, 2)\n",
    "    y_probs (np.array): Predicted probabilities from softmax (n_samples × 3)\n",
    "    average (str): F1 averaging method ('weighted', 'macro', 'micro')\n",
    "    \n",
    "    Returns:\n",
    "    np.array: Optimized thresholds for each class [threshold_class0, threshold_class1, threshold_class2]\n",
    "    \"\"\"\n",
    "    num_classes = y_probs.shape[1]\n",
    "    thresholds = np.full(num_classes, 0.5)  # Default thresholds\n",
    "    best_f1 = 0\n",
    "    \n",
    "    # Optimize each class threshold separately\n",
    "    for c in range(num_classes):\n",
    "        best_t = 0.5\n",
    "        best_class_f1 = 0\n",
    "        \n",
    "        # Test thresholds from 0.1 to 0.9\n",
    "        for t in np.arange(0.1, 0.9, 0.01):\n",
    "            # Create temporary predictions where we only consider current class\n",
    "            temp_preds = np.zeros_like(y_probs)\n",
    "            temp_preds[:, c] = (y_probs[:, c] >= t).astype(int)\n",
    "            \n",
    "            # Get final predictions (class with highest probability)\n",
    "            pred_labels = np.argmax(temp_preds, axis=1)\n",
    "            \n",
    "            # Calculate F1 score\n",
    "            current_f1 = f1_score(y_true, pred_labels, average=average)\n",
    "            \n",
    "            # Update best threshold for this class\n",
    "            if current_f1 > best_class_f1:\n",
    "                best_class_f1 = current_f1\n",
    "                best_t = t\n",
    "        \n",
    "        # Update global best F1 and thresholds\n",
    "        if best_class_f1 > best_f1:\n",
    "            best_f1 = best_class_f1\n",
    "        thresholds[c] = best_t\n",
    "    \n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              Tweet  Tag\n",
      "0           3                   USER گھٹیا انسان دنیا ہی چھوڑ دو    1\n",
      "1          11  USER PMLN میں آپ کے بارے میں میری بہتر راۓ تھی...    1\n",
      "2          20  ہمیں تو آج تک سمجھ نہیں آئی کہ کم عقل عیسائی ح...    2\n",
      "3          21  کیا پتہ اس گدھے کو بھی ہینڈلرز کی طرف سے گرین ...    1\n",
      "4          25  USER ون آن ون والی پہلے اپنی اوقات تو کر لو۔ ی...    1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6594 entries, 0 to 6593\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  6594 non-null   int64 \n",
      " 1   Tweet       6594 non-null   object\n",
      " 2   Tag         6594 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 154.7+ KB\n",
      "None\n",
      "Index(['Unnamed: 0', 'Tweet', 'Tag'], dtype='object') (6594, 3)\n",
      "Unique Classes: [1 2 3]\n",
      "Class Distribution:\n",
      " Tag\n",
      "1    4850\n",
      "2    1244\n",
      "3     500\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8802"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------- Data Loading ---------------\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "df['Tweet'] = df['Tweet'].astype(str)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.columns, df.shape)\n",
    "\n",
    "# Class information (now expects 3 classes: 1, 2, 3)\n",
    "xcolumn = 'Tweet'\n",
    "ycolumn = 'Tag'\n",
    "print(\"Unique Classes:\", df[ycolumn].unique())  # Should show [1, 2, 3]\n",
    "print(\"Class Distribution:\\n\", df[ycolumn].value_counts())  # Counts for each class\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteResults(reports):\n",
    "    from collections import defaultdict\n",
    "    import datetime\n",
    "\n",
    "    class_metrics = defaultdict(lambda: {'precision': [], 'recall': [], 'f1-score': []})\n",
    "    macroavg = {'precision': [], 'recall': [], 'f1-score': []}\n",
    "    weightedavg = {'precision': [], 'recall': [], 'f1-score': []}\n",
    "    accu = []\n",
    "\n",
    "    for report in reports:\n",
    "        for k, v in report.items():\n",
    "            if k == 'accuracy':\n",
    "                accu.append(v)\n",
    "            elif k == 'macro avg':\n",
    "                macroavg['precision'].append(v['precision'])\n",
    "                macroavg['recall'].append(v['recall'])\n",
    "                macroavg['f1-score'].append(v['f1-score'])\n",
    "            elif k == 'weighted avg':\n",
    "                weightedavg['precision'].append(v['precision'])\n",
    "                weightedavg['recall'].append(v['recall'])\n",
    "                weightedavg['f1-score'].append(v['f1-score'])\n",
    "            elif k in ['0', '1', '2']:  # Modified to expect class labels 0,1,2\n",
    "                class_metrics[k]['precision'].append(v['precision'])\n",
    "                class_metrics[k]['recall'].append(v['recall'])\n",
    "                class_metrics[k]['f1-score'].append(v['f1-score'])\n",
    "\n",
    "    # Rest of the function remains EXACTLY THE SAME\n",
    "    print(f\"Accuracy: {np.mean(accu):.4f}\\n\")\n",
    "\n",
    "    for class_name, metrics in class_metrics.items():\n",
    "        print(f\"{class_name} Precision: {np.mean(metrics['precision']):.4f}\")\n",
    "        print(f\"{class_name} Recall:    {np.mean(metrics['recall']):.4f}\")\n",
    "        print(f\"{class_name} F1-Score:  {np.mean(metrics['f1-score']):.4f}\\n\")\n",
    "\n",
    "    print(f\"Weighted Avg Precision: {np.mean(weightedavg['precision']):.4f}\")\n",
    "    print(f\"Weighted Avg Recall:    {np.mean(weightedavg['recall']):.4f}\")\n",
    "    print(f\"Weighted Avg F1-Score:  {np.mean(weightedavg['f1-score']):.4f}\\n\")\n",
    "\n",
    "    print(f\"Macro Avg Precision:    {np.mean(macroavg['precision']):.4f}\")\n",
    "    print(f\"Macro Avg Recall:       {np.mean(macroavg['recall']):.4f}\")\n",
    "    print(f\"Macro Avg F1-Score:     {np.mean(macroavg['f1-score']):.4f}\")\n",
    "\n",
    "    # Write to file\n",
    "    with open(result_path, mode='a') as file:\n",
    "        file.write(modelname + ' ( ' + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + ' )\\n')\n",
    "        file.write(f'Accuracy: {np.mean(accu):.4f}\\n')\n",
    "        for class_name, metrics in class_metrics.items():\n",
    "            file.write(f'{class_name} Precision: {np.mean(metrics[\"precision\"]):.4f}\\n')\n",
    "            file.write(f'{class_name} Recall:    {np.mean(metrics[\"recall\"]):.4f}\\n')\n",
    "            file.write(f'{class_name} F1-Score:  {np.mean(metrics[\"f1-score\"]):.4f}\\n')\n",
    "        file.write(f'Weighted Avg Precision: {np.mean(weightedavg[\"precision\"]):.4f}\\n')\n",
    "        file.write(f'Weighted Avg Recall:    {np.mean(weightedavg[\"recall\"]):.4f}\\n')\n",
    "        file.write(f'Weighted Avg F1-Score:  {np.mean(weightedavg[\"f1-score\"]):.4f}\\n')\n",
    "        file.write(f'Macro Avg Precision:    {np.mean(macroavg[\"precision\"]):.4f}\\n')\n",
    "        file.write(f'Macro Avg Recall:       {np.mean(macroavg[\"recall\"]):.4f}\\n')\n",
    "        file.write(f'Macro Avg F1-Score:     {np.mean(macroavg[\"f1-score\"]):.4f}\\n')\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local System Time: 09:33 AM\n",
      "Fold1 Ep1/20 - ValMacroF1=0.2821 Pat=0\n",
      "Fold1 Ep2/20 - ValMacroF1=0.2821 Pat=1\n",
      "Fold1 Ep3/20 - ValMacroF1=0.2821 Pat=2\n",
      "Fold1 Ep4/20 - ValMacroF1=0.2821 Pat=3\n",
      "Fold1 Ep5/20 - ValMacroF1=0.2821 Pat=4\n",
      "Stopping early at epoch 5\n",
      "Completed fold 1/5\n",
      "Fold2 Ep1/20 - ValMacroF1=0.2843 Pat=0\n",
      "Fold2 Ep2/20 - ValMacroF1=0.2843 Pat=1\n",
      "Fold2 Ep3/20 - ValMacroF1=0.2843 Pat=2\n",
      "Fold2 Ep4/20 - ValMacroF1=0.2843 Pat=3\n",
      "Fold2 Ep5/20 - ValMacroF1=0.2843 Pat=4\n",
      "Stopping early at epoch 5\n",
      "Completed fold 2/5\n",
      "Fold3 Ep1/20 - ValMacroF1=0.2860 Pat=0\n",
      "Fold3 Ep2/20 - ValMacroF1=0.3183 Pat=0\n",
      "Fold3 Ep3/20 - ValMacroF1=0.2860 Pat=1\n",
      "Fold3 Ep4/20 - ValMacroF1=0.2860 Pat=2\n",
      "Fold3 Ep5/20 - ValMacroF1=0.2860 Pat=3\n",
      "Fold3 Ep6/20 - ValMacroF1=0.2860 Pat=4\n",
      "Stopping early at epoch 6\n",
      "Completed fold 3/5\n",
      "Fold4 Ep1/20 - ValMacroF1=0.2790 Pat=0\n",
      "Fold4 Ep2/20 - ValMacroF1=0.2790 Pat=1\n",
      "Fold4 Ep3/20 - ValMacroF1=0.2790 Pat=2\n",
      "Fold4 Ep4/20 - ValMacroF1=0.2790 Pat=3\n",
      "Fold4 Ep5/20 - ValMacroF1=0.2790 Pat=4\n",
      "Stopping early at epoch 5\n",
      "Completed fold 4/5\n",
      "Fold5 Ep1/20 - ValMacroF1=0.2793 Pat=0\n",
      "Fold5 Ep2/20 - ValMacroF1=0.2793 Pat=1\n",
      "Fold5 Ep3/20 - ValMacroF1=0.2793 Pat=2\n",
      "Fold5 Ep4/20 - ValMacroF1=0.2793 Pat=3\n",
      "Fold5 Ep5/20 - ValMacroF1=0.2793 Pat=4\n",
      "Stopping early at epoch 5\n",
      "Completed fold 5/5\n",
      "Total runtime: 0 hrs 10 mins 38.04 secs\n",
      "Accuracy: 0.7378\n",
      "\n",
      "Weighted Avg Precision: 0.5759\n",
      "Weighted Avg Recall:    0.7378\n",
      "Weighted Avg F1-Score:  0.6288\n",
      "\n",
      "Macro Avg Precision:    0.3051\n",
      "Macro Avg Recall:       0.3375\n",
      "Macro Avg F1-Score:     0.2909\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# K-Fold setup (unchanged)\n",
    "skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "# Clear previous metrics\n",
    "valaccuracy, valprecision, valrecall, valf1, valcm = [], [], [], [], []\n",
    "val_f1_macro = []\n",
    "testaccuracy, testprecision, testrecall, testf1, testcm = [], [], [], [], []\n",
    "test_f1_macro = []\n",
    "reports = []\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(bertmodelname)\n",
    "\n",
    "start = time.time()\n",
    "print(\"Local System Time:\", time.strftime(\"%I:%M %p\", time.localtime()))\n",
    "\n",
    "for fold, (tr, te) in enumerate(skf.split(df[xcolumn], df[ycolumn]), 1):\n",
    "    xtr = df.loc[tr, xcolumn].tolist()\n",
    "    ytr = df.loc[tr, ycolumn].values - 1  # Convert labels to 0,1,2\n",
    "    xte = df.loc[te, xcolumn].tolist()\n",
    "    yte = df.loc[te, ycolumn].values - 1  # Convert labels to 0,1,2\n",
    "\n",
    "    xtr, xv, ytr, yv = train_test_split(xtr, ytr, test_size=0.15, random_state=0)\n",
    "\n",
    "    # Tokenization (unchanged)\n",
    "    enc_tr = tokenizer(xtr, padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    enc_v = tokenizer(xv, padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    enc_te = tokenizer(xte, padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "    # Dataset loaders (unchanged)\n",
    "    dt_tr = TextDataset(enc_tr, ytr)\n",
    "    lt = DataLoader(dt_tr, batch_size=BATCH, shuffle=True)\n",
    "    dt_v = TextDataset(enc_v, yv)\n",
    "    lv = DataLoader(dt_v, batch_size=BATCH)\n",
    "    dt_te = TextDataset(enc_te, yte)\n",
    "    le = DataLoader(dt_te, batch_size=BATCH)\n",
    "\n",
    "    # Model & loss (modified for 3 classes)\n",
    "    model = BertClassifier(bertmodelname).to(device)  # Your class now outputs 3 units\n",
    "    crit = nn.CrossEntropyLoss()  # Changed from BCELoss to CrossEntropyLoss\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=LR_RATE)\n",
    "\n",
    "    best_f, pt = -np.inf, 0\n",
    "\n",
    "    # Training loop (unchanged structure)\n",
    "    for e in range(NEPOCHS):\n",
    "        model.train()\n",
    "        for b in lt:\n",
    "            opt.zero_grad()\n",
    "            ids = b['input_ids'].to(device)\n",
    "            m = b['attention_mask'].to(device)\n",
    "            lbls = b['labels'].to(device)  # Now expects class indices 0,1,2\n",
    "            pr = model(ids, m)            # Outputs [batch_size, 3]\n",
    "            loss = crit(pr, lbls)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        # Validation (modified metrics for 3 classes)\n",
    "        model.eval(); vp, vt = [], []\n",
    "        with torch.no_grad():\n",
    "            for b in lv:\n",
    "                ids = b['input_ids'].to(device)\n",
    "                m = b['attention_mask'].to(device)\n",
    "                lbls = b['labels'].cpu().numpy().tolist()\n",
    "                logits = model(ids, m)\n",
    "                preds = torch.argmax(logits, dim=1).cpu().numpy().tolist()  # Class indices\n",
    "                vp.extend(preds)\n",
    "                vt.extend(lbls)\n",
    "\n",
    "        # Metrics (now uses 'macro' averaging by default)\n",
    "        valaccuracy.append(accuracy_score(vt, vp))\n",
    "        valprecision.append(precision_score(vt, vp, average='macro', zero_division=0))\n",
    "        valrecall.append(recall_score(vt, vp, average='macro', zero_division=0))\n",
    "        valf1.append(f1_score(vt, vp, average='macro', zero_division=0))\n",
    "        valcm.append(confusion_matrix(vt, vp, labels=[0,1,2]))  # Added explicit labels\n",
    "        vm = f1_score(vt, vp, average='macro', zero_division=0)\n",
    "        val_f1_macro.append(vm)\n",
    "\n",
    "        # Early stopping (unchanged)\n",
    "        if vm > best_f:\n",
    "            best_f, pt = vm, 0\n",
    "            torch.save(model.state_dict(), os.path.join(modelpath, f\"{modelname}_fold{fold}.bin\"))\n",
    "        else:\n",
    "            pt += 1\n",
    "\n",
    "        if DECAY and pt % DECAY_AFTER == 0 and pt != 0:\n",
    "            for g in opt.param_groups:\n",
    "                g['lr'] *= DECAY_RATE\n",
    "\n",
    "        print(f\"Fold{fold} Ep{e + 1}/{NEPOCHS} - ValMacroF1={vm:.4f} Pat={pt}\")\n",
    "        if pt >= PATIENCE:\n",
    "            print(f\"Stopping early at epoch {e + 1}\")\n",
    "            break\n",
    "\n",
    "    # Test Evaluation (modified for 3 classes)\n",
    "    model.load_state_dict(torch.load(os.path.join(modelpath, f\"{modelname}_fold{fold}.bin\")))\n",
    "    model.eval(); tp, tt = [], []\n",
    "    with torch.no_grad():\n",
    "        for b in le:\n",
    "            ids = b['input_ids'].to(device)\n",
    "            m = b['attention_mask'].to(device)\n",
    "            logits = model(ids, m)\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy().tolist()  # Class indices\n",
    "            lbls = b['labels'].cpu().numpy().tolist()\n",
    "            tp.extend(preds)\n",
    "            tt.extend(lbls)\n",
    "\n",
    "    testaccuracy.append(accuracy_score(tt, tp))\n",
    "    testprecision.append(precision_score(tt, tp, average='macro', zero_division=0))\n",
    "    testrecall.append(recall_score(tt, tp, average='macro', zero_division=0))\n",
    "    testf1.append(f1_score(tt, tp, average='macro', zero_division=0))\n",
    "    testcm.append(confusion_matrix(tt, tp, labels=[0,1,2]))  # Added explicit labels\n",
    "    test_f1_macro.append(f1_score(tt, tp, average='macro', zero_division=0))\n",
    "\n",
    "    # Classification report for 3 classes\n",
    "    reports.append(classification_report(\n",
    "        tt, tp,\n",
    "        output_dict=True,\n",
    "        zero_division=0,\n",
    "        labels=[0, 1, 2],  # Explicit class indices\n",
    "        target_names=['Class 0', 'Class 1', 'Class 2']  # Your class names\n",
    "    ))\n",
    "\n",
    "    print(f\"Completed fold {fold}/5\")\n",
    "    del model; torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "print(f\"Total runtime: {hms_string(time.time()-start)}\")\n",
    "WriteResults(reports)  # Fixed typo in your original (WriteResutls -> WriteResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              Tweet  Tag\n",
      "0           3                   USER گھٹیا انسان دنیا ہی چھوڑ دو    1\n",
      "1          11  USER PMLN میں آپ کے بارے میں میری بہتر راۓ تھی...    1\n",
      "2          20  ہمیں تو آج تک سمجھ نہیں آئی کہ کم عقل عیسائی ح...    2\n",
      "3          21  کیا پتہ اس گدھے کو بھی ہینڈلرز کی طرف سے گرین ...    1\n",
      "4          25  USER ون آن ون والی پہلے اپنی اوقات تو کر لو۔ ی...    1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6594 entries, 0 to 6593\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  6594 non-null   int64 \n",
      " 1   Tweet       6594 non-null   object\n",
      " 2   Tag         6594 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 154.7+ KB\n",
      "None\n",
      "Index(['Unnamed: 0', 'Tweet', 'Tag'], dtype='object') (6594, 3)\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "# -------------- Data Loading ---------------\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "df['Tweet'] = df['Tweet'].astype(str)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.columns, df.shape)\n",
    "gc.collect()\n",
    "xcolumn = 'Tweet'\n",
    "ycolumn = 'Tag'\n",
    "print(df.Tag.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "def WriteResutls(reports):\n",
    "\n",
    "  unt0 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  tin1 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  Oth2 = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  macroavg = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  weightedavg = {'precision':[], 'recall':[], 'f1-score':[] }\n",
    "  accu = []\n",
    "  for report in reports:\n",
    "    for k,v in report.items():\n",
    "      if 'IND' in k:\n",
    "        unt0['precision'].append(v['precision'])\n",
    "        unt0['recall'].append(v['recall'])\n",
    "        unt0['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'GRP' in k:\n",
    "        tin1['precision'].append(v['precision'])\n",
    "        tin1['recall'].append(v['recall'])\n",
    "        tin1['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'OTH' in k:\n",
    "        Oth2['precision'].append(v['precision'])\n",
    "        Oth2['recall'].append(v['recall'])\n",
    "        Oth2['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'macro avg' in k:\n",
    "        macroavg['precision'].append(v['precision'])\n",
    "        macroavg['recall'].append(v['recall'])\n",
    "        macroavg['f1-score'].append(v['f1-score'])\n",
    "\n",
    "      elif 'weighted avg' in k:\n",
    "        weightedavg['precision'].append(v['precision'])\n",
    "        weightedavg['recall'].append(v['recall'])\n",
    "        weightedavg['f1-score'].append(v['f1-score'])\n",
    "      elif 'accuracy' in k:\n",
    "        accu.append(v)\n",
    "\n",
    "  print('Accuracy:',np.mean(accu))\n",
    "  print(\"\")\n",
    "  print('IND 1 Precision:',np.mean(unt0['precision']))\n",
    "  print('IND 1 Recall:',np.mean(unt0['recall']))\n",
    "  print('IND 1 F1-Score:',np.mean(unt0['f1-score']))\n",
    "  print(\"\")\n",
    "  print('GRP 2 Precision:',np.mean(tin1['precision']))\n",
    "  print('GRP 2 Recall:',np.mean(tin1['recall']))\n",
    "  print('GRP 2 F1-Score:',np.mean(tin1['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('OTH 3 Precision:',np.mean(Oth2['precision']))\n",
    "  print('OTH 3 Recall:',np.mean(Oth2['recall']))\n",
    "  print('OTH 3 F1-Score:',np.mean(Oth2['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('Weighted Avg Precision:',np.mean(weightedavg['precision']))\n",
    "  print('Weighted Avg Recall:',np.mean(weightedavg['recall']))\n",
    "  print('Weighted Avg F1-Score:',np.mean(weightedavg['f1-score']))\n",
    "\n",
    "  print(\"\")\n",
    "  print('Macro  Precision:',np.mean(macroavg['precision']))\n",
    "  print('Macro  Recall:',np.mean(macroavg['recall']))\n",
    "  print('Macro  F1-Score:',np.mean(macroavg['f1-score']))\n",
    "\n",
    "  file = open( result_path, mode='a' )\n",
    "  file.write( modelname+ ' ( '+ datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") +') \\n' )\n",
    "  file.write( 'Accuracy:'+str(np.mean(accu))+'\\n' )\n",
    "  file.write('IND 1 Precision:'+str(np.mean(unt0['precision']))+'\\n' )\n",
    "  file.write('IND 1 Recall:'+str(np.mean(unt0['recall']))+'\\n' )\n",
    "  file.write('IND 1 F1-Score:'+str(np.mean(unt0['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('GRP 2 Precision:'+str(np.mean(tin1['precision']))+'\\n' )\n",
    "  file.write('GRP 2 Recall:'+str(np.mean(tin1['recall']))+'\\n' )\n",
    "  file.write('GRP 2 F1-Score:'+str(np.mean(tin1['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('OTH 3 Precision:'+str(np.mean(Oth2['precision']))+'\\n' )\n",
    "  file.write('OTH 3 Recall:'+str(np.mean(Oth2['recall']))+'\\n' )\n",
    "  file.write('OTH 3 F1-Score:'+str(np.mean(Oth2['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('Weighted Avg Precision:'+str(np.mean(weightedavg['precision']))+'\\n' )\n",
    "  file.write('Weighted Avg Recall:'+str(np.mean(weightedavg['recall']))+'\\n' )\n",
    "  file.write('Weighted Avg F1-Score:'+str(np.mean(weightedavg['f1-score']))+'\\n' )\n",
    "\n",
    "  file.write('Macro  Precision:'+str(np.mean(macroavg['precision']))+'\\n' )\n",
    "  file.write('Macro  Recall:'+str(np.mean(macroavg['recall']))+'\\n' )\n",
    "  file.write('Macro  F1-Score:'+str(np.mean(macroavg['f1-score']))+'\\n' )\n",
    "  file.close()\n",
    "  print(\"Done\")\n",
    "######################################################################################\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(bertmodelname)\n",
    "config = AutoConfig.from_pretrained(bertmodelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- K-Fold Training ----------------\n",
    "skf = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "# Metrics storage\n",
    "valaccuracy, valprecision, valrecall, valf1, valcm = [], [], [], [], []\n",
    "val_prec_pc, val_rec_pc, val_f1_pc, val_f1_macro = [], [], [], []\n",
    "testaccuracy, testprecision, testrecall, testf1, testcm = [], [], [], [], []\n",
    "test_prec_pc, test_rec_pc, test_f1_pc, test_f1_macro = [], [], [], []\n",
    "reports = []\n",
    "start = time.time()\n",
    "print(\"Local System Time:\", time.strftime(\"%I:%M %p\", time.localtime()))\n",
    "\n",
    "for fold, (tr, te) in enumerate(skf.split(df[xcolumn], df[ycolumn]),1):\n",
    "    xtr = df.loc[tr, xcolumn].tolist();\n",
    "    ytr = df.loc[tr, ycolumn].values\n",
    "    xte = df.loc[te, xcolumn].tolist(); \n",
    "    yte = df.loc[te, ycolumn].values\n",
    "    xtr, xv, ytr, yv = train_test_split(xtr, ytr, test_size=0.15, random_state=0)\n",
    "    # tokenize\n",
    "    enc_tr = tokenizer(xtr, padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    enc_v  = tokenizer(xv,  padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    enc_te = tokenizer(xte, padding='max_length', truncation=True, max_length=MAX_LEN)\n",
    "    # datasets & loaders\n",
    "    dt_tr = TextDataset(enc_tr, ytr); \n",
    "    lt = DataLoader(dt_tr, batch_size=BATCH, shuffle=True)\n",
    "    dt_v  = TextDataset(enc_v,  yv); \n",
    "    lv = DataLoader(dt_v, batch_size=BATCH)\n",
    "    dt_te = TextDataset(enc_te, yte); \n",
    "    le = DataLoader(dt_te, batch_size=BATCH)\n",
    "    # model, loss, opt\n",
    "    model = BertClassifier(bertmodelname).to(device)\n",
    "    crit = nn.BCELoss()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=LR_RATE)\n",
    "    best_f, pt = -np.inf, 0\n",
    "    # train\n",
    "    for e in range(NEPOCHS):\n",
    "        model.train()\n",
    "        for b in lt:\n",
    "            opt.zero_grad()\n",
    "            ids = b['input_ids'].to(device); \n",
    "            m = b['attention_mask'].to(device)\n",
    "            lbls = b['labels'].to(device)\n",
    "            pr = model(ids,m)\n",
    "            loss = crit(pr, lbls)\n",
    "            loss.backward(); opt.step()\n",
    "        # val\n",
    "        model.eval(); vp, vt = [], []\n",
    "        with torch.no_grad():\n",
    "            for b in lv:\n",
    "                ids = b['input_ids'].to(device); \n",
    "                m = b['attention_mask'].to(device)\n",
    "                vp.extend(model(ids,m).cpu().numpy().tolist()); \n",
    "                vt.extend(b['labels'].cpu().numpy().tolist())\n",
    "        th = optimize_threshold(np.array(vt), np.array(vp))\n",
    "        vpred = (np.array(vp)>=th).astype(int)\n",
    "        # record\n",
    "        valaccuracy.append(accuracy_score(vt, vpred)); \n",
    "        valprecision.append(precision_score(vt, vpred))\n",
    "        valrecall.append(recall_score(vt, vpred)); \n",
    "        valf1.append(f1_score(vt, vpred))\n",
    "        valcm.append(confusion_matrix(vt, vpred))\n",
    "        # per-class\n",
    "       \n",
    "        vm = f1_score(vt, vpred, average='macro'); \n",
    "        val_f1_macro.append(vm)\n",
    "        # early stop & save\n",
    "        if vm>best_f:\n",
    "            best_f, pt = vm, 0\n",
    "            torch.save(model.state_dict(), os.path.join(modelpath,f\"{modelname}_fold{fold}.bin\"))\n",
    "        else:\n",
    "            pt+=1\n",
    "        if DECAY and pt%DECAY_AFTER==0 and pt!=0:\n",
    "            for g in opt.param_groups: g['lr']*=DECAY_RATE\n",
    "        print(f\"Fold{fold} Ep{e+1}/{NEPOCHS} - ValMacroF1={vm:.4f} Pat={pt}\")\n",
    "        if pt>=PATIENCE:\n",
    "            print(f\"Stopping early at epoch {e+1}\"); break\n",
    "    # test eval\n",
    "    model.load_state_dict(torch.load(os.path.join(modelpath,f\"{modelname}_fold{fold}.bin\")))\n",
    "    model.eval(); tp, tt = [], []\n",
    "    with torch.no_grad():\n",
    "        for b in le:\n",
    "            ids = b['input_ids'].to(device); \n",
    "            m = b['attention_mask'].to(device)\n",
    "            tp.extend(model(ids,m).cpu().numpy().tolist()); \n",
    "            tt.extend(b['labels'].cpu().numpy().tolist())\n",
    "    tpred = (np.array(tp)>=th).astype(int)\n",
    "    testaccuracy.append(accuracy_score(tt,tpred)); \n",
    "    testprecision.append(precision_score(tt,tpred))\n",
    "    testrecall.append(recall_score(tt,tpred)); \n",
    "    testf1.append(f1_score(tt,tpred))\n",
    "    testcm.append(confusion_matrix(tt,tpred))\n",
    "    #reports.append(classification_report( tt, tpred, output_dict=True, zero_division=0, target_names=['UNT 0', 'TIN 1']))\n",
    "    reports.append(classification_report( tt, tpred, output_dict=True, zero_division=0,labels=[1, 2, 3], target_names=['IND 1', 'GRP 2', 'OTH 3']))\n",
    "    print(f\"Completed fold {fold}/5\")\n",
    "    # cleanup\n",
    "    del model; torch.cuda.empty_cache(); gc.collect()\n",
    "\n",
    "print(f\"Total runtime: {hms_string(time.time()-start)}\")\n",
    "WriteResutls(reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "055bc683a2e74bdeb392dd1957ccb1b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0626dee929b245f3a3060f36e04e56bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f9cb13080f3e412f9993d3624beae077",
       "IPY_MODEL_6e1d2517eb044bcebd077ca6408f258a",
       "IPY_MODEL_55e64cf8425f46e783f9103899ee1cd1"
      ],
      "layout": "IPY_MODEL_055bc683a2e74bdeb392dd1957ccb1b6"
     }
    },
    "07cd1e6af8da4e519647110727ae65cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "08ac0e9b1e00432d91c6749339937a43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4234ba8d5ff846dc8b9a0dac23e5c3b4",
       "IPY_MODEL_7ce13a71ee7a4289b03724abdb5be89d",
       "IPY_MODEL_cb04ab03187e4e06a42a7366bc953f8e"
      ],
      "layout": "IPY_MODEL_4169f5e47e464366841151514c72f7a3"
     }
    },
    "0999a9d5c20049a8b3ffe426c35bcf3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ccbe4e6af97e45ac8019e9b958771187",
      "placeholder": "​",
      "style": "IPY_MODEL_a1120e87b34446109cd377964e2cfa45",
      "value": " 9.10M/9.10M [00:00&lt;00:00, 31.8MB/s]"
     }
    },
    "1151e5a047f041f9ac4c8b830d9061f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f6b9263d7584fc8896150e000b709c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_638805ab4f1b4f3da186465fbd36bf01",
      "max": 25,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_afbd6222b9b64c79a8ed95cf1ae954d4",
      "value": 25
     }
    },
    "24197ce2f45c41b5ae194469d2f9cd4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "263d73ba90a14edf8a4ba379627e9b2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2b28c9309beb47e5981a56d670207250": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ddf2f0fb85a4f46859bc50f48d382ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fe226f85c764d45a5bc63044f156763": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7cc8e85ba79347d58a2c417f8d3c72a8",
      "max": 9096718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_07cd1e6af8da4e519647110727ae65cd",
      "value": 9096718
     }
    },
    "3855a0b5bca044b19f100401742dd964": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd20a7cda9d54cbc9cc87b2a7c29d16f",
      "placeholder": "​",
      "style": "IPY_MODEL_2b28c9309beb47e5981a56d670207250",
      "value": " 25.0/25.0 [00:00&lt;00:00, 1.51kB/s]"
     }
    },
    "3870f9ff6f074f2c8aa4aefa9306a307": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2faa613e35e4887975945574617ce02",
      "placeholder": "​",
      "style": "IPY_MODEL_2ddf2f0fb85a4f46859bc50f48d382ca",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "4169f5e47e464366841151514c72f7a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4234ba8d5ff846dc8b9a0dac23e5c3b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45c1b030b875474cabe57f162a65e175",
      "placeholder": "​",
      "style": "IPY_MODEL_7ef02693da264329aa36de97b45bb154",
      "value": "sentencepiece.bpe.model: 100%"
     }
    },
    "45c1b030b875474cabe57f162a65e175": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4bb8a29050c24e73b3fb26eb31bcc80c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4eb0760d72924bef927cbc661bccbd5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "55e64cf8425f46e783f9103899ee1cd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aeb3673b112e4620b8c712ab7979a97d",
      "placeholder": "​",
      "style": "IPY_MODEL_cb61fad0e7c6435997550ecc29a17e6c",
      "value": " 615/615 [00:00&lt;00:00, 17.8kB/s]"
     }
    },
    "638805ab4f1b4f3da186465fbd36bf01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64ffb2d3b5094507b087138dc56bac86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67b7c958c2f4452b8ed0d1bdfa31b1f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e1d2517eb044bcebd077ca6408f258a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67b7c958c2f4452b8ed0d1bdfa31b1f0",
      "max": 615,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ffed429885e4429f95301cbdd6da0726",
      "value": 615
     }
    },
    "74c5a71c6d4047dd9c66e59ce4173750": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a31d867fb8e04d09997269a4a100f8f3",
       "IPY_MODEL_cafcff3b21c446369358c23a5d388aa9",
       "IPY_MODEL_d0a6dd425f104139a415302c31bc8d70"
      ],
      "layout": "IPY_MODEL_24197ce2f45c41b5ae194469d2f9cd4c"
     }
    },
    "7cc8e85ba79347d58a2c417f8d3c72a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ce13a71ee7a4289b03724abdb5be89d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d9314836e1634b53a3c9f5b9d5c23329",
      "max": 5069051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4bb8a29050c24e73b3fb26eb31bcc80c",
      "value": 5069051
     }
    },
    "7ef02693da264329aa36de97b45bb154": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8218a57782d7495394945cfbbf87213e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9704dc4aaa374c34982d9545fe9760ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1120e87b34446109cd377964e2cfa45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a31d867fb8e04d09997269a4a100f8f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8218a57782d7495394945cfbbf87213e",
      "placeholder": "​",
      "style": "IPY_MODEL_b5226f27887a4616bf2848a342812083",
      "value": "model.safetensors: 100%"
     }
    },
    "a3a8ae066d7f455f8a4fc481e78d89e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a693dc69f27f481db7efd455c1ebbeeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a81faf0a4a6a4834b9b91363a2ad6ba6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d69b704def054170a3f2ad44e3ef37ab",
       "IPY_MODEL_2fe226f85c764d45a5bc63044f156763",
       "IPY_MODEL_0999a9d5c20049a8b3ffe426c35bcf3b"
      ],
      "layout": "IPY_MODEL_bfd633b618ea4efb8a457d1f80cecd65"
     }
    },
    "aeb3673b112e4620b8c712ab7979a97d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afbd6222b9b64c79a8ed95cf1ae954d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b5226f27887a4616bf2848a342812083": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba43741fafda4a9b83023e784aa66e2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3870f9ff6f074f2c8aa4aefa9306a307",
       "IPY_MODEL_1f6b9263d7584fc8896150e000b709c4",
       "IPY_MODEL_3855a0b5bca044b19f100401742dd964"
      ],
      "layout": "IPY_MODEL_64ffb2d3b5094507b087138dc56bac86"
     }
    },
    "bfd633b618ea4efb8a457d1f80cecd65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cafcff3b21c446369358c23a5d388aa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd26b947dba3415c8245a053cef46110",
      "max": 1115567652,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_263d73ba90a14edf8a4ba379627e9b2d",
      "value": 1115567652
     }
    },
    "cb04ab03187e4e06a42a7366bc953f8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edbfb62bb6284c7cb0da1aebd851e04c",
      "placeholder": "​",
      "style": "IPY_MODEL_4eb0760d72924bef927cbc661bccbd5b",
      "value": " 5.07M/5.07M [00:00&lt;00:00, 16.2MB/s]"
     }
    },
    "cb61fad0e7c6435997550ecc29a17e6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ccbe4e6af97e45ac8019e9b958771187": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd20a7cda9d54cbc9cc87b2a7c29d16f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d0a6dd425f104139a415302c31bc8d70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e43ab3e305c140e2afe7e27c31b5d860",
      "placeholder": "​",
      "style": "IPY_MODEL_1151e5a047f041f9ac4c8b830d9061f2",
      "value": " 1.12G/1.12G [00:06&lt;00:00, 149MB/s]"
     }
    },
    "d26fcb3e4551450abe815a8ad757e91b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d69b704def054170a3f2ad44e3ef37ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d26fcb3e4551450abe815a8ad757e91b",
      "placeholder": "​",
      "style": "IPY_MODEL_9704dc4aaa374c34982d9545fe9760ea",
      "value": "tokenizer.json: 100%"
     }
    },
    "d9314836e1634b53a3c9f5b9d5c23329": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2faa613e35e4887975945574617ce02": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e43ab3e305c140e2afe7e27c31b5d860": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edbfb62bb6284c7cb0da1aebd851e04c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9cb13080f3e412f9993d3624beae077": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3a8ae066d7f455f8a4fc481e78d89e2",
      "placeholder": "​",
      "style": "IPY_MODEL_a693dc69f27f481db7efd455c1ebbeeb",
      "value": "config.json: 100%"
     }
    },
    "fd26b947dba3415c8245a053cef46110": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffed429885e4429f95301cbdd6da0726": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
